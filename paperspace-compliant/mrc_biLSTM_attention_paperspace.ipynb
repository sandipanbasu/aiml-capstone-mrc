{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sandipanbasu/aiml-capstone/blob/master/mrc_biLSTM_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "879mz4G6-lRH"
   },
   "source": [
    "## 1. Import Libraries, setting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "DA8sHlEbfYnn",
    "outputId": "b3f6277d-4e5c-4d34-d2cb-58f5ead129a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "u_po1L9T-V5d",
    "outputId": "196ea275-ad22-48d8-adb0-41352b753667"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to the following link in your browser:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=607263109331-gaed96n8hjeqf7er45au9ifj0834geog.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter verification code:  4/0wEpX4crkfc8CEJQxUqvOgxsm0VK-V8nfQ1E2ZPPCOLnI1C0W7R3N1w\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "gauth = GoogleAuth()\n",
    "gauth.CommandLineAuth()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://drive.google.com/open?id=1HeKbRZhCq5kxkSb7g1E6XNY2ZAecCiUN\n",
    "# download data \n",
    "download = drive.CreateFile({'id': '1HeKbRZhCq5kxkSb7g1E6XNY2ZAecCiUN'})\n",
    "download.GetContentFile(project_path + 'squad_data_final_withstopword_withpunctuation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://drive.google.com/open?id=1rDpil-hAhl-A14bs6-3UVPcmM4nU6aTQ\n",
    "# universal sentence encoder\n",
    "download = drive.CreateFile({'id': '1rDpil-hAhl-A14bs6-3UVPcmM4nU6aTQ'})\n",
    "download.GetContentFile(model_path + 'universalembedmatrix.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "yTDFtsEtV7dY",
    "outputId": "984a42ba-d92f-47d8-b415-22cac3c6f838"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pprint\n",
    "from tensorflow.keras.layers import Bidirectional,LSTM,Dense,Dropout,BatchNormalization,Flatten,Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from numpy import array\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uPD8_fgd8PhR"
   },
   "outputs": [],
   "source": [
    "# we will store the params as we go along in this object\n",
    "params = {}\n",
    "project_path = \"/content/drive/My Drive/AIML-MRC-Capstone/datasets/Squad2.0/TrainingDataset/\"\n",
    "model_path = \"/content/drive/My Drive/AIML-MRC-Capstone/models/\"\n",
    "tensorboard_logpath  = \"/content/drive/My Drive/AIML-MRC-Capstone/models/tensorboard-logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for paperspace\n",
    "# we will store the params as we go along in this object\n",
    "params = {}\n",
    "project_path = \"/storage/\"\n",
    "model_path = \"/storage/models/\"\n",
    "tensorboard_logpath  = \"/notebooks/tensorboard-logs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "09eGk3oWWCaP"
   },
   "source": [
    "# Objective - Bi-LSTM Attention\n",
    "\n",
    "*   **Inputs: A question q = {q1, ..., qQ} of length Q and a context paragraph p = {p1, ..., pP } of length P.**\n",
    "*   **Output: An answer span {as, ae} where as is the index of the first answer token in p, ae is the index of the last answer token in p, 0 <= as, ae >= m, and ae >= as.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C-TACUiuOCJw"
   },
   "source": [
    "## 0 Common Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XtBcy2Qwm2-c"
   },
   "source": [
    "#### 0.1 Custom function for preprocessing of context and question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LFr3-S_Gm9FX"
   },
   "outputs": [],
   "source": [
    "# remove unwanted chars\n",
    "# convert to lowercase\n",
    "# remove unwanted spaces\n",
    "# remove stop words\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "## reference \n",
    "def decontracted(phrase):\n",
    "    \"\"\"\n",
    "    This function remooves punctuation from given sentence.\n",
    "    \"\"\"\n",
    "\n",
    "    if(phrase is np.nan):\n",
    "      return 'impossible'      \n",
    "\n",
    "    try:      \n",
    "      # specific\n",
    "      phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "      phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "      # general\n",
    "      phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "      phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "      phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "      phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "      phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "      phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "      phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "      phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "      \n",
    "      # string operation\n",
    "      phrase = phrase.replace('\\\\r', ' ')\n",
    "      phrase = phrase.replace('\\\\\"', ' ')\n",
    "      phrase = phrase.replace('\\\\n', ' ')\n",
    "\n",
    "      phrase = re.sub('[^A-Za-z0-9]+', ' ', phrase.lower())\n",
    "    except:\n",
    "      print(phrase)  \n",
    "    \n",
    "    return phrase\n",
    "\n",
    "def preprocess_text(corpus, text_lower_case=True, \n",
    "                      special_char_removal=True, stopword_removal=True, remove_digits=False):    \n",
    "    normalized_text = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "        # doc = decontracted(doc)\n",
    "        # lowercase the text    \n",
    "        if text_lower_case:\n",
    "            doc = doc.lower()\n",
    "        # remove special characters and\\or digits    \n",
    "        if special_char_removal:\n",
    "            # insert spaces between special characters to isolate them    \n",
    "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "            doc = remove_special_characters(doc, remove_digits=remove_digits) \n",
    "\n",
    "        if stopword_removal:\n",
    "            doc = remove_stopwords(doc)\n",
    "\n",
    "        normalized_text.append(doc)\n",
    "        \n",
    "    return normalized_text\n",
    "\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    #Using regex\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):  \n",
    "    word_tokens = word_tokenize(text) \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]   \n",
    "    filtered_sentence = [] \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)                 \n",
    "    return ' '.join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "20-D8HBeOf_p"
   },
   "source": [
    "### 0.2 Answer Span from Context and Answer, and reverse for predicted spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vbM8z2AEjxKK"
   },
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    \"\"\"\n",
    "    Returns tokenised words.\n",
    "    \"\"\"\n",
    "    return nltk.word_tokenize(sentence)\n",
    "\n",
    "def answer_span(context,ans):\n",
    "    \"\"\"\n",
    "    This funtion returns anwer span start index and end index.\n",
    "    \"\"\"\n",
    "    ans_token = tokenize(ans)\n",
    "    con_token = tokenize(context)\n",
    "    ans_len = len(ans_token)\n",
    "    \n",
    "    if ans_len!=0 and ans_token[0] in con_token:\n",
    "    \n",
    "        indices = [i for i, x in enumerate(con_token) if x == ans_token[0]]        \n",
    "        try:\n",
    "\n",
    "            if(len(indices)>1):\n",
    "                start = [i for i in indices if (con_token[i:i+ans_len] == ans_token) ]\n",
    "                end = start[0] + ans_len - 1\n",
    "                return start[0],end\n",
    "\n",
    "            else:\n",
    "                start = con_token.index(ans_token[0])\n",
    "                end = start + ans_len - 1\n",
    "                return start,end\n",
    "        except:\n",
    "            return -1,-1\n",
    "    else:\n",
    "        return -1,-1\n",
    "\n",
    "def span_to_answer(span, context):\n",
    "  con_token = tokenize(context)  \n",
    "  return ' '.join(con_token[span[0]:span[1]+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_sveyxKK5j8q"
   },
   "source": [
    "### 0.3 Update and persist params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K170rfN15qGP"
   },
   "outputs": [],
   "source": [
    "### SAVE PARAMS\n",
    "# Writing to sample.json \n",
    "\n",
    "def updateparams():\n",
    "  with open(model_path + \"params.json\", \"w\") as p: \n",
    "    p.write(json.dumps(params))\n",
    "  print(\"params.jsop updated and can be found in \", model_path + \"params.json\")  \n",
    "\n",
    "# updateparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yYMDmMJNU9mw"
   },
   "outputs": [],
   "source": [
    "def showparams():\n",
    "  pprint.pprint(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hxuHGmpRMBHT"
   },
   "source": [
    "## 1 Context, Answer EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6tWRDHA6z_Ji"
   },
   "source": [
    "**<font color=\"red\">BE CAREFUL BEFORE EXECUTING THIS PLEASE. THERE IS HIGH CHANCE THAT THIS WILL OVERWRITE EXISTING DATAFRAMES</font>** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "colab_type": "code",
    "id": "JsuZ3NdiMOiB",
    "outputId": "bdf4beea-2faf-4277-cf2f-95bd6f3ff540"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-421eee24cc90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msquad_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'squad_data_final_withstopword_withpunctuation.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msquad_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /content/drive/My Drive/AIML-MRC-Capstone/datasets/Squad2.0/TrainingDataset/squad_data_final_withstopword_withpunctuation.csv does not exist: '/content/drive/My Drive/AIML-MRC-Capstone/datasets/Squad2.0/TrainingDataset/squad_data_final_withstopword_withpunctuation.csv'"
     ]
    }
   ],
   "source": [
    "squad_df = pd.read_csv(project_path+'squad_data_final_withstopword_withpunctuation.csv')\n",
    "squad_df.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vps2_zIB7q7i"
   },
   "outputs": [],
   "source": [
    "### specific cleaning of context and question\n",
    "### DO NOT REMOVE STOP WORDS \n",
    "###\n",
    "squad_df['clean_context'] = preprocess_text(squad_df['context'],stopword_removal=False, special_char_removal=False)\n",
    "squad_df['clean_question'] = preprocess_text(squad_df['question'],stopword_removal=False, special_char_removal=False)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZ5CD4fzCPcj"
   },
   "outputs": [],
   "source": [
    "squad_df['clean_answer'] = preprocess_text(squad_df['answer'],stopword_removal=False, special_char_removal = False)\n",
    "\n",
    "# preprocess_text([squad_df['answer'].iloc[23]],stopword_removal=False, special_char_removal = False)\n",
    "# preprocess_text([np.nan],stopword_removal=False, special_char_removal = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "UgrKpCLgC8q-",
    "outputId": "381d3afc-8e27-42fc-9cf4-2c67356096d3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>id</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer</th>\n",
       "      <th>plausible_answer_start</th>\n",
       "      <th>plausible_answer</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>clean_context</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>answer_len</th>\n",
       "      <th>answer_end</th>\n",
       "      <th>answer_span</th>\n",
       "      <th>answer_word_span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>269</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>beyonc giselle knowles carter bi j nse bee yon...</td>\n",
       "      <td>when did beyonce start becoming popular</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>17</td>\n",
       "      <td>286</td>\n",
       "      <td>(269, 286)</td>\n",
       "      <td>(44, 47)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>207</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>beyonc giselle knowles carter bi j nse bee yon...</td>\n",
       "      <td>what areas did beyonce compete in when she was...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>19</td>\n",
       "      <td>226</td>\n",
       "      <td>(207, 226)</td>\n",
       "      <td>(33, 35)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>56be85543aeaaa14008c9066</td>\n",
       "      <td>526</td>\n",
       "      <td>2003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>beyonc giselle knowles carter bi j nse bee yon...</td>\n",
       "      <td>when did beyonce leave destiny is child and be...</td>\n",
       "      <td>2003</td>\n",
       "      <td>4</td>\n",
       "      <td>530</td>\n",
       "      <td>(526, 530)</td>\n",
       "      <td>(93, 93)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
       "      <td>166</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>beyonc giselle knowles carter bi j nse bee yon...</td>\n",
       "      <td>in what city and state did beyonce grow up</td>\n",
       "      <td>houston texas</td>\n",
       "      <td>13</td>\n",
       "      <td>179</td>\n",
       "      <td>(166, 179)</td>\n",
       "      <td>(27, 28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
       "      <td>276</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>beyonc giselle knowles carter bi j nse bee yon...</td>\n",
       "      <td>in which decade did beyonce become famous</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>10</td>\n",
       "      <td>286</td>\n",
       "      <td>(276, 286)</td>\n",
       "      <td>(46, 47)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>In what R&amp;B group was she the lead singer?</td>\n",
       "      <td>56bf6b0f3aeaaa14008c9603</td>\n",
       "      <td>320</td>\n",
       "      <td>Destiny's Child</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>beyonc giselle knowles carter bi j nse bee yon...</td>\n",
       "      <td>in what r b group was she the lead singer</td>\n",
       "      <td>destiny is child</td>\n",
       "      <td>14</td>\n",
       "      <td>334</td>\n",
       "      <td>(320, 334)</td>\n",
       "      <td>(56, 58)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     title  ... answer_word_span\n",
       "0  Beyoncé  ...         (44, 47)\n",
       "1  Beyoncé  ...         (33, 35)\n",
       "2  Beyoncé  ...         (93, 93)\n",
       "3  Beyoncé  ...         (27, 28)\n",
       "4  Beyoncé  ...         (46, 47)\n",
       "5  Beyoncé  ...         (56, 58)\n",
       "\n",
       "[6 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jhUog7nH_uqL"
   },
   "outputs": [],
   "source": [
    "ans_span = []\n",
    "for i in range(len(squad_df)):\n",
    "    s,e = answer_span(squad_df[\"clean_context\"].iloc[i],squad_df[\"clean_answer\"].iloc[i])\n",
    "    ans_span.append((s,e))\n",
    "\n",
    "squad_df[\"answer_word_span\"] = ans_span    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "BpMnsnfCIqh1",
    "outputId": "664eb3b0-179e-4063-c638-4deb57068883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 16)\n",
      "(43502, 16)\n",
      "No of records which does not have answer but span not found in context =  (0, 16)\n"
     ]
    }
   ],
   "source": [
    "# check no of right answer span detection \n",
    "print(squad_df[squad_df[\"answer_word_span\"] == (-1,-1)].shape)\n",
    "print(squad_df[squad_df['clean_answer'] == 'impossible' ].shape)\n",
    "\n",
    "print('No of records which does not have answer but span not found in context = ', \n",
    "      squad_df[(squad_df['clean_answer'] != 'impossible') & (squad_df[\"answer_word_span\"] == (-1,-1))].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XK2rwLdg9Aqq"
   },
   "outputs": [],
   "source": [
    "# write the latest greatet\n",
    "squad_df.to_csv(project_path+'squad_data_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wYRTJ6qX9kRj"
   },
   "outputs": [],
   "source": [
    "squad_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "ltvYXgi07_p2",
    "outputId": "d373fc87-1564-427d-d301-2f2392144c6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('beyonc giselle knowles was born in houston texas to celestine ann tina '\n",
      " 'knowles n e beyinc a hairdresser and salon owner and mathew knowles a xerox '\n",
      " 'sales manager beyonc is name is a tribute to her mother is maiden name '\n",
      " 'beyonc is younger sister solange is also a singer and a former member of '\n",
      " 'destiny is child mathew is african american while tina is of louisiana '\n",
      " 'creole descent with african native american french cajun and distant irish '\n",
      " 'and spanish ancestry through her mother beyonc is a descendant of acadian '\n",
      " 'leader joseph broussard she was raised in a methodist household ')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(squad_df['clean_context'].iloc[39])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mGZp4iLEHE8n"
   },
   "source": [
    "## 2 Load Squad Data - Cleaned and curated (output of preprocessing step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CFPpoxl7Afls"
   },
   "source": [
    "### 2.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "4_u1n8G3fge_",
    "outputId": "0234cb38-c70b-4a9d-ed0a-dc1011e3aa5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130306 entries, 0 to 130305\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   title                   130306 non-null  object \n",
      " 1   context                 130306 non-null  object \n",
      " 2   question                130306 non-null  object \n",
      " 3   id                      130306 non-null  object \n",
      " 4   answer_start            130306 non-null  int64  \n",
      " 5   answer                  86807 non-null   object \n",
      " 6   plausible_answer_start  43498 non-null   float64\n",
      " 7   plausible_answer        43498 non-null   object \n",
      " 8   is_impossible           130306 non-null  bool   \n",
      " 9   clean_context           130306 non-null  object \n",
      " 10  clean_question          130306 non-null  object \n",
      " 11  clean_answer            130306 non-null  object \n",
      " 12  answer_len              130306 non-null  int64  \n",
      " 13  answer_end              130306 non-null  int64  \n",
      " 14  answer_span             130306 non-null  object \n",
      " 15  answer_word_span        130306 non-null  object \n",
      "dtypes: bool(1), float64(1), int64(3), object(11)\n",
      "memory usage: 15.0+ MB\n",
      "None\n",
      "beyonc giselle knowlescarter bijnse beeyonsay born september 4 1981 american singer songwriter record producer actress born raised houston texas performed various singing dancing competitions child rose fame late 1990s lead singer rb girlgroup destinys child managed father mathew knowles group became one worlds bestselling girl groups time hiatus saw release beyoncs debut album dangerously love 2003 established solo artist worldwide earned five grammy awards featured billboard hot 100 numberone singles crazy love baby boy\n"
     ]
    }
   ],
   "source": [
    "#### NOTE THE 2 data frames's\n",
    "df_nostopwords = 'squad_data_final_context_withoutstopwords.csv'\n",
    "# df_withstopwords = 'squad_data_final_withstopword_withpunctuation.csv'\n",
    "squad_df = pd.read_csv(project_path+'squad_data_final_context_withoutstopwords.csv')\n",
    "squad_df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "squad_df[\"answer_word_span\"] = squad_df[\"answer_word_span\"].apply(lambda x :eval(x))\n",
    "print(squad_df.info())\n",
    "print(squad_df['clean_context'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "colab_type": "code",
    "id": "uJ_KUPvezIOi",
    "outputId": "2749501c-761c-4794-a7bc-3b32046695d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>id</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer</th>\n",
       "      <th>plausible_answer_start</th>\n",
       "      <th>plausible_answer</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>clean_context</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>answer_len</th>\n",
       "      <th>answer_end</th>\n",
       "      <th>answer_span</th>\n",
       "      <th>answer_word_span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>269</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>beyonc giselle knowlescarter bijnse beeyonsay ...</td>\n",
       "      <td>when did beyonce start becoming popular</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>17</td>\n",
       "      <td>286</td>\n",
       "      <td>(269, 286)</td>\n",
       "      <td>(-1, -1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>207</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>beyonc giselle knowlescarter bijnse beeyonsay ...</td>\n",
       "      <td>what areas did beyonce compete in when she was...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>19</td>\n",
       "      <td>226</td>\n",
       "      <td>(207, 226)</td>\n",
       "      <td>(21, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>56be85543aeaaa14008c9066</td>\n",
       "      <td>526</td>\n",
       "      <td>2003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>beyonc giselle knowlescarter bijnse beeyonsay ...</td>\n",
       "      <td>when did beyonce leave destinys child and beco...</td>\n",
       "      <td>2003</td>\n",
       "      <td>4</td>\n",
       "      <td>530</td>\n",
       "      <td>(526, 530)</td>\n",
       "      <td>(55, 55)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     title  ... answer_word_span\n",
       "0  Beyoncé  ...         (-1, -1)\n",
       "1  Beyoncé  ...         (21, 23)\n",
       "2  Beyoncé  ...         (55, 55)\n",
       "\n",
       "[3 rows x 16 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U35P3ZvGAQQD"
   },
   "source": [
    "### 2.2 Create Train, Validation and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "7M9hW4xy-Suj",
    "outputId": "ca7c5b1c-2f5c-4f5d-dab4-17baf95cd759"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78183, 16)\n",
      "(26061, 16)\n",
      "(26062, 16)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample,shuffle\n",
    "\n",
    "# train = resample(train)\n",
    "# train = shuffle(train,n_samples =50000)\n",
    "\n",
    "train,test = train_test_split(squad_df,test_size = 0.2)\n",
    "train,val = train_test_split(train,test_size=0.25)\n",
    "\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y6dcPCGiJrz1"
   },
   "source": [
    "### 2.3 Build Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hxoMIrC6EIgS",
    "outputId": "13a92eac-0497-49d9-db40-019767375a3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:09<00:00,  4.63s/it]\n"
     ]
    }
   ],
   "source": [
    "# from tqdm import tqdm\n",
    "# params['tokenizer_num_words'] = 80000\n",
    "# tokenizer = preprocessing.text.Tokenizer(num_words=params['tokenizer_num_words'])\n",
    "\n",
    "# # NOTE: tokenizer is been made out of original dataset\n",
    "# for text in tqdm([squad_df['clean_context'], squad_df['clean_question']]):  \n",
    "#   tokenizer.fit_on_texts(text.values)\n",
    "\n",
    "# # total tokenizer words\n",
    "# params['vocab_size'] = len(tokenizer.word_index)\n",
    "\n",
    "# ### SAVE TOKENIZERS\n",
    "# with open(model_path + \"tokenizer.pkl\",\"wb\") as f:\n",
    "#     pickle.dump(tokenizer,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2x8w3nfOSwKc",
    "outputId": "adb5729f-43ab-4d1d-9a09-20f4760b3c92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100850"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(model_path + \"tokenizer.pkl\",\"rb\") as infile:\n",
    "    tokenizer = pickle.load(infile)\n",
    "\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Y7fIbj3tatHH",
    "outputId": "e9524041-7272-477c-a196-e047486d6e8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['how']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7gXSy_y36IFb"
   },
   "source": [
    "### 2.4 Update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "2whUHcmX5PwS",
    "outputId": "c86bbf25-8ba3-4442-ee84-937bc7dce3c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_length_99': 285,\n",
      " 'context_pad_seq': 'pre',\n",
      " 'embedding_size': 300,\n",
      " 'question_length_99': 20,\n",
      " 'question_pad_seq': 'pre',\n",
      " 'rnn_units': 256,\n",
      " 'test_shape': (26062, 16),\n",
      " 'train_shape': (78183, 16),\n",
      " 'val_shape': (26061, 16),\n",
      " 'vocab_size': 100850}\n"
     ]
    }
   ],
   "source": [
    "# From the EDA and historgrams we can conclude that - \n",
    "# 99% percentile of context word length = 285\n",
    "# 99% percentile or question word lengt = 20\n",
    "context_length = 285\n",
    "question_length = 20\n",
    "params['train_shape'] = train.shape\n",
    "params['val_shape'] = val.shape\n",
    "params['test_shape'] = test.shape\n",
    "params['context_length_99'] = context_length # initialize with a high percentile\n",
    "params['question_length_99'] = question_length # initialize with a high percentile\n",
    "params['embedding_size'] = 300\n",
    "params['rnn_units'] = 256\n",
    "params['context_pad_seq'] = 'pre'\n",
    "params['question_pad_seq'] = 'pre'\n",
    "params['vocab_size'] = len(tokenizer.word_index)\n",
    "\n",
    "pprint.pprint(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7lRuVtp_7y51"
   },
   "source": [
    "## 3 Vectorization / Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oEJqzOfW9ARO"
   },
   "source": [
    "#### 3.1 Integer Sequence of Context and Question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HhuvjYmZ7m6W"
   },
   "outputs": [],
   "source": [
    "train_clean_context_sequence = tokenizer.texts_to_sequences(train[\"clean_context\"].values)\n",
    "test_clean_context_sequence = tokenizer.texts_to_sequences(test[\"clean_context\"].values)\n",
    "val_clean_context_sequence = tokenizer.texts_to_sequences(val[\"clean_context\"].values)\n",
    "\n",
    "\n",
    "train_clean_question_sequence = tokenizer.texts_to_sequences(train[\"clean_question\"].values)\n",
    "test_clean_question_sequence = tokenizer.texts_to_sequences(test[\"clean_question\"].values)\n",
    "val_clean_question_sequence = tokenizer.texts_to_sequences(val[\"clean_question\"].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "vXQNaAxehrDa",
    "outputId": "63c50a02-dcfa-4fba-da50-8832c43bcee8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 501, 1918, 2024, 642],\n",
       " [37,\n",
       "  512,\n",
       "  26,\n",
       "  8,\n",
       "  3805,\n",
       "  59,\n",
       "  391,\n",
       "  521,\n",
       "  66,\n",
       "  844,\n",
       "  1305,\n",
       "  71,\n",
       "  2428,\n",
       "  2078,\n",
       "  2428,\n",
       "  113,\n",
       "  1579,\n",
       "  500],\n",
       " [93, 117, 10909, 608, 2223, 186, 1, 3346],\n",
       " [39, 16, 1, 1018, 1449, 133, 14660, 5307],\n",
       " [5, 1, 68540, 15780, 24719, 39, 9, 3, 939, 170, 1984, 10, 3557]]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean_question_sequence[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "0kmRjkqRlExD",
    "outputId": "8de64ea6-b362-4171-fb68-178ddc1dc3a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79664                    what has usb effectively replaced\n",
       "52220    who designed a new wing for queen victoria and...\n",
       "70796     which countries werent taken over by the soviets\n",
       "62757    how did the sun describe john majors conservat...\n",
       "45589    in the jablonski allgemeines lexicon 1721 how ...\n",
       "Name: clean_question, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['clean_question'][5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQpM6dGtoGkP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7u41PKZTFcwm"
   },
   "source": [
    "#### 3.2 Find Max Sequence length of Context and Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Jwh8HGs0Fbp2",
    "outputId": "d8e836e3-e105-47db-d24d-a99ff9c0582e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_length_99': 285,\n",
      " 'context_max_length': 426,\n",
      " 'context_pad_seq': 'pre',\n",
      " 'embedding_size': 300,\n",
      " 'question_length_99': 20,\n",
      " 'question_max_length': 40,\n",
      " 'question_pad_seq': 'pre',\n",
      " 'rnn_units': 256,\n",
      " 'test_shape': (26062, 16),\n",
      " 'train_shape': (78183, 16),\n",
      " 'val_shape': (26061, 16),\n",
      " 'vocab_size': 100850}\n"
     ]
    }
   ],
   "source": [
    "# max length of context\n",
    "params['context_max_length'] = max(max(len(txt) for txt in train_clean_context_sequence),\n",
    "                                  max(len(txt) for txt in test_clean_context_sequence),\n",
    "                                  max(len(txt) for txt in val_clean_context_sequence))\n",
    "\n",
    "params['question_max_length'] = max(max(len(txt) for txt in train_clean_question_sequence),\n",
    "                                  max(len(txt) for txt in test_clean_question_sequence),\n",
    "                                  max(len(txt) for txt in val_clean_question_sequence))\n",
    "\n",
    "\n",
    "pprint.pprint(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NhnBwThFIA0H"
   },
   "source": [
    "#### 3.3 Padding of the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "gGvIf7xU9rIJ",
    "outputId": "20889ad2-0bdf-48a0-d7b5-8901f4105260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78183, 426)\n",
      "(26062, 426)\n",
      "(26061, 426)\n"
     ]
    }
   ],
   "source": [
    "train_context_sequence = preprocessing.sequence.pad_sequences(train_clean_context_sequence,\n",
    "                                                              maxlen=params['context_max_length'],\n",
    "                                                              padding=params['context_pad_seq'])\n",
    "test_context_sequence = preprocessing.sequence.pad_sequences(test_clean_context_sequence,\n",
    "                                                             maxlen=params['context_max_length'],\n",
    "                                                             padding=params['context_pad_seq'])\n",
    "val_context_sequence = preprocessing.sequence.pad_sequences(val_clean_context_sequence,\n",
    "                                                            maxlen=params['context_max_length'],\n",
    "                                                            padding=params['context_pad_seq'])\n",
    "\n",
    "print(train_context_sequence.shape)\n",
    "print(test_context_sequence.shape)\n",
    "print(val_context_sequence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "2NxpIGIb9p5T",
    "outputId": "7322d09a-1326-42d0-add2-4863d1d50b72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78183, 40)\n",
      "(26062, 40)\n",
      "(26061, 40)\n"
     ]
    }
   ],
   "source": [
    "train_question_sequence = preprocessing.sequence.pad_sequences(train_clean_question_sequence,\n",
    "                                                               maxlen=params['question_max_length'],\n",
    "                                                               padding=params['question_pad_seq'])\n",
    "test_question_sequence = preprocessing.sequence.pad_sequences(test_clean_question_sequence,\n",
    "                                                              maxlen=params['question_max_length'],\n",
    "                                                              padding=params['question_pad_seq'])\n",
    "val_question_sequence = preprocessing.sequence.pad_sequences(val_clean_question_sequence,\n",
    "                                                             maxlen=params['question_max_length'],\n",
    "                                                             padding=params['question_pad_seq'])\n",
    "\n",
    "print(train_question_sequence.shape)\n",
    "print(test_question_sequence.shape)\n",
    "print(val_question_sequence.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgCKNbH6_-yd"
   },
   "source": [
    "#### 3.4 Create Answer Sequence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bv0yC_w8AF4x"
   },
   "source": [
    "Encode y_trues as big array consisting of ans_start + ans_end. This has to be used in loss function as well. We will use the answer_word_span feature\n",
    "\n",
    "**y_true = answer_start + answer_end**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cHPxRRHuAnSH"
   },
   "outputs": [],
   "source": [
    "# for train data\n",
    "y_train = []\n",
    "span_ofr = 0;\n",
    "params['train_span_outofrange'] = 0\n",
    "params['test_span_outofrange'] = 0\n",
    "params['val_span_outofrange'] = 0\n",
    "\n",
    "for i in range(len(train)):    \n",
    "    s = np.zeros(params['context_max_length'],dtype = \"float32\")\n",
    "    e = np.zeros(params['context_max_length'],dtype = \"float32\")\n",
    "    start, end = train[\"answer_word_span\"].iloc[i]    \n",
    "    s[start] = 1\n",
    "    e[end] = 1\n",
    "    y_train.append(np.concatenate((s,e)))    \n",
    "\n",
    "params['train_span_outofrange'] = span_ofr\n",
    "span_ofr = 0;\n",
    "\n",
    "# for test data\n",
    "y_test = []\n",
    "for i in range(len(test)):    \n",
    "    s = np.zeros(params['context_max_length'],dtype = \"float32\")\n",
    "    e = np.zeros(params['context_max_length'],dtype = \"float32\")        \n",
    "    start,end = test[\"answer_word_span\"].iloc[i]    \n",
    "    s[start] = 1\n",
    "    e[end] = 1\n",
    "    y_test.append(np.concatenate((s,e)))\n",
    "\n",
    "params['test_span_outofrange'] = span_ofr\n",
    "span_ofr = 0;\n",
    "                \n",
    "# for val data\n",
    "y_val = []\n",
    "for i in range(len(val)):\n",
    "    s = np.zeros(params['context_max_length'],dtype = \"int\")\n",
    "    e = np.zeros(params['context_max_length'],dtype = \"int\")        \n",
    "    start,end = val[\"answer_word_span\"].iloc[i]    \n",
    "    s[start] = 1\n",
    "    e[end] = 1      \n",
    "    y_val.append(np.concatenate((s,e)))\n",
    "\n",
    "params['val_span_outofrange'] = span_ofr    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "WgPgnMl0VZCd",
    "outputId": "bb237c6b-39e7-410f-a03a-e456570d26b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78183 852\n",
      "26062 852\n",
      "26061 852\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train),len(y_train[0]))\n",
    "print(len(y_test),len(y_test[0]))\n",
    "print(len(y_val),len(y_val[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mFuJMid-iT7a"
   },
   "source": [
    "### 3.5 Check 1 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SXXhftC5kE8A",
    "outputId": "79720897-96ca-45a6-e0d5-7f193dd77007"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sweden'"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 1\n",
    "answer_span(train['clean_context'].iloc[index],train['clean_answer'].iloc[index])\n",
    "span_to_answer((22,22),train['clean_context'].iloc[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "fAXS9YCpiVkn",
    "outputId": "9eed9e40-ddc3-4ccc-ae4c-a3136c1ff9f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ori Cont = \n",
      "(\"An important element in Estonia's post-independence reorientation has been \"\n",
      " 'closer ties with the Nordic countries, especially Finland and Sweden. '\n",
      " 'Indeed, Estonians consider themselves a Nordic people rather than Balts, '\n",
      " 'based on their historical ties with Sweden, Denmark and particularly '\n",
      " 'Finland. In December 1999, then Estonian foreign minister (and since 2006, '\n",
      " 'president of Estonia) Toomas Hendrik Ilves delivered a speech entitled '\n",
      " '\"Estonia as a Nordic Country\" to the Swedish Institute for International '\n",
      " 'Affairs. In 2003, the foreign ministry also hosted an exhibit called '\n",
      " '\"Estonia: Nordic with a Twist\".')\n",
      "CLean Cont = \n",
      "('important element estonias postindependence reorientation closer ties nordic '\n",
      " 'countries especially finland sweden indeed estonians consider nordic people '\n",
      " 'rather balts based historical ties sweden denmark particularly finland '\n",
      " 'december 1999 estonian foreign minister since 2006 president estonia toomas '\n",
      " 'hendrik ilves delivered speech entitled estonia nordic country swedish '\n",
      " 'institute international affairs 2003 foreign ministry also hosted exhibit '\n",
      " 'called estonia nordic twist')\n",
      "Question =  What year did the foreign ministry hold an exhibit exploring the Nordic ties of Estonia?\n",
      "Clean Question =  what year did the foreign ministry hold an exhibit exploring the nordic ties of estonia\n",
      "Answer =  2003\n",
      "Clean Answer =  2003\n",
      "AS,AE =  (48, 48)\n",
      "encoded  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Ori Cont = \")\n",
    "pprint.pprint(train['context'].iloc[index])\n",
    "print(\"CLean Cont = \")\n",
    "pprint.pprint(train['clean_context'].iloc[index])\n",
    "print('Question = ',train['question'].iloc[index])\n",
    "print('Clean Question = ',train['clean_question'].iloc[index])\n",
    "print('Answer = ',train['answer'].iloc[index])\n",
    "print('Clean Answer = ',train['clean_answer'].iloc[index])\n",
    "print('AS,AE = ',train['answer_word_span'].iloc[index])\n",
    "print(\"encoded \", y_train[index])\n",
    "print(span_to_answer([60,62],train['clean_context'].iloc[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "-rZCyBydBZW1",
    "outputId": "ca0e3749-7ce9-4992-bf09-02fe4d64e0f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_length_99': 285,\n",
      " 'context_max_length': 426,\n",
      " 'context_pad_seq': 'pre',\n",
      " 'embedding_size': 300,\n",
      " 'question_length_99': 20,\n",
      " 'question_max_length': 40,\n",
      " 'question_pad_seq': 'pre',\n",
      " 'rnn_units': 256,\n",
      " 'test_shape': (26062, 16),\n",
      " 'test_span_outofrange': 0,\n",
      " 'tokenizer_num_words': 80000,\n",
      " 'train_shape': (78183, 16),\n",
      " 'train_span_outofrange': 0,\n",
      " 'val_shape': (26061, 16),\n",
      " 'val_span_outofrange': 0,\n",
      " 'vocab_size': 100850}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 751
    },
    "colab_type": "code",
    "id": "mDzXjXa3MpP0",
    "outputId": "9b68891d-4c2c-4b48-c17e-b1dae05c3486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beyonc giselle knowlescarter bijnse beeyonsay born september 4 1981 american singer songwriter record producer actress born raised houston texas performed various singing dancing competitions child rose fame late 1990s lead singer rb girlgroup destinys child managed father mathew knowles group became one worlds bestselling girl groups time hiatus saw release beyoncs debut album dangerously love 2003 established solo artist worldwide earned five grammy awards featured billboard hot 100 numberone singles crazy love baby boy\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0    53\n",
      "  9334 62177    77   332    29   478   533    77  5847  4257 62178   133\n",
      "   376 11388  3499 62179  8796   960  4376  3907   764 10890  1611  5008\n",
      "  1416   130  2687   852  6026   789  2830 30171 10830   706  1427  4279\n",
      "    45  2092   219  3395 11870  4279  2187   360    77   332   125   818\n",
      "   665  2830  1339 24572     9  1129]\n",
      "what was the first album beyonc released as a solo artist\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    71    11 22149   906]\n"
     ]
    }
   ],
   "source": [
    "print(squad_df['clean_context'][10])\n",
    "print(train_context_sequence[110])\n",
    "print(squad_df['clean_question'][10])\n",
    "print(train_question_sequence[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V0TSjNkdXzuR"
   },
   "source": [
    "### 3.6 Create a common function to generate sequences (useful in prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sq97Vq4kXTST"
   },
   "outputs": [],
   "source": [
    "# function to generate sequences withg appropiate padding\n",
    "def generate_question_context_sequence(context, question):\n",
    "  question_seq = tokenizer.texts_to_sequences(question)\n",
    "  context_seq = tokenizer.texts_to_sequences(context)\n",
    "  question_seq = preprocessing.sequence.pad_sequences(question_seq,\n",
    "                                                      maxlen=params['question_max_length'],\n",
    "                                                     padding=params['question_pad_seq'])\n",
    "  context_seq = preprocessing.sequence.pad_sequences(context_seq,\n",
    "                                                     maxlen=params['context_max_length'],\n",
    "                                                    padding=params['question_pad_seq'])\n",
    "  return context_seq, question_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "nkpMiW1HaqrL",
    "outputId": "3bf8bb0b-15c2-4301-8c20-ce7022779b49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are invented to represent a multiple and unrelated pronunciation\n",
      "(1, 426) (1, 40)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train[\"clean_question\"].iloc[1])\n",
    "\n",
    "c='state among best prekindergarten education national institute early education research rated first united states regard standards quality access prekindergarten education 2004 calling model early childhood schooling high school dropout rate decreased 3 1 2 5 percent 2007 2008 oklahoma ranked among 18 states 3 percent less dropout rate 2004 state ranked 36th nation relative number adults high school diplomas though 85 2 percent highest rate among southern states'\n",
    "q='what are invented to represent a multiple and unrelated pronunciation'\n",
    "cs,qs = generate_question_context_sequence([c],[q])\n",
    "print(cs.shape,qs.shape)\n",
    "train_question_sequence[1] == qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "nl55IUkVck82",
    "outputId": "a81ead47-97ec-4fdc-f6db-1680213c5f1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    2,   29,   16,    1,  444, 2080, 1091,  429,\n",
       "       4103, 9437,    1, 8200, 3218,    3, 1916], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_question_sequence[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Wt51Se0SchIp",
    "outputId": "ef115d85-e173-4040-f129-ba9fdc4212af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what term can be used to refer to the usable spectrum of an antennas frequency'"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r6FSl5UDL_qD"
   },
   "source": [
    "## 4 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yS6fKEvieWrX"
   },
   "source": [
    "**Implements a baseline 0 in Deep Learning based approach per our project synopsis. This baseline model uses the following layers **\n",
    "0.   Input layer\n",
    "1.   Embedding Layer\n",
    "2.   List LSTM\n",
    "3.   a custom Bilinear Similarity layer \n",
    "4.   Prediction Layer\n",
    "5.   Output layer \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U9JFn3oWiU4y"
   },
   "source": [
    "### 4.2 Building Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TOTSZc8_UeU2"
   },
   "source": [
    "#### Common Function - CUDNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VwjPKOsTUdgY"
   },
   "outputs": [],
   "source": [
    "# As per https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM, it will use CuDNN Lstm\n",
    "# if below params match\n",
    "# activation == tanh\n",
    "# recurrent_activation == sigmoid\n",
    "# recurrent_dropout == 0\n",
    "# unroll is False\n",
    "# use_bias is True\n",
    "# Inputs are not masked or strictly right padded.\n",
    "\n",
    "def createCUDNNLstm(units,return_state,return_sequences,dropout,name=''):\n",
    "  return layers.LSTM(units=units,\n",
    "                     return_state=return_state,\n",
    "                     return_sequences=return_sequences, \n",
    "                     name = name,\n",
    "                     activation='tanh',\n",
    "                     recurrent_activation='sigmoid',\n",
    "                     recurrent_dropout=0,\n",
    "                     dropout=dropout,\n",
    "                     unroll=False,\n",
    "                     use_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "55fdB8yMWMVU",
    "outputId": "0fc9d9fc-e53e-429a-d5b0-0838c402ae55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_length_99': 285,\n",
      " 'context_max_length': 426,\n",
      " 'context_pad_seq': 'pre',\n",
      " 'embedding_size': 300,\n",
      " 'question_length_99': 20,\n",
      " 'question_max_length': 40,\n",
      " 'question_pad_seq': 'pre',\n",
      " 'rnn_units': 256,\n",
      " 'test_shape': (26062, 16),\n",
      " 'test_span_outofrange': 0,\n",
      " 'train_shape': (78183, 16),\n",
      " 'train_span_outofrange': 0,\n",
      " 'val_shape': (26061, 16),\n",
      " 'val_span_outofrange': 0,\n",
      " 'vocab_size': 100850}\n"
     ]
    }
   ],
   "source": [
    "showparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ApNPzOsdNGMi"
   },
   "source": [
    "#### Load Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "V335qJsB19VO",
    "outputId": "2c2aeb9f-e9ca-42a7-af83-93c5f2a598ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100851, 300)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((params['vocab_size']+1,300))\n",
    "\n",
    "with open(model_path + \"glove300dembedmatrix.pkl\",\"rb\") as f:\n",
    "\n",
    "  embedding_matrix=pickle.load(f)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UmhiPPKrpCFv"
   },
   "source": [
    "#### Create TF Mirror Strategy for Multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g1TCqo4_pBkL",
    "outputId": "b33d4c7b-2e42-4bde-f851-c5c8288f03a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tLGurD9eijTh"
   },
   "source": [
    "#### Questions Bi-LSTM Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "TFxtiieuSY2J",
    "outputId": "32d3be8a-e61e-44bd-ad43-fabc97817a49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 40, 512)\n",
      "(None, 512)\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "  q_input = layers.Input(shape=(params['question_max_length'],),name=\"QUESTION_INPUT\")\n",
    "  q_emb = layers.Embedding(input_dim=params['vocab_size']+1,\n",
    "                    output_dim=params['embedding_size'],\n",
    "                    weights=[embedding_matrix], \n",
    "                    trainable=False, \n",
    "                    mask_zero=True,\n",
    "                    name=\"QUESTION_EMBEDDING\")(q_input)\n",
    "\n",
    "  # q_output0, state_h,state_c = createCUDNNLstm(units=params['rnn_units'],\n",
    "  #                                                   return_state=True,\n",
    "  #                                                   return_sequences=True,\n",
    "  #                                              dropout=0.2) (q_emb)\n",
    "\n",
    "    # encoder \n",
    "  q_output0,forward_h, forward_c,backward_h,backward_c=layers.Bidirectional(createCUDNNLstm(units=params['rnn_units'],\n",
    "                                                                   return_state=True,\n",
    "                                                                   return_sequences=True,\n",
    "                                                                   dropout=0.2),\n",
    "                                                   merge_mode='concat',\n",
    "                                                   name='QUESTION_LSTM')(q_emb)  \n",
    "\n",
    "  # dont know if add is the right approach or should be concat\n",
    "  state_h = tf.keras.layers.concatenate([forward_h,backward_h])\n",
    "\n",
    "print(q_output0.shape)\n",
    "print(state_h.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2eJ2ykC1megw"
   },
   "source": [
    "#### Context Bi-LSTM Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-glhG509P5Yh",
    "outputId": "161e2804-c99a-4a0b-fdff-1b0546c79f5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape of context  (None, 426, 512)\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "  c_input = layers.Input(shape=(params['context_max_length'],),name=\"CONTEXT_INPUT\")\n",
    "\n",
    "  # context embedding\n",
    "  c_emb = layers.Embedding(input_dim=params['vocab_size']+1,\n",
    "                    output_dim=300,\n",
    "                    weights=[embedding_matrix],trainable=False, mask_zero= True,\n",
    "                    name=\"CONTEXT_EMBEDDING\")(c_input)\n",
    "\n",
    "  c_output = layers.Bidirectional(LSTM(params['rnn_units'],\n",
    "                                       return_sequences=True,\n",
    "                                       dropout=0.2),\n",
    "                                    merge_mode='concat',\n",
    "                                    name='CONTEXT_LSTM')(c_emb)\n",
    "#c_output= tf.keras.layers.LSTM(units=params['rnn_units'],return_sequences=True)(c_emb)\n",
    "print(\"output shape of context \",c_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B4kH2VNROc2L"
   },
   "source": [
    "### 4.2 Create Attention - QUESTION TO CONTEXT Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "F_sszay-79xF",
    "outputId": "7b836932-70d8-470f-c189-50b11d701b40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 426, 40])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "  # Dot product of q_output0 and c_output\n",
    "  score = tf.keras.layers.dot([c_output, q_output0], axes=2)\n",
    "  #Pass the score through softmax layer to get the alignment matrix\n",
    "  #alignment_matrix=tf.keras.layers.Activation('softmax')(score)\n",
    "  #end_ = tf.nn.softmax(end_,axis=2,name=\"BILINEAR_AE_SOFTMAX\")\n",
    "  alignment_matrix=tf.nn.softmax(score,axis=2)\n",
    "  #alignment matrix = batch_size x max_decoder_length x max_encoder_length\n",
    "\n",
    "alignment_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K8NZNHco9JqH",
    "outputId": "b192df95-90f0-404f-da71-baec1c966ff2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 426, 512])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "  #question vector which is the q_output to the bilinear\n",
    "  question_vector=tf.keras.layers.dot([alignment_matrix,q_output0],axes=[2,1])\n",
    "  #Dimension of question_vector =  batch_size x max_decoder_length x rnn_units\n",
    "\n",
    "question_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bvsSAD_d_9EU",
    "outputId": "13d675d2-75cb-4b19-9e4e-f164749548f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 426, 512])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "  context_vector_hidden = tf.keras.layers.concatenate([c_output, \n",
    "                                                        question_vector])\n",
    "\n",
    "  attention_vector = tf.keras.layers.Dense(params['rnn_units']*2, \n",
    "                                                use_bias=False, \n",
    "                                                activation='tanh')(context_vector_hidden)  \n",
    "\n",
    "attention_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ldXt2dnSFH1K",
    "outputId": "eb1916ea-df6d-44e1-d387-44ca67497d2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 426, 512)\n",
      "(None, 426, 512)\n"
     ]
    }
   ],
   "source": [
    "print(c_output.shape)\n",
    "print(attention_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "69fAAuCkeOdD"
   },
   "source": [
    "**Bilinear Term**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "b9pDVnlAJaEL",
    "outputId": "6a1d0c5f-1c40-4913-e5f7-bdf8ea53dabc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question context shape  (None, 512)\n",
      "final o/p of context  (None, 426, 512)\n",
      "Probab shape  Tensor(\"BILINEAR_AS_AE_CONCAT:0\", shape=(None, 852), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Reference -- https://github.com/kellywzhang/reading-comprehension/blob/master/attention.py\n",
    "# bilinear term ####\n",
    "print(\"Question context shape \",state_h.shape)\n",
    "print(\"final o/p of context \",attention_vector.shape)\n",
    "\n",
    "with strategy.scope():\n",
    "  ################ start prediction ######################\n",
    "  start = layers.Dense(params['rnn_units']*2,name=\"BILINEAR_AS_SPAN\")(state_h)\n",
    "  hidden_start_time_axis = tf.expand_dims(start, 2, name='BILINEAR_AS_ADD_DIM')\n",
    "\n",
    "  # squeeze remooves time slice we added before\n",
    "  # final shape = (batch_size,decoder_timesteps)\n",
    "  start_ = tf.squeeze(tf.matmul(attention_vector,hidden_start_time_axis,name=\"BILINEAR_AS_MATMUL_Q_C\"),2,name=\"BILINEAR_AS_DEL_DIM\")\n",
    "      \n",
    "  start_ = tf.nn.softmax(start_,axis = 1,name=\"BILINEAR_AS_SOFTMAX\")\n",
    "      \n",
    "  ################ end prediction ######################\n",
    "  end = layers.Dense(params['rnn_units']*2,name=\"BILINEAR_AE_SPAN\")(state_h)\n",
    "\n",
    "  hidden_end_time_axis = tf.expand_dims(end, 2, name=\"BILINEAR_AE_ADD_DIM\")\n",
    "\n",
    "  # squeeze remooves time slice we added before\n",
    "  # final shape = (batch_size,decoder_timesteps)\n",
    "  end_ = tf.squeeze(tf.matmul(attention_vector,hidden_end_time_axis,name=\"BILINEAR_AE_MATMUL_Q_C\"),2,name=\"BILINEAR_AE_DEL_DIM\")\n",
    "  end_ = tf.nn.softmax(end_,axis=1,name=\"BILINEAR_AE_SOFTMAX\")\n",
    "\n",
    "  prob_token_span = tf.concat((start_,end_),axis = 1,name=\"BILINEAR_AS_AE_CONCAT\")\n",
    "print(\"Probab shape \",prob_token_span)\n",
    "\n",
    "\n",
    "# logits = BilinearSimilarity(UNITS)(q_cont,c_)\n",
    "# Y_prob = Prediction()(logits)\n",
    "# print(\"Logits shape \",logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9k60tb1hSfTo"
   },
   "outputs": [],
   "source": [
    "#start_ = tf.matmul(c_output,hidden_start_time_axis,name=\"BILINEAR_AS_MATMUL_Q_C\")\n",
    "#print(c_output.shape)\n",
    "#print(hidden_start_time_axis.shape)\n",
    "##c = tf.constant([[[1.0, 2.0], [3.0,2],[3.0, 4.0]]])\n",
    "#d = tf.constant([[[1.0, 1.0, 1], [0.0, 1.0, 1]]])\n",
    "#print(c)\n",
    "#print(d)\n",
    "#c = tf.constant([[[1.0, 2.0], [3.0,2],[3.0, 4.0]]])\n",
    "#d = tf.constant([[[1.0, 1.0], [0.0, 1.0], [3.0,2]]])\n",
    "#f = tf.reshape(c,[1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ibcGeRqUxzKN"
   },
   "source": [
    "**Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "vFbuhviAyX7l",
    "outputId": "3bc204cb-206b-48d1-a428-85c269bc9517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probab shape  Tensor(\"START_PROBAB:0\", shape=(None, 426), dtype=float32)\n",
      "(None, 852)\n"
     ]
    }
   ],
   "source": [
    "####### Prediction ### \n",
    "with strategy.scope():\n",
    "  token_span = 20\n",
    "  start_prob = tf.identity(prob_token_span[:,:params['context_max_length']],\n",
    "                          name=\"START_PROBAB\")\n",
    "  # start_prob.name = \"START_PROBAB\"\n",
    "\n",
    "  end_prob = tf.identity(prob_token_span[:,params['context_max_length']:],\n",
    "                        name=\"END_PROBAB\")\n",
    "  # end_prob.name = \"END_PROBAB\"\n",
    "  print(\"Probab shape \",start_prob)\n",
    "\n",
    "  # do the outer product\n",
    "  outer = tf.matmul(tf.expand_dims(start_prob, axis=2, name=\"PREDICT_AS_PROBAB\"),tf.expand_dims(end_prob, axis=1, name=\"PREDICT_AS_PROBAB\"),name=\"PREDICT_AS_AE_MATMUL\")\n",
    "\n",
    "  outer = tf.linalg.band_part(outer, 0, token_span,name=\"PREDICT_AS_AE_TOPTRIANGLE\")\n",
    "\n",
    "  # start_position will have shape of (batch_size,)\n",
    "  start_position = tf.reduce_max(outer, axis=2,name=\"PREDICT_AS_MAX\")\n",
    "  #end position will have shape of (batch_size,)\n",
    "  end_position = tf.reduce_max(outer, axis=1,name=\"PREDICT_AE_MAX\")\n",
    "\n",
    "  y_probab = tf.concat([start_position,end_position],axis=1,name=\"PREDICT_AS_AE\")\n",
    "\n",
    "print(y_probab.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PLtlPSfLxyzB"
   },
   "source": [
    "### 4.3 Custom Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tlOkeMveyCWM"
   },
   "outputs": [],
   "source": [
    "def logits_loss(y_true,logits):  \n",
    "    \"\"\"\n",
    "    Custom loss function which minimises log_loss.\n",
    "    Referance https://stackoverflow.com/questions/50063613/add-loss-function-in-keras\n",
    "    \"\"\"\n",
    "    \n",
    "    #y_true = tf.cast(y_true,dtype=tf.int32)\n",
    "    #logits = tf.cast(logits,dtype=tf.float32)\n",
    "    \n",
    "    # breaking the tensor into two half's to get start and end label.\n",
    "    start_label = y_true[:,:params['context_max_length']]\n",
    "    end_label = y_true[:,params['context_max_length']:]\n",
    "    \n",
    "    # braking the logits tensor into start and end part for loss calcultion.\n",
    "    start_logit = logits[:,:params['context_max_length']]\n",
    "    end_logit = logits[:,params['context_max_length']:]\n",
    "    \n",
    "    start_loss = tf.keras.backend.categorical_crossentropy(start_label,start_logit)\n",
    "    end_loss = tf.keras.backend.categorical_crossentropy(end_label,end_logit)\n",
    "    \n",
    "    loss = start_loss + end_loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dNiC79-tyLmq"
   },
   "source": [
    "### 4.4 Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Rv9aw2EewJbr",
    "outputId": "02867076-0e94-4cf0-99c5-d25b610a455c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "CONTEXT_INPUT (InputLayer)      [(None, 426)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "QUESTION_INPUT (InputLayer)     [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CONTEXT_EMBEDDING (Embedding)   (None, 426, 300)     30255300    CONTEXT_INPUT[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "QUESTION_EMBEDDING (Embedding)  (None, 40, 300)      30255300    QUESTION_INPUT[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "CONTEXT_LSTM (Bidirectional)    (None, 426, 512)     1140736     CONTEXT_EMBEDDING[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "QUESTION_LSTM (Bidirectional)   [(None, 40, 512), (N 1140736     QUESTION_EMBEDDING[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 426, 40)      0           CONTEXT_LSTM[0][0]               \n",
      "                                                                 QUESTION_LSTM[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softmax (TensorFlow [(None, 426, 40)]    0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 426, 512)     0           tf_op_layer_Softmax[0][0]        \n",
      "                                                                 QUESTION_LSTM[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 512)          0           QUESTION_LSTM[0][1]              \n",
      "                                                                 QUESTION_LSTM[0][3]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 426, 1024)    0           CONTEXT_LSTM[0][0]               \n",
      "                                                                 dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "BILINEAR_AS_SPAN (Dense)        (None, 512)          262656      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "BILINEAR_AE_SPAN (Dense)        (None, 512)          262656      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 426, 512)     524288      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BILINEAR_AS_ADD_DIM [(None, 512, 1)]     0           BILINEAR_AS_SPAN[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BILINEAR_AE_ADD_DIM [(None, 512, 1)]     0           BILINEAR_AE_SPAN[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BatchMatMulV2 (Tens [(None, 426, 1)]     0           dense[0][0]                      \n",
      "                                                                 tf_op_layer_BILINEAR_AS_ADD_DIM[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BatchMatMulV2_1 (Te [(None, 426, 1)]     0           dense[0][0]                      \n",
      "                                                                 tf_op_layer_BILINEAR_AE_ADD_DIM[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BILINEAR_AS_DEL_DIM [(None, 426)]        0           tf_op_layer_BatchMatMulV2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BILINEAR_AE_DEL_DIM [(None, 426)]        0           tf_op_layer_BatchMatMulV2_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BILINEAR_AS_SOFTMAX [(None, 426)]        0           tf_op_layer_BILINEAR_AS_DEL_DIM[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BILINEAR_AE_SOFTMAX [(None, 426)]        0           tf_op_layer_BILINEAR_AE_DEL_DIM[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BILINEAR_AS_AE_CONC [(None, 852)]        0           tf_op_layer_BILINEAR_AS_SOFTMAX[0\n",
      "                                                                 tf_op_layer_BILINEAR_AE_SOFTMAX[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 426)]        0           tf_op_layer_BILINEAR_AS_AE_CONCAT\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None, 426)]        0           tf_op_layer_BILINEAR_AS_AE_CONCAT\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_START_PROBAB (Tenso [(None, 426)]        0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_END_PROBAB (TensorF [(None, 426)]        0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_PREDICT_AS_PROBAB ( [(None, 426, 1)]     0           tf_op_layer_START_PROBAB[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_PREDICT_AS_PROBAB_1 [(None, 1, 426)]     0           tf_op_layer_END_PROBAB[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BatchMatMulV2_2 (Te [(None, 426, 426)]   0           tf_op_layer_PREDICT_AS_PROBAB[0][\n",
      "                                                                 tf_op_layer_PREDICT_AS_PROBAB_1[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_PREDICT_AS_AE_TOPTR [(None, 426, 426)]   0           tf_op_layer_BatchMatMulV2_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_PREDICT_AS_MAX (Ten [(None, 426)]        0           tf_op_layer_PREDICT_AS_AE_TOPTRIA\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_PREDICT_AE_MAX (Ten [(None, 426)]        0           tf_op_layer_PREDICT_AS_AE_TOPTRIA\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_PREDICT_AS_AE (Tens [(None, 852)]        0           tf_op_layer_PREDICT_AS_MAX[0][0] \n",
      "                                                                 tf_op_layer_PREDICT_AE_MAX[0][0] \n",
      "==================================================================================================\n",
      "Total params: 63,841,672\n",
      "Trainable params: 3,331,072\n",
      "Non-trainable params: 60,510,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs = [q_input,c_input],outputs =y_probab)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Biepd_j518BQ"
   },
   "source": [
    "### 4.5 Model Compile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uAqT6LWbXxWE"
   },
   "source": [
    "**Tensorboard Logs and Model compilation** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kTB5bE8I2Al-",
    "outputId": "baa97347-c43f-4b9c-d809-3faca673627c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensprflow logs  /notebooks/tensorboard-logs/lstm-baseline0\n"
     ]
    }
   ],
   "source": [
    "# using tensorboard instance for callbacks\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "log_dir = tensorboard_logpath +\"lstm-baseline0\"\n",
    "print('Tensprflow logs ',log_dir)\n",
    "tensorboard = TensorBoard(log_dir=log_dir,histogram_freq=1)\n",
    "with strategy.scope():\n",
    "  # model compilation\n",
    "  model.compile(optimizer=\"adamax\",loss=logits_loss,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4WuaPHlU8hnp"
   },
   "source": [
    "### 4.6 Generator Function for use in Model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yYIgojpb8g82"
   },
   "outputs": [],
   "source": [
    "## Reference \n",
    "def generator_function(length,batch_size = 64,data_type = 'Train'):\n",
    "    \"\"\"\n",
    "    This function is generates batches of data to avoid strain on memory.\n",
    "    \"\"\"\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    flag = True\n",
    "    if data_type == 'Val':\n",
    "        flag = False\n",
    "    n = 0\n",
    "    # loop forever over datapoints.\n",
    "    while 1:\n",
    "        for i in range(length):\n",
    "            n += 1\n",
    "            if flag:\n",
    "                X1.append(train_question_sequence[i])\n",
    "                X2.append(train_context_sequence[i])                \n",
    "                y.append(y_train[i])\n",
    "            else:\n",
    "                X1.append(val_question_sequence[i])\n",
    "                X2.append(val_context_sequence[i])                \n",
    "                y.append(y_val[i])\n",
    "            if n == batch_size:\n",
    "                yield ((array(X1),array(X2)),array(y))\n",
    "                X1,X2, y = list(), list(), list()\n",
    "                n=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vlGf9CAe-ZW-"
   },
   "source": [
    "### 4.7 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "bO-l9AhD-fPM",
    "outputId": "347d4aa4-375c-4eea-d0c0-3d3184d6cdf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_length_99': 285,\n",
      " 'context_max_length': 426,\n",
      " 'context_pad_seq': 'pre',\n",
      " 'embedding_size': 300,\n",
      " 'question_length_99': 20,\n",
      " 'question_max_length': 40,\n",
      " 'question_pad_seq': 'pre',\n",
      " 'rnn_units': 256,\n",
      " 'test_shape': (26062, 16),\n",
      " 'test_span_outofrange': 0,\n",
      " 'train_shape': (78183, 16),\n",
      " 'train_span_outofrange': 0,\n",
      " 'training.batch_size': 64,\n",
      " 'training.epochs': 25,\n",
      " 'training.train_length': 78183,\n",
      " 'training.train_steps': 1221,\n",
      " 'training.val_length': 26061,\n",
      " 'training.val_steps': 814,\n",
      " 'val_shape': (26061, 16),\n",
      " 'val_span_outofrange': 0,\n",
      " 'vocab_size': 100850}\n",
      "params.jsop updated and can be found in  /storage/models/params.json\n"
     ]
    }
   ],
   "source": [
    "params['training.epochs']=25\n",
    "params['training.batch_size']=64\n",
    "params['training.train_length']=len(y_train)\n",
    "params['training.val_length']=len(y_val)\n",
    "params['training.train_steps']=params['training.train_length']//params['training.batch_size']\n",
    "params['training.val_steps']=params['training.val_length']//32\n",
    "\n",
    "pprint.pprint(params)\n",
    "\n",
    "### SAVE PARAMS\n",
    "# Writing to sample.json \n",
    "updateparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RCDI2GTwSAdc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(filepath=model_path,\n",
    "                                            save_weights_only=True,\n",
    "                                            monitor='val_acc',\n",
    "                                            mode='max',\n",
    "                                            save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "colab_type": "code",
    "id": "dfbn-RnO_EOc",
    "outputId": "3493c774-2821-487f-f6e5-c3be4e270349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 start at time  2020-06-16 06:53:05.241846\n",
      "1198/1221 [============================>.] - ETA: 34s - accuracy: 0.4670 - loss: 7.7126WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1221/1221 [==============================] - 2121s 2s/step - accuracy: 0.4674 - loss: 7.7085 - val_accuracy: 0.4728 - val_loss: 7.7226\n",
      "Epoch 1 start at time  2020-06-16 07:28:43.463581\n",
      "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4714 - loss: 7.4231WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1221/1221 [==============================] - 2112s 2s/step - accuracy: 0.4714 - loss: 7.4231 - val_accuracy: 0.4730 - val_loss: 7.5097\n",
      "Epoch 3 start at time  2020-06-16 08:39:05.842742\n",
      "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4714 - loss: 7.3236WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1221/1221 [==============================] - 2107s 2s/step - accuracy: 0.4714 - loss: 7.3236 - val_accuracy: 0.4730 - val_loss: 7.5719\n",
      "Epoch 4 start at time  2020-06-16 09:14:14.456698\n",
      "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4715 - loss: 7.2154WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1221/1221 [==============================] - 2109s 2s/step - accuracy: 0.4715 - loss: 7.2154 - val_accuracy: 0.4728 - val_loss: 7.6682\n",
      "Epoch 5 start at time  2020-06-16 09:49:25.966801\n",
      "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4718 - loss: 7.1022WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1221/1221 [==============================] - 2111s 2s/step - accuracy: 0.4718 - loss: 7.1022 - val_accuracy: 0.4715 - val_loss: 7.8103\n",
      "Epoch 6 start at time  2020-06-16 10:24:38.170299\n",
      "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4725 - loss: 7.0034WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1221/1221 [==============================] - 2110s 2s/step - accuracy: 0.4725 - loss: 7.0034 - val_accuracy: 0.4706 - val_loss: 7.9241\n",
      "Epoch 7 start at time  2020-06-16 10:59:49.998991\n",
      "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4730 - loss: 6.9195WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1221/1221 [==============================] - 2111s 2s/step - accuracy: 0.4730 - loss: 6.9195 - val_accuracy: 0.4696 - val_loss: 8.0926\n",
      "Epoch 8 start at time  2020-06-16 11:35:02.572797\n",
      "1205/1221 [============================>.] - ETA: 23s - accuracy: 0.4735 - loss: 6.8473"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "  for i in range(params['training.epochs']):\n",
    "      print(\"Epoch {} start at time \".format(i),datetime.now())\n",
    "      \n",
    "      train_generator = generator_function(params['training.train_length'],\n",
    "                                          params['training.batch_size'])\n",
    "      \n",
    "      val_generator = generator_function(params['training.val_length'],\n",
    "                                        32,\n",
    "                                        \"Val\")\n",
    "      model.fit(x=train_generator, epochs=1, \n",
    "                          steps_per_epoch=params['training.train_steps'],\n",
    "                          verbose=1,\n",
    "                          callbacks=[model_checkpoint_callback],\n",
    "                          validation_data=val_generator,\n",
    "                          validation_steps=params['training.val_steps'])\n",
    "    \n",
    "model.save_weights(model_path + \"context_withoutstopwords_model_epoch_25_bilstm_q2c-attention.h5\")  \n",
    "# full model save\n",
    "model.save(model_path + \"full_context_withoutstopwords_model_epoch_25_bilstm_q2c-attention.h5\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kRoOUajk492o"
   },
   "source": [
    "### 4.6 Serialize and Persist Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnnjf-hX2FD7"
   },
   "outputs": [],
   "source": [
    "model.save_weights(model_path + \"context_withoutstopwords_model_epoch_24.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ELL6OBOaFud5"
   },
   "outputs": [],
   "source": [
    "# full model save\n",
    "model.save(model_path + \"full_context_withoutstopwords_model_epoch.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jl0YsArymDdF"
   },
   "source": [
    "### 4.7 Load existing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sBwGJN07mEGY"
   },
   "outputs": [],
   "source": [
    "modelname = 'context_withoutstopwords_model_epoch_24.h5'\n",
    "# modelname = 'model_epoch_24.h5'\n",
    "model.load_weights(model_path + modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5tVohk7bORpH"
   },
   "source": [
    "### 4.8 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r7pxr5yHOV6m"
   },
   "source": [
    "#### 4.8.1 Eval on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VEUBrVHN6c_"
   },
   "outputs": [],
   "source": [
    "y_prediction = model.predict([test_question_sequence,test_context_sequence])\n",
    "# print y_prediction[0] should return probabilty of of each index been a start and end token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CnVyS4ONOiNO"
   },
   "outputs": [],
   "source": [
    "# y_test was a list changing to numpy array\n",
    "y_test_fixed = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_XCfB-gOpuh"
   },
   "outputs": [],
   "source": [
    "# argmax is used to get the index where the max value in a list appears, and hence \n",
    "# for every index i, we can get the place of start and end token of the max probab\n",
    "start_pred = []\n",
    "end_pred = []\n",
    "for i in range(26062):\n",
    "    start_pred.append(np.argmax(y_prediction[i,:params['context_max_length']]))\n",
    "    end_pred.append(np.argmax(y_prediction[i,params['context_max_length']:]))\n",
    "    \n",
    "# compute for y_test though in this case it the max of 0 and 1 for \n",
    "# the frist half od array size for start, and rest for end\n",
    "start = []\n",
    "end = []\n",
    "for i in range(26062):\n",
    "    start.append(np.argmax(y_test_fixed[i,:params['context_max_length']]))\n",
    "    end.append(np.argmax(y_test_fixed[i,params['context_max_length']:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "138CmIXnR7LS",
    "outputId": "6fbfff77-86b7-42aa-c11a-cb32d53309f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[425, 36, 425, 425, 28, 19, 425, 37, 20, 9, 425, 43, 425, 80, 425, 22, 20, 48, 425, 11]\n",
      "[425, 38, 425, 425, 29, 20, 425, 37, 22, 15, 425, 56, 425, 80, 425, 25, 21, 49, 425, 13]\n"
     ]
    }
   ],
   "source": [
    "print(start[100:120])\n",
    "print(end[100:120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UPx7_OKMR8fX"
   },
   "outputs": [],
   "source": [
    "y_predicted_new = np.zeros((26062,params['context_max_length']))\n",
    "for i in range(26062):\n",
    "    y_predicted_new[i,start_pred[i]:end_pred[i]+1] = 1\n",
    "    \n",
    "y_test_new = np.zeros((26062,params['context_max_length']))\n",
    "for i in range(26062):\n",
    "    y_test_new[i,start[i]:end[i]+1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0tD4wUQ09SRb",
    "outputId": "c0e4dba1-ca98-4ada-d37e-0efad693cf22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "677"
      ]
     },
     "execution_count": 444,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test_new[testindex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v78fhG3Tdhx5"
   },
   "source": [
    "#### 4.8.2 Create a common function to predict and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v6KDfM25dhZr"
   },
   "outputs": [],
   "source": [
    "def predit_test(context, question):\n",
    "  # get sequence for context and question\n",
    "  c_ = preprocess_text(context)\n",
    "  q_ = preprocess_text(question,stopword_removal=False)\n",
    "  c,q = generate_question_context_sequence(c_, q_)  \n",
    "  y_ = model.predict([q,c])    \n",
    "  # # for i in range(26062):\n",
    "  s = np.argmax(y_[0,:params['context_max_length']])\n",
    "  e = np.argmax(y_[0,params['context_max_length']:])\n",
    "  answer = span_to_answer((s,e),c_[0])\n",
    "  \n",
    "  # print(c.shape,q.shape,y_.shape,s,e,answer)  \n",
    "  # print(s, e)\n",
    "  return c_,q_,[s,e],y_,answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNqWwnNX5EAF"
   },
   "source": [
    "##### 4.8.2.1 TEST 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "aqKrcmCae0z8",
    "outputId": "fd407491-5065-4f07-b20e-1ad3d1760daa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori c = \n",
      "('UNFPA began operations in 1969 as the United Nations Fund for Population '\n",
      " 'Activities (the name was changed in 1987) under the administration of the '\n",
      " 'United Nations Development Fund. In 1971 it was placed under the authority '\n",
      " 'of the United Nations General Assembly.')\n",
      "ori c c = \n",
      "('unfpa began operations 1969 united nations fund population activities name '\n",
      " 'changed 1987 administration united nations development fund 1971 placed '\n",
      " 'authority united nations general assembly')\n",
      "ori q =  what year did the united nations general assembly disband\n",
      "new c\n",
      "('mahayana buddha tends viewed merely human earthly projection beginningless '\n",
      " 'endless omnipresent see dharmakaya beyond range reach thought moreover '\n",
      " 'certain mahayana sutras buddha dharma sangha viewed essentially one three '\n",
      " 'seen eternal buddha')\n",
      "new q ['in what sutras are the buddha dharma and sangha viewed as one']\n",
      "predicted answer mahayana\n"
     ]
    }
   ],
   "source": [
    "c='In the Mahayana, the Buddha tends not to be viewed as merely human, but as the earthly projection of a beginningless and endless, omnipresent being (see Dharmakaya) beyond the range and reach of thought. Moreover, in certain Mahayana sutras, the Buddha, Dharma and Sangha are viewed essentially as One: all three are seen as the eternal Buddha himself.'\n",
    "q='in what sutras are the buddha dharma and sangha viewed as one'\n",
    "\n",
    "# c_,q_,span,y_,answer = predit_test(test['context'].iloc[39],test['question'].iloc[39])\n",
    "c_,q_,span,y_,answer = predit_test([c],[q])\n",
    "print('ori c = ')\n",
    "pprint.pprint(test['context'].iloc[39])\n",
    "print('ori c c = ')\n",
    "pprint.pprint(test['clean_context'].iloc[39])\n",
    "print('ori q = ',test['clean_question'].iloc[39])\n",
    "print('new c')\n",
    "pprint.pprint(c_[0])\n",
    "print('new q',q_)\n",
    "\n",
    "print('predicted answer' ,answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PEKF0GU5SZg"
   },
   "source": [
    "##### 4.8.2.2 TEST 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YnSg9CSCxy2k",
    "outputId": "8590e314-efad-4374-cfff-c745b737bad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted answer travelled\n"
     ]
    }
   ],
   "source": [
    "c = 'Mary went to the bathroom. John is in the playground.John moved to the hallway. John picked up the football.Mary travelled to the office'\n",
    "q = 'Where is john?'\n",
    "c_,q_,span,y_,answer = predit_test([c],[q])\n",
    "print('predicted answer' ,answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YUF1OjiM5Uh5"
   },
   "source": [
    "##### 4.8.2.3 TEST 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jSBOvRP90Rs9",
    "outputId": "8efcdbc2-6875-488e-df12-3edc09cf2d6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted answer ministry\n"
     ]
    }
   ],
   "source": [
    "c='The Union health ministry said that so far, 95,527 COVID-19 patients have recovered in the country.The recovery rate is now 48.07 percent, Lav Agrawal, Joint Secretary, Health Ministry claimed. We have asked all states to analyse the trajectory of the cases in their respective states. If a state thinks that it needs to set up temporary COVID-19 care centres then it must do so, he added.'\n",
    "q='what is the recovery rate'\n",
    "c_,q_,span,y_,answer = predit_test([c],[q])\n",
    "print('predicted answer' ,answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AHxti5JDP4UD"
   },
   "source": [
    "#### 4.8.3 See true vs predict for all samples in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "y9qs-no68n52",
    "outputId": "d4b94e03-b0d1-4932-b46a-e557b1295b62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ori Cont = \n",
      "('Christian missions established Western educational institutions in the '\n",
      " \"Protectorates. Under Britain's policy of indirect rule and validation of \"\n",
      " 'Islamic tradition, the Crown did not encourage the operation of Christian '\n",
      " 'missions in the northern, Islamic part of the country. Some children of the '\n",
      " 'southern elite went to Great Britain to pursue higher education. By '\n",
      " 'independence in 1960, regional differences in modern educational access were '\n",
      " 'marked. The legacy, though less pronounced, continues to the present-day. '\n",
      " \"Imbalances between North and South were expressed in Nigeria's political \"\n",
      " 'life as well. For instance, northern Nigeria did not outlaw slavery until '\n",
      " '1936 whilst in other parts of Nigeria slavery was abolished soon after '\n",
      " 'colonialism.')\n",
      "CLean Cont = \n",
      "('christian missions established western educational institutions '\n",
      " 'protectorates britains policy indirect rule validation islamic tradition '\n",
      " 'crown encourage operation christian missions northern islamic part country '\n",
      " 'children southern elite went great britain pursue higher education '\n",
      " 'independence 1960 regional differences modern educational access marked '\n",
      " 'legacy though less pronounced continues presentday imbalances north south '\n",
      " 'expressed nigerias political life well instance northern nigeria outlaw '\n",
      " 'slavery 1936 whilst parts nigeria slavery abolished soon colonialism')\n",
      "Question =  What religion built Western schools in Nigeria?\n",
      "Clean Question =  what religion built western schools in nigeria\n",
      "Answer =  Christian\n",
      "Clean Answer =  christian\n",
      "AS,AE =  (0, 0)\n",
      "pAS,pAE =  (0, 0)\n",
      "Predict answer = christian\n",
      "test data encoded  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "predict data  encoded  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "testindex = 54\n",
    "print(\"Ori Cont = \")\n",
    "pprint.pprint(test['context'].iloc[testindex])\n",
    "print(\"CLean Cont = \")\n",
    "pprint.pprint(test['clean_context'].iloc[testindex])\n",
    "print('Question = ',test['question'].iloc[testindex])\n",
    "print('Clean Question = ',test['clean_question'].iloc[testindex])\n",
    "print('Answer = ',test['answer'].iloc[testindex])\n",
    "print('Clean Answer = ',test['clean_answer'].iloc[testindex])\n",
    "print('AS,AE = ',test['answer_word_span'].iloc[testindex])\n",
    "print('pAS,pAE = ',(start_pred[testindex],end_pred[testindex]))\n",
    "print(\"Predict answer =\",span_to_answer([start_pred[testindex],end_pred[testindex]],test['clean_context'].iloc[testindex]))\n",
    "# print(\"encoded len\", len(y_train[testindex]))\n",
    "# print(\"encoded \", len(y_test[testindex]))\n",
    "print(\"test data encoded \",y_test_new[testindex])\n",
    "print(\"predict data  encoded \",y_predicted_new[testindex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DYHNErgrQILC"
   },
   "source": [
    "#### 4.8.4 Accuracy Metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "FmwzLM3WSriL",
    "outputId": "04656795-6542-4fa2-934a-58580700fb79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro f1-score on test data is  0.2751746082042751\n",
      "Macro f1-score on test data is  0.00583615881279302\n",
      "Accuracy on test data is  0.3761798787506715\n",
      "params.jsop updated and can be found in  /content/drive/My Drive/AIML-MRC-Capstone/models/params.json\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score\n",
    "params['prediction.accuracy.score'] = accuracy_score(y_test_new,y_predicted_new)\n",
    "params['prediction.macrof1.score'] = f1_score(y_test_new,y_predicted_new,average=\"macro\")\n",
    "params['prediction.microf1.score'] = f1_score(y_test_new,y_predicted_new,average=\"micro\")\n",
    "\n",
    "print(\"Micro f1-score on test data is \",params['prediction.microf1.score'])\n",
    "print(\"Macro f1-score on test data is \",params['prediction.macrof1.score'])\n",
    "print(\"Accuracy on test data is \",params['prediction.accuracy.score'])\n",
    "\n",
    "# update params\n",
    "updateparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "RY02U6dQSCMU",
    "outputId": "7bc096c4-caf0-46fe-c375-67ea2c3538b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_length_99': 285,\n",
      " 'context_max_length': 426,\n",
      " 'context_pad_seq': 'pre',\n",
      " 'embedding_size': 100,\n",
      " 'prediction.accuracy.score': 0.3761798787506715,\n",
      " 'prediction.macrof1.score': 0.00583615881279302,\n",
      " 'prediction.microf1.score': 0.2751746082042751,\n",
      " 'question_length_99': 20,\n",
      " 'question_max_length': 40,\n",
      " 'question_pad_seq': 'pre',\n",
      " 'rnn_units': 256,\n",
      " 'test_shape': (26062, 16),\n",
      " 'test_span_outofrange': 0,\n",
      " 'tokenizer_num_words': 80000,\n",
      " 'train_shape': (78183, 16),\n",
      " 'train_span_outofrange': 0,\n",
      " 'training.batch_size': 64,\n",
      " 'training.epochs': 25,\n",
      " 'training.train_length': 78183,\n",
      " 'training.train_steps': 1221,\n",
      " 'training.val_length': 26061,\n",
      " 'training.val_steps': 814,\n",
      " 'val_shape': (26061, 16),\n",
      " 'val_span_outofrange': 0,\n",
      " 'vocab_size': 100850}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rI40rd0bQZgn"
   },
   "source": [
    "#### 4.8.5 Store the result to build more meterics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p5T9BSNgS-uG"
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "summary = PrettyTable()\n",
    "summary.title = \"Test vs Prediction\"\n",
    "summary.field_names = [\"ID\",\n",
    "                       \"Clean Question\",\n",
    "                       \"Clean Context\",\n",
    "                       \"True Answer\",\n",
    "                       \"True AS and AE\",\n",
    "                       \"Predict Answer\",\n",
    "                       \"Predict AS and AE\"]\n",
    "result_df = pd.DataFrame(columns=summary.field_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6TdUqImSC1_I",
    "outputId": "c1d50f85-940a-4bf5-9343-c3ed51ad9ed8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26062/26062 [02:03<00:00, 211.71it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(26062)):  \n",
    "  values = [test['id'].iloc[i], \n",
    "            test['clean_question'].iloc[i], \n",
    "            test['clean_context'].iloc[i], \n",
    "            test['clean_answer'].iloc[i], \n",
    "            test['answer_word_span'].iloc[i],\n",
    "            span_to_answer([start_pred[i],end_pred[i]],test['clean_context'].iloc[i]),\n",
    "            (start_pred[i],end_pred[i])]\n",
    "  zipped = zip(summary.field_names, values)\n",
    "  a_dictionary = dict(zipped)\n",
    "  result_df = result_df.append(a_dictionary,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "TySMZHmbJB1r",
    "outputId": "507594a5-738a-48c6-d281-8fd8297427f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Clean Question</th>\n",
       "      <th>Clean Context</th>\n",
       "      <th>True Answer</th>\n",
       "      <th>True AS and AE</th>\n",
       "      <th>Predict Answer</th>\n",
       "      <th>Predict AS and AE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>572710d0f1498d1400e8f2ed</td>\n",
       "      <td>who is originally claimed to have given birth ...</td>\n",
       "      <td>nutritionism view excessive reliance food scie...</td>\n",
       "      <td>gyorgy scrinis</td>\n",
       "      <td>(15, 16)</td>\n",
       "      <td>rely</td>\n",
       "      <td>(25, 25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56f8cc7b9e9bad19000a0520</td>\n",
       "      <td>the neocerebellum supports what other part of ...</td>\n",
       "      <td>elaboration cerebral cortex carries changes br...</td>\n",
       "      <td>cerebral cortex</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td></td>\n",
       "      <td>(425, 425)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570d9e64df2f5219002ed063</td>\n",
       "      <td>what is the hmmwv also known as</td>\n",
       "      <td>armys common vehicle high mobility multipurpos...</td>\n",
       "      <td>humvee</td>\n",
       "      <td>(11, 11)</td>\n",
       "      <td>armys</td>\n",
       "      <td>(0, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56d1070517492d1400aab77a</td>\n",
       "      <td>what was a notable 20th century gang in new york</td>\n",
       "      <td>organized crime long associated new york city ...</td>\n",
       "      <td>the black spades</td>\n",
       "      <td>(-1, -1)</td>\n",
       "      <td></td>\n",
       "      <td>(425, 425)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56fb7df48ddada1400cd6481</td>\n",
       "      <td>along with len portugal aragon and castile wha...</td>\n",
       "      <td>iberia christian states confined northwestern ...</td>\n",
       "      <td>navarre</td>\n",
       "      <td>(26, 26)</td>\n",
       "      <td>iberia</td>\n",
       "      <td>(0, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ID  ... Predict AS and AE\n",
       "0  572710d0f1498d1400e8f2ed  ...          (25, 25)\n",
       "1  56f8cc7b9e9bad19000a0520  ...        (425, 425)\n",
       "2  570d9e64df2f5219002ed063  ...            (0, 0)\n",
       "3  56d1070517492d1400aab77a  ...        (425, 425)\n",
       "4  56fb7df48ddada1400cd6481  ...            (0, 0)\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.to_csv(model_path + \"results.csv\")  \n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kCKNvmOaQtx_"
   },
   "source": [
    "## 5 More Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b2emUc95Q53a"
   },
   "source": [
    "**Read the result dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "geCm-V3SQ0v7"
   },
   "outputs": [],
   "source": [
    "result_df = result_df.read_csv(model_path + \"results.csv\")  \n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mz6uetkTRLrz"
   },
   "source": [
    "### 5.1 EM (Exact Match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "colab_type": "code",
    "id": "5uTD7fZZUhyw",
    "outputId": "34b2bd42-610a-4f2b-a5aa-777929a202a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Clean Question</th>\n",
       "      <th>Clean Context</th>\n",
       "      <th>True Answer</th>\n",
       "      <th>True AS and AE</th>\n",
       "      <th>Predict Answer</th>\n",
       "      <th>Predict AS and AE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5726d4895951b619008f7f5f</td>\n",
       "      <td>what religion built western schools in nigeria</td>\n",
       "      <td>christian missions established western educati...</td>\n",
       "      <td>christian</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>christian</td>\n",
       "      <td>(0, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5725f32589a1e219009ac0e8</td>\n",
       "      <td>what year did the cubs record a major league r...</td>\n",
       "      <td>1906 franchise recorded major league record 11...</td>\n",
       "      <td>1906</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>1906</td>\n",
       "      <td>(0, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>5731e2a6e99e3014001e63b8</td>\n",
       "      <td>how many floors does the alvorada have</td>\n",
       "      <td>palcio da alvorada official residence presiden...</td>\n",
       "      <td>three</td>\n",
       "      <td>(57, 57)</td>\n",
       "      <td>three</td>\n",
       "      <td>(57, 57)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>56f715e43d8e2e1400e3732c</td>\n",
       "      <td>when did the second yugoslavia start</td>\n",
       "      <td>tito chief architect second yugoslavia sociali...</td>\n",
       "      <td>1943</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>1943</td>\n",
       "      <td>(8, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>57298be2af94a219006aa4f7</td>\n",
       "      <td>what sound volume is produced by coleoptera</td>\n",
       "      <td>low sounds also produced various species coleo...</td>\n",
       "      <td>low</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>low</td>\n",
       "      <td>(0, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25543</th>\n",
       "      <td>5733a3cbd058e614000b5f41</td>\n",
       "      <td>in what year did the college of arts and lette...</td>\n",
       "      <td>college arts letters established universitys f...</td>\n",
       "      <td>1849</td>\n",
       "      <td>(11, 11)</td>\n",
       "      <td>1849</td>\n",
       "      <td>(11, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25584</th>\n",
       "      <td>5728c1a84b864d1900164d6b</td>\n",
       "      <td>what name literally means farshooting</td>\n",
       "      <td>god archery apollo known aphetor fitr feetr ap...</td>\n",
       "      <td>hecargus</td>\n",
       "      <td>(22, 22)</td>\n",
       "      <td>hecargus</td>\n",
       "      <td>(22, 22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25598</th>\n",
       "      <td>5726831df1498d1400e8e238</td>\n",
       "      <td>what compression cannot attain high compressio...</td>\n",
       "      <td>lossless audio compression produces representa...</td>\n",
       "      <td>lossless</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>lossless</td>\n",
       "      <td>(0, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25734</th>\n",
       "      <td>572fe604a23a5019007fcb01</td>\n",
       "      <td>when was san diegos current charter adopted</td>\n",
       "      <td>state california admitted united states 1850 y...</td>\n",
       "      <td>1931</td>\n",
       "      <td>(52, 52)</td>\n",
       "      <td>1931</td>\n",
       "      <td>(52, 52)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25913</th>\n",
       "      <td>56d4c13d2ccc5a1400d831d2</td>\n",
       "      <td>what year was it decided that if wolves and do...</td>\n",
       "      <td>2003 iczn ruled opinion 2027 wild animals dome...</td>\n",
       "      <td>2003</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>2003</td>\n",
       "      <td>(0, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ID  ... Predict AS and AE\n",
       "54     5726d4895951b619008f7f5f  ...            (0, 0)\n",
       "77     5725f32589a1e219009ac0e8  ...            (0, 0)\n",
       "356    5731e2a6e99e3014001e63b8  ...          (57, 57)\n",
       "432    56f715e43d8e2e1400e3732c  ...            (8, 8)\n",
       "440    57298be2af94a219006aa4f7  ...            (0, 0)\n",
       "...                         ...  ...               ...\n",
       "25543  5733a3cbd058e614000b5f41  ...          (11, 11)\n",
       "25584  5728c1a84b864d1900164d6b  ...          (22, 22)\n",
       "25598  5726831df1498d1400e8e238  ...            (0, 0)\n",
       "25734  572fe604a23a5019007fcb01  ...          (52, 52)\n",
       "25913  56d4c13d2ccc5a1400d831d2  ...            (0, 0)\n",
       "\n",
       "[180 rows x 7 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[result_df['Predict Answer'] == result_df['True Answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rm4YmnfQNqQC"
   },
   "outputs": [],
   "source": [
    "ematch = result_df[result_df['Predict Answer'] == result_df['True Answer']].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BF44727PN1dq",
    "outputId": "4612d5f0-2b6a-4cea-d584-ed9cfda9871b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params.jsop updated and can be found in  /content/drive/My Drive/AIML-MRC-Capstone/models/params.json\n"
     ]
    }
   ],
   "source": [
    "params['prediction.em.score'] = ematch / params['test_shape'][0]\n",
    "updateparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "ZbO5yYzRTTyu",
    "outputId": "89f7b537-b591-4575-e5c4-4efb7b9b1183"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_length_99': 285,\n",
      " 'context_max_length': 426,\n",
      " 'context_pad_seq': 'pre',\n",
      " 'embedding_size': 100,\n",
      " 'prediction.accuracy.score': 0.3761798787506715,\n",
      " 'prediction.em.score': 0.00690660732100376,\n",
      " 'prediction.macrof1.score': 0.00583615881279302,\n",
      " 'prediction.microf1.score': 0.2751746082042751,\n",
      " 'question_length_99': 20,\n",
      " 'question_max_length': 40,\n",
      " 'question_pad_seq': 'pre',\n",
      " 'rnn_units': 256,\n",
      " 'test_shape': (26062, 16),\n",
      " 'test_span_outofrange': 0,\n",
      " 'tokenizer_num_words': 80000,\n",
      " 'train_shape': (78183, 16),\n",
      " 'train_span_outofrange': 0,\n",
      " 'training.batch_size': 64,\n",
      " 'training.epochs': 25,\n",
      " 'training.train_length': 78183,\n",
      " 'training.train_steps': 1221,\n",
      " 'training.val_length': 26061,\n",
      " 'training.val_steps': 814,\n",
      " 'val_shape': (26061, 16),\n",
      " 'val_span_outofrange': 0,\n",
      " 'vocab_size': 100850}\n"
     ]
    }
   ],
   "source": [
    "showparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vlR2BYOT66Lk"
   },
   "source": [
    "# **<font color=\"GREEN\">END OF THE NOTEBOOK </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6u50QkJn6-om"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "mrc_biLSTM_attention.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
