{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mrc_DeepLSTM_.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandipanbasu/aiml-capstone/blob/master/mrc_DeepLSTM_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "879mz4G6-lRH"
      },
      "source": [
        "## 1. Import Libraries, setting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DA8sHlEbfYnn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a4d8f180-4798-4585-a29b-f8656e3365ed"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u_po1L9T-V5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b58d9e8c-abf2-43e8-c037-1daa15cef281"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yTDFtsEtV7dY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "66296e2e-69ec-4422-eaef-e9ca80f38c56"
      },
      "source": [
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "tf.debugging.set_log_device_placement(True)\n",
        "import pickle\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pprint\n",
        "from tensorflow.keras.layers import Bidirectional,LSTM,Dense,Dropout,BatchNormalization,Flatten,Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from numpy import array\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uPD8_fgd8PhR",
        "colab": {}
      },
      "source": [
        "# we will store the params as we go along in this object\n",
        "params = {}\n",
        "project_path = \"/content/drive/My Drive/AIML-MRC-Capstone/datasets/Squad2.0/TrainingDataset/\"\n",
        "model_path = \"/content/drive/My Drive/AIML-MRC-Capstone/models/\"\n",
        "tensorboard_logpath  = \"/content/drive/My Drive/AIML-MRC-Capstone/models/tensorboard-logs/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwMtV5KsEInK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## FOR PAPERSPACE\n",
        "# we will store the params as we go along in this object\n",
        "params = {}\n",
        "project_path = \"/storage/\"\n",
        "model_path = \"/storage/models/\"\n",
        "model_name = \"deeplstm\"\n",
        "tensorboard_logpath  = \"/notebooks/tensorboard-logs/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "09eGk3oWWCaP"
      },
      "source": [
        "# Objective - Deep (or Stacked) LSTM \n",
        "\n",
        "*   **Inputs: A question q = {q1, ..., qQ} of length Q and a context paragraph p = {p1, ..., pP } of length P.**\n",
        "*   **Output: An answer span {as, ae} where as is the index of the first answer token in p, ae is the index of the last answer token in p, 0 <= as, ae >= m, and ae >= as.** \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C-TACUiuOCJw"
      },
      "source": [
        "## 0 Common Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XtBcy2Qwm2-c"
      },
      "source": [
        "#### 0.1 Custom function for preprocessing of context and question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LFr3-S_Gm9FX",
        "colab": {}
      },
      "source": [
        "# remove unwanted chars\n",
        "# convert to lowercase\n",
        "# remove unwanted spaces\n",
        "# remove stop words\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "## reference \n",
        "def decontracted(phrase):\n",
        "    \"\"\"\n",
        "    This function remooves punctuation from given sentence.\n",
        "    \"\"\"\n",
        "\n",
        "    if(phrase is np.nan):\n",
        "      return 'impossible'      \n",
        "\n",
        "    try:      \n",
        "      # specific\n",
        "      phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "      phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "      # general\n",
        "      phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "      phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "      phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "      phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "      phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "      phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "      phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "      phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "      \n",
        "      # string operation\n",
        "      phrase = phrase.replace('\\\\r', ' ')\n",
        "      phrase = phrase.replace('\\\\\"', ' ')\n",
        "      phrase = phrase.replace('\\\\n', ' ')\n",
        "\n",
        "      phrase = re.sub('[^A-Za-z0-9]+', ' ', phrase.lower())\n",
        "    except:\n",
        "      print(phrase)  \n",
        "    \n",
        "    return phrase\n",
        "\n",
        "def preprocess_text(corpus, text_lower_case=True, \n",
        "                      special_char_removal=True, stopword_removal=True, remove_digits=False):    \n",
        "    normalized_text = []\n",
        "    # normalize each document in the corpus\n",
        "    for doc in corpus:\n",
        "        # doc = decontracted(doc)\n",
        "        # lowercase the text    \n",
        "        if text_lower_case:\n",
        "            doc = doc.lower()\n",
        "        # remove special characters and\\or digits    \n",
        "        if special_char_removal:\n",
        "            # insert spaces between special characters to isolate them    \n",
        "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
        "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
        "            doc = remove_special_characters(doc, remove_digits=remove_digits) \n",
        "\n",
        "        if stopword_removal:\n",
        "            doc = remove_stopwords(doc)\n",
        "\n",
        "        normalized_text.append(doc)\n",
        "        \n",
        "    return normalized_text\n",
        "\n",
        "def remove_special_characters(text, remove_digits=False):\n",
        "    #Using regex\n",
        "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "def remove_stopwords(text):  \n",
        "    word_tokens = word_tokenize(text) \n",
        "    filtered_sentence = [w for w in word_tokens if not w in stop_words]   \n",
        "    filtered_sentence = [] \n",
        "    for w in word_tokens: \n",
        "        if w not in stop_words: \n",
        "            filtered_sentence.append(w)                 \n",
        "    return ' '.join(filtered_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "20-D8HBeOf_p"
      },
      "source": [
        "### 0.2 Answer Span from Context and Answer, and reverse for predicted spans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vbM8z2AEjxKK",
        "colab": {}
      },
      "source": [
        "def tokenize(sentence):\n",
        "    \"\"\"\n",
        "    Returns tokenised words.\n",
        "    \"\"\"\n",
        "    return nltk.word_tokenize(sentence)\n",
        "\n",
        "def answer_span(context,ans):\n",
        "    \"\"\"\n",
        "    This funtion returns anwer span start index and end index.\n",
        "    \"\"\"\n",
        "    ans_token = tokenize(ans)\n",
        "    con_token = tokenize(context)\n",
        "    ans_len = len(ans_token)\n",
        "    \n",
        "    if ans_len!=0 and ans_token[0] in con_token:\n",
        "    \n",
        "        indices = [i for i, x in enumerate(con_token) if x == ans_token[0]]        \n",
        "        try:\n",
        "\n",
        "            if(len(indices)>1):\n",
        "                start = [i for i in indices if (con_token[i:i+ans_len] == ans_token) ]\n",
        "                end = start[0] + ans_len - 1\n",
        "                return start[0],end\n",
        "\n",
        "            else:\n",
        "                start = con_token.index(ans_token[0])\n",
        "                end = start + ans_len - 1\n",
        "                return start,end\n",
        "        except:\n",
        "            return -1,-1\n",
        "    else:\n",
        "        return -1,-1\n",
        "\n",
        "def span_to_answer(span, context):\n",
        "  con_token = tokenize(context)  \n",
        "  return ' '.join(con_token[span[0]:span[1]+1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_sveyxKK5j8q"
      },
      "source": [
        "### 0.3 Update and persist params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K170rfN15qGP",
        "colab": {}
      },
      "source": [
        "### SAVE PARAMS\n",
        "# Writing to sample.json \n",
        "\n",
        "def updateparams():\n",
        "  with open(model_path + \"params.json\", \"w\") as p: \n",
        "    p.write(json.dumps(params))\n",
        "  print(\"params.jsop updated and can be found in \", model_path + \"params.json\")  \n",
        "\n",
        "# updateparams()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yYMDmMJNU9mw",
        "colab": {}
      },
      "source": [
        "def showparams():\n",
        "  pprint.pprint(params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hxuHGmpRMBHT"
      },
      "source": [
        "## 1 Context, Answer EDA "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6tWRDHA6z_Ji"
      },
      "source": [
        "**<font color=\"red\">BE CAREFUL BEFORE EXECUTING THIS PLEASE. THERE IS HIGH CHANCE THAT THIS WILL OVERWRITE EXISTING DATAFRAMES</font>** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JsuZ3NdiMOiB",
        "colab": {}
      },
      "source": [
        "squad_df = pd.read_csv(project_path+'squad_data_final_withstopword_withpunctuation.csv')\n",
        "squad_df.drop('Unnamed: 0',axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vps2_zIB7q7i",
        "colab": {}
      },
      "source": [
        "### specific cleaning of context and question\n",
        "### DO NOT REMOVE STOP WORDS \n",
        "###\n",
        "squad_df['clean_context'] = preprocess_text(squad_df['context'],stopword_removal=False, special_char_removal=False)\n",
        "squad_df['clean_question'] = preprocess_text(squad_df['question'],stopword_removal=False, special_char_removal=False)\n",
        "# "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pZ5CD4fzCPcj",
        "colab": {}
      },
      "source": [
        "squad_df['clean_answer'] = preprocess_text(squad_df['answer'],stopword_removal=False, special_char_removal = False)\n",
        "\n",
        "# preprocess_text([squad_df['answer'].iloc[23]],stopword_removal=False, special_char_removal = False)\n",
        "# preprocess_text([np.nan],stopword_removal=False, special_char_removal = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UgrKpCLgC8q-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "381d3afc-8e27-42fc-9cf4-2c67356096d3"
      },
      "source": [
        "squad_df.head(6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>id</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer</th>\n",
              "      <th>plausible_answer_start</th>\n",
              "      <th>plausible_answer</th>\n",
              "      <th>is_impossible</th>\n",
              "      <th>clean_context</th>\n",
              "      <th>clean_question</th>\n",
              "      <th>clean_answer</th>\n",
              "      <th>answer_len</th>\n",
              "      <th>answer_end</th>\n",
              "      <th>answer_span</th>\n",
              "      <th>answer_word_span</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>56be85543aeaaa14008c9063</td>\n",
              "      <td>269</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>beyonc giselle knowles carter bi j nse bee yon...</td>\n",
              "      <td>when did beyonce start becoming popular</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>17</td>\n",
              "      <td>286</td>\n",
              "      <td>(269, 286)</td>\n",
              "      <td>(44, 47)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>56be85543aeaaa14008c9065</td>\n",
              "      <td>207</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>beyonc giselle knowles carter bi j nse bee yon...</td>\n",
              "      <td>what areas did beyonce compete in when she was...</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>19</td>\n",
              "      <td>226</td>\n",
              "      <td>(207, 226)</td>\n",
              "      <td>(33, 35)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>56be85543aeaaa14008c9066</td>\n",
              "      <td>526</td>\n",
              "      <td>2003</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>beyonc giselle knowles carter bi j nse bee yon...</td>\n",
              "      <td>when did beyonce leave destiny is child and be...</td>\n",
              "      <td>2003</td>\n",
              "      <td>4</td>\n",
              "      <td>530</td>\n",
              "      <td>(526, 530)</td>\n",
              "      <td>(93, 93)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>In what city and state did Beyonce  grow up?</td>\n",
              "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
              "      <td>166</td>\n",
              "      <td>Houston, Texas</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>beyonc giselle knowles carter bi j nse bee yon...</td>\n",
              "      <td>in what city and state did beyonce grow up</td>\n",
              "      <td>houston texas</td>\n",
              "      <td>13</td>\n",
              "      <td>179</td>\n",
              "      <td>(166, 179)</td>\n",
              "      <td>(27, 28)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>In which decade did Beyonce become famous?</td>\n",
              "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
              "      <td>276</td>\n",
              "      <td>late 1990s</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>beyonc giselle knowles carter bi j nse bee yon...</td>\n",
              "      <td>in which decade did beyonce become famous</td>\n",
              "      <td>late 1990s</td>\n",
              "      <td>10</td>\n",
              "      <td>286</td>\n",
              "      <td>(276, 286)</td>\n",
              "      <td>(46, 47)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>In what R&amp;B group was she the lead singer?</td>\n",
              "      <td>56bf6b0f3aeaaa14008c9603</td>\n",
              "      <td>320</td>\n",
              "      <td>Destiny's Child</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>beyonc giselle knowles carter bi j nse bee yon...</td>\n",
              "      <td>in what r b group was she the lead singer</td>\n",
              "      <td>destiny is child</td>\n",
              "      <td>14</td>\n",
              "      <td>334</td>\n",
              "      <td>(320, 334)</td>\n",
              "      <td>(56, 58)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     title  ... answer_word_span\n",
              "0  Beyoncé  ...         (44, 47)\n",
              "1  Beyoncé  ...         (33, 35)\n",
              "2  Beyoncé  ...         (93, 93)\n",
              "3  Beyoncé  ...         (27, 28)\n",
              "4  Beyoncé  ...         (46, 47)\n",
              "5  Beyoncé  ...         (56, 58)\n",
              "\n",
              "[6 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jhUog7nH_uqL",
        "colab": {}
      },
      "source": [
        "ans_span = []\n",
        "for i in range(len(squad_df)):\n",
        "    s,e = answer_span(squad_df[\"clean_context\"].iloc[i],squad_df[\"clean_answer\"].iloc[i])\n",
        "    ans_span.append((s,e))\n",
        "\n",
        "squad_df[\"answer_word_span\"] = ans_span    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BpMnsnfCIqh1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "664eb3b0-179e-4063-c638-4deb57068883"
      },
      "source": [
        "# check no of right answer span detection \n",
        "print(squad_df[squad_df[\"answer_word_span\"] == (-1,-1)].shape)\n",
        "print(squad_df[squad_df['clean_answer'] == 'impossible' ].shape)\n",
        "\n",
        "print('No of records which does not have answer but span not found in context = ', \n",
        "      squad_df[(squad_df['clean_answer'] != 'impossible') & (squad_df[\"answer_word_span\"] == (-1,-1))].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 16)\n",
            "(43502, 16)\n",
            "No of records which does not have answer but span not found in context =  (0, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XK2rwLdg9Aqq",
        "colab": {}
      },
      "source": [
        "# write the latest greatet\n",
        "squad_df.to_csv(project_path+'squad_data_final.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wYRTJ6qX9kRj",
        "colab": {}
      },
      "source": [
        "squad_df.head(25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ltvYXgi07_p2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d373fc87-1564-427d-d301-2f2392144c6a"
      },
      "source": [
        "pprint.pprint(squad_df['clean_context'].iloc[39])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('beyonc giselle knowles was born in houston texas to celestine ann tina '\n",
            " 'knowles n e beyinc a hairdresser and salon owner and mathew knowles a xerox '\n",
            " 'sales manager beyonc is name is a tribute to her mother is maiden name '\n",
            " 'beyonc is younger sister solange is also a singer and a former member of '\n",
            " 'destiny is child mathew is african american while tina is of louisiana '\n",
            " 'creole descent with african native american french cajun and distant irish '\n",
            " 'and spanish ancestry through her mother beyonc is a descendant of acadian '\n",
            " 'leader joseph broussard she was raised in a methodist household ')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mGZp4iLEHE8n"
      },
      "source": [
        "## 2 Load Squad Data - Cleaned and curated (output of preprocessing step)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZAP5oLWEkU0",
        "colab_type": "text"
      },
      "source": [
        "**<font color=red>REFER TO CREATE TEST UTIL NOTEBOOK FOR COMMON DATA LOAD FUNCTION</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CFPpoxl7Afls"
      },
      "source": [
        "### 2.1 Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4_u1n8G3fge_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "3f6619a8-e8aa-4fe4-a957-57f1c4b6ce79"
      },
      "source": [
        "# #### NOTE THE 2 data frames's\n",
        "# df_nostopwords = 'squad_data_final_context_withoutstopwords.csv'\n",
        "# # df_withstopwords = 'squad_data_final_withstopword_withpunctuation.csv'\n",
        "# squad_df = pd.read_csv(project_path+'squad_data_final_context_withoutstopwords.csv')\n",
        "# squad_df.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "\n",
        "\n",
        "# squad_df[\"answer_word_span\"] = squad_df[\"answer_word_span\"].apply(lambda x :eval(x))\n",
        "# print(squad_df.info())\n",
        "# print(squad_df['clean_context'].iloc[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 130306 entries, 0 to 130305\n",
            "Data columns (total 16 columns):\n",
            " #   Column                  Non-Null Count   Dtype  \n",
            "---  ------                  --------------   -----  \n",
            " 0   title                   130306 non-null  object \n",
            " 1   context                 130306 non-null  object \n",
            " 2   question                130306 non-null  object \n",
            " 3   id                      130306 non-null  object \n",
            " 4   answer_start            130306 non-null  int64  \n",
            " 5   answer                  86807 non-null   object \n",
            " 6   plausible_answer_start  43498 non-null   float64\n",
            " 7   plausible_answer        43498 non-null   object \n",
            " 8   is_impossible           130306 non-null  bool   \n",
            " 9   clean_context           130306 non-null  object \n",
            " 10  clean_question          130306 non-null  object \n",
            " 11  clean_answer            130306 non-null  object \n",
            " 12  answer_len              130306 non-null  int64  \n",
            " 13  answer_end              130306 non-null  int64  \n",
            " 14  answer_span             130306 non-null  object \n",
            " 15  answer_word_span        130306 non-null  object \n",
            "dtypes: bool(1), float64(1), int64(3), object(11)\n",
            "memory usage: 15.0+ MB\n",
            "None\n",
            "beyonc giselle knowlescarter bijnse beeyonsay born september 4 1981 american singer songwriter record producer actress born raised houston texas performed various singing dancing competitions child rose fame late 1990s lead singer rb girlgroup destinys child managed father mathew knowles group became one worlds bestselling girl groups time hiatus saw release beyoncs debut album dangerously love 2003 established solo artist worldwide earned five grammy awards featured billboard hot 100 numberone singles crazy love baby boy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uJ_KUPvezIOi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "12becdf2-cbb6-4a16-efed-1d154ce9a9e4"
      },
      "source": [
        "squad_df.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>id</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer</th>\n",
              "      <th>plausible_answer_start</th>\n",
              "      <th>plausible_answer</th>\n",
              "      <th>is_impossible</th>\n",
              "      <th>clean_context</th>\n",
              "      <th>clean_question</th>\n",
              "      <th>clean_answer</th>\n",
              "      <th>answer_len</th>\n",
              "      <th>answer_end</th>\n",
              "      <th>answer_span</th>\n",
              "      <th>answer_word_span</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>56be85543aeaaa14008c9063</td>\n",
              "      <td>269</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>beyonc giselle knowlescarter bijnse beeyonsay ...</td>\n",
              "      <td>when did beyonce start becoming popular</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>17</td>\n",
              "      <td>286</td>\n",
              "      <td>(269, 286)</td>\n",
              "      <td>(-1, -1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>56be85543aeaaa14008c9065</td>\n",
              "      <td>207</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>beyonc giselle knowlescarter bijnse beeyonsay ...</td>\n",
              "      <td>what areas did beyonce compete in when she was...</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>19</td>\n",
              "      <td>226</td>\n",
              "      <td>(207, 226)</td>\n",
              "      <td>(21, 23)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>56be85543aeaaa14008c9066</td>\n",
              "      <td>526</td>\n",
              "      <td>2003</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>beyonc giselle knowlescarter bijnse beeyonsay ...</td>\n",
              "      <td>when did beyonce leave destinys child and beco...</td>\n",
              "      <td>2003</td>\n",
              "      <td>4</td>\n",
              "      <td>530</td>\n",
              "      <td>(526, 530)</td>\n",
              "      <td>(55, 55)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     title  ... answer_word_span\n",
              "0  Beyoncé  ...         (-1, -1)\n",
              "1  Beyoncé  ...         (21, 23)\n",
              "2  Beyoncé  ...         (55, 55)\n",
              "\n",
              "[3 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U35P3ZvGAQQD"
      },
      "source": [
        "### 2.2 Load Train, Validation and Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7M9hW4xy-Suj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f02b4395-d982-4b82-b5a4-d97350281898"
      },
      "source": [
        "train = pd.read_csv(model_path +'train-withoutstopwords.csv')\n",
        "train.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "train[\"answer_word_span\"] = train[\"answer_word_span\"].apply(lambda x :eval(x))\n",
        "\n",
        "val = pd.read_csv(model_path +'val-withoutstopwords.csv')\n",
        "val.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "val[\"answer_word_span\"] = val[\"answer_word_span\"].apply(lambda x :eval(x))\n",
        "\n",
        "test = pd.read_csv(model_path +'test-withoutstopwords.csv')\n",
        "test.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "test[\"answer_word_span\"] = test[\"answer_word_span\"].apply(lambda x :eval(x))\n",
        "\n",
        "print(train.shape)\n",
        "print(val.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(78183, 16)\n",
            "(26061, 16)\n",
            "(26062, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y6dcPCGiJrz1"
      },
      "source": [
        "### 2.3 Load Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hxoMIrC6EIgS",
        "colab": {}
      },
      "source": [
        "# from tqdm import tqdm\n",
        "# params['tokenizer_num_words'] = 80000\n",
        "# tokenizer = preprocessing.text.Tokenizer(num_words=params['tokenizer_num_words'])\n",
        "\n",
        "# # NOTE: tokenizer is been made out of original dataset\n",
        "# for text in tqdm([squad_df['clean_context'], squad_df['clean_question']]):  \n",
        "#   tokenizer.fit_on_texts(text.values)\n",
        "\n",
        "# # total tokenizer words\n",
        "# params['vocab_size'] = len(tokenizer.word_index)\n",
        "\n",
        "# ### SAVE TOKENIZERS\n",
        "# with open(model_path + \"tokenizer.pkl\",\"wb\") as f:\n",
        "#     pickle.dump(tokenizer,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "56CH_5FcfTsV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f026ce0c-6a79-46fe-942a-a028f6af8b4f"
      },
      "source": [
        "with open(model_path + \"tokenizer.pkl\",\"rb\") as infile:\n",
        "    tokenizer = pickle.load(infile)\n",
        "\n",
        "len(tokenizer.word_index)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100850"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y7fIbj3tatHH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae67bf1b-c4d2-47c9-8311-eb109589aecd"
      },
      "source": [
        "tokenizer.word_index['how']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7gXSy_y36IFb"
      },
      "source": [
        "### 2.4 Update parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2whUHcmX5PwS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "7b67e9d1-6f3f-485d-ec35-787d5ff4287c"
      },
      "source": [
        "# From the EDA and historgrams we can conclude that - \n",
        "# 99% percentile of context word length = 285\n",
        "# 99% percentile or question word lengt = 20\n",
        "context_length = 285\n",
        "question_length = 20\n",
        "params['train_shape'] = train.shape\n",
        "params['val_shape'] = val.shape\n",
        "params['test_shape'] = test.shape\n",
        "params['context_length_99'] = context_length # initialize with a high percentile\n",
        "params['question_length_99'] = question_length # initialize with a high percentile\n",
        "params['embedding_size'] = 300\n",
        "params['rnn_units'] = 256\n",
        "params['context_pad_seq'] = 'pre'\n",
        "params['question_pad_seq'] = 'pre'\n",
        "params['vocab_size'] = len(tokenizer.word_index)\n",
        "\n",
        "pprint.pprint(params)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 300,\n",
            " 'question_length_99': 20,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': (26062, 16),\n",
            " 'train_shape': (78183, 16),\n",
            " 'val_shape': (26061, 16),\n",
            " 'vocab_size': 100850}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7lRuVtp_7y51"
      },
      "source": [
        "## 3 Vectorization / Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oEJqzOfW9ARO"
      },
      "source": [
        "#### 3.1 Integer Sequence of Context and Question "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HhuvjYmZ7m6W",
        "colab": {}
      },
      "source": [
        "train_clean_context_sequence = tokenizer.texts_to_sequences(train[\"clean_context\"].values)\n",
        "test_clean_context_sequence = tokenizer.texts_to_sequences(test[\"clean_context\"].values)\n",
        "val_clean_context_sequence = tokenizer.texts_to_sequences(val[\"clean_context\"].values)\n",
        "\n",
        "\n",
        "train_clean_question_sequence = tokenizer.texts_to_sequences(train[\"clean_question\"].values)\n",
        "test_clean_question_sequence = tokenizer.texts_to_sequences(test[\"clean_question\"].values)\n",
        "val_clean_question_sequence = tokenizer.texts_to_sequences(val[\"clean_question\"].values)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vXQNaAxehrDa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c9785c09-a761-4b30-9c7d-b167a755fd0c"
      },
      "source": [
        "train_clean_question_sequence[5:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3654, 1871, 4254, 501, 2],\n",
              " [961, 140, 612, 940, 15315, 553, 10, 158, 1823],\n",
              " [208, 16, 1, 1902, 168, 9718, 10],\n",
              " [93, 72, 3563, 2660, 1489, 3331, 16, 4345, 86, 639, 26, 765, 59],\n",
              " [2, 225, 3, 7788, 1003, 173, 737, 1656, 14, 488, 10, 9137, 7078]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0kmRjkqRlExD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ade470c0-9d44-41ac-c681-931d863af9b8"
      },
      "source": [
        "train['clean_question'][5:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9806                         each cardinal priest has what\n",
              "61317    why does congress give generalized powers to f...\n",
              "8811                 where did the prussian forces flee to\n",
              "4773     which u s billboard 200 chart topper did kanye...\n",
              "5695     what type of buddhists believe that personal e...\n",
              "Name: clean_question, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EQpM6dGtoGkP",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7u41PKZTFcwm"
      },
      "source": [
        "#### 3.2 Find Max Sequence length of Context and Question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jwh8HGs0Fbp2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "5667fbf7-a00f-4c6e-97db-70a8da3db2c2"
      },
      "source": [
        "# max length of context\n",
        "params['context_max_length'] = max(max(len(txt) for txt in train_clean_context_sequence),\n",
        "                                  max(len(txt) for txt in test_clean_context_sequence),\n",
        "                                  max(len(txt) for txt in val_clean_context_sequence))\n",
        "\n",
        "params['question_max_length'] = max(max(len(txt) for txt in train_clean_question_sequence),\n",
        "                                  max(len(txt) for txt in test_clean_question_sequence),\n",
        "                                  max(len(txt) for txt in val_clean_question_sequence))\n",
        "\n",
        "\n",
        "pprint.pprint(params)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_max_length': 426,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 300,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': (26062, 16),\n",
            " 'train_shape': (78183, 16),\n",
            " 'val_shape': (26061, 16),\n",
            " 'vocab_size': 100850}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NhnBwThFIA0H"
      },
      "source": [
        "#### 3.3 Padding of the sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gGvIf7xU9rIJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4c8bafcf-d856-400a-df11-f65240cb1ddd"
      },
      "source": [
        "train_context_sequence = preprocessing.sequence.pad_sequences(train_clean_context_sequence,\n",
        "                                                              maxlen=params['context_max_length'],\n",
        "                                                              padding=params['context_pad_seq'])\n",
        "test_context_sequence = preprocessing.sequence.pad_sequences(test_clean_context_sequence,\n",
        "                                                             maxlen=params['context_max_length'],\n",
        "                                                             padding=params['context_pad_seq'])\n",
        "val_context_sequence = preprocessing.sequence.pad_sequences(val_clean_context_sequence,\n",
        "                                                            maxlen=params['context_max_length'],\n",
        "                                                            padding=params['context_pad_seq'])\n",
        "\n",
        "print(train_context_sequence.shape)\n",
        "print(test_context_sequence.shape)\n",
        "print(val_context_sequence.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(78183, 426)\n",
            "(26062, 426)\n",
            "(26061, 426)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2NxpIGIb9p5T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0675ff19-623c-43e4-f434-403785fd1881"
      },
      "source": [
        "train_question_sequence = preprocessing.sequence.pad_sequences(train_clean_question_sequence,\n",
        "                                                               maxlen=params['question_max_length'],\n",
        "                                                               padding=params['question_pad_seq'])\n",
        "test_question_sequence = preprocessing.sequence.pad_sequences(test_clean_question_sequence,\n",
        "                                                              maxlen=params['question_max_length'],\n",
        "                                                              padding=params['question_pad_seq'])\n",
        "val_question_sequence = preprocessing.sequence.pad_sequences(val_clean_question_sequence,\n",
        "                                                             maxlen=params['question_max_length'],\n",
        "                                                             padding=params['question_pad_seq'])\n",
        "\n",
        "print(train_question_sequence.shape)\n",
        "print(test_question_sequence.shape)\n",
        "print(val_question_sequence.shape)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(78183, 40)\n",
            "(26062, 40)\n",
            "(26061, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fgCKNbH6_-yd"
      },
      "source": [
        "#### 3.4 Create Answer Sequence "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bv0yC_w8AF4x"
      },
      "source": [
        "Encode y_trues as big array consisting of ans_start + ans_end. This has to be used in loss function as well. We will use the answer_word_span feature\n",
        "\n",
        "**y_true = answer_start + answer_end**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cHPxRRHuAnSH",
        "colab": {}
      },
      "source": [
        "# for train data\n",
        "y_train = []\n",
        "span_ofr = 0;\n",
        "params['train_span_outofrange'] = 0\n",
        "params['test_span_outofrange'] = 0\n",
        "params['val_span_outofrange'] = 0\n",
        "\n",
        "for i in range(len(train)):    \n",
        "    s = np.zeros(params['context_max_length'],dtype = \"float32\")\n",
        "    e = np.zeros(params['context_max_length'],dtype = \"float32\")\n",
        "    start, end = train[\"answer_word_span\"].iloc[i]    \n",
        "    s[start] = 1\n",
        "    e[end] = 1\n",
        "    y_train.append(np.concatenate((s,e)))    \n",
        "\n",
        "params['train_span_outofrange'] = span_ofr\n",
        "span_ofr = 0;\n",
        "\n",
        "# for test data\n",
        "y_test = []\n",
        "for i in range(len(test)):    \n",
        "    s = np.zeros(params['context_max_length'],dtype = \"float32\")\n",
        "    e = np.zeros(params['context_max_length'],dtype = \"float32\")        \n",
        "    start,end = test[\"answer_word_span\"].iloc[i]    \n",
        "    s[start] = 1\n",
        "    e[end] = 1\n",
        "    y_test.append(np.concatenate((s,e)))\n",
        "\n",
        "params['test_span_outofrange'] = span_ofr\n",
        "span_ofr = 0;\n",
        "                \n",
        "# for val data\n",
        "y_val = []\n",
        "for i in range(len(val)):\n",
        "    s = np.zeros(params['context_max_length'],dtype = \"float32\")\n",
        "    e = np.zeros(params['context_max_length'],dtype = \"float32\")        \n",
        "    start,end = val[\"answer_word_span\"].iloc[i]    \n",
        "    s[start] = 1\n",
        "    e[end] = 1      \n",
        "    y_val.append(np.concatenate((s,e)))\n",
        "\n",
        "params['val_span_outofrange'] = span_ofr    "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WgPgnMl0VZCd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d446a50d-7053-4166-d135-02399e6a486e"
      },
      "source": [
        "print(len(y_train),len(y_train[0]))\n",
        "print(len(y_test),len(y_test[0]))\n",
        "print(len(y_val),len(y_val[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78183 852\n",
            "26062 852\n",
            "26061 852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mFuJMid-iT7a"
      },
      "source": [
        "### 3.5 Check 1 value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SXXhftC5kE8A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19b57edf-8b13-4c1a-e53a-0baa70f5f213"
      },
      "source": [
        "index = 1\n",
        "answer_span(train['clean_context'].iloc[index],train['clean_answer'].iloc[index])\n",
        "span_to_answer((22,22),train['clean_context'].iloc[index])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'income'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fAXS9YCpiVkn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "15f6c184-4a0b-4f34-8b5e-0d8c0515f492"
      },
      "source": [
        "print(\"Ori Cont = \")\n",
        "pprint.pprint(train['context'].iloc[index])\n",
        "print(\"CLean Cont = \")\n",
        "pprint.pprint(train['clean_context'].iloc[index])\n",
        "print('Question = ',train['question'].iloc[index])\n",
        "print('Clean Question = ',train['clean_question'].iloc[index])\n",
        "print('Answer = ',train['answer'].iloc[index])\n",
        "print('Clean Answer = ',train['clean_answer'].iloc[index])\n",
        "print('AS,AE = ',train['answer_word_span'].iloc[index])\n",
        "print(\"encoded \", y_train[index])\n",
        "print(span_to_answer([60,62],train['clean_context'].iloc[index]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ori Cont = \n",
            "('Bermuda is an offshore financial centre, which results from its minimal '\n",
            " 'standards of business regulation/laws and direct taxation on personal or '\n",
            " 'corporate income. It has one of the highest consumption taxes in the world '\n",
            " \"and taxes all imports in lieu of an income tax system. Bermudas's \"\n",
            " 'consumption tax is equivalent to local income tax to local residents and '\n",
            " 'funds government and infrastructure expenditures. The local tax system '\n",
            " 'depends upon import duties, payroll taxes and consumption taxes. The legal '\n",
            " 'system is derived from that of the United Kingdom, with recourse to English '\n",
            " 'courts of final appeal. Foreign private individuals cannot easily open bank '\n",
            " 'accounts or subscribe to mobile phone or internet services.')\n",
            "CLean Cont = \n",
            "('bermuda offshore financial centre results minimal standards business '\n",
            " 'regulationlaws direct taxation personal corporate income one highest '\n",
            " 'consumption taxes world taxes imports lieu income tax system bermudass '\n",
            " 'consumption tax equivalent local income tax local residents funds government '\n",
            " 'infrastructure expenditures local tax system depends upon import duties '\n",
            " 'payroll taxes consumption taxes legal system derived united kingdom recourse '\n",
            " 'english courts final appeal foreign private individuals easily open bank '\n",
            " 'accounts subscribe mobile phone internet services')\n",
            "Question =  What does Bermuda use the consumption tax for?\n",
            "Clean Question =  what does bermuda use the consumption tax for\n",
            "Answer =  funds government and infrastructure expenditures\n",
            "Clean Answer =  funds government and infrastructure expenditures\n",
            "AS,AE =  (34, 38)\n",
            "encoded  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0]\n",
            "private individuals easily\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-rZCyBydBZW1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "18ca5f26-e6f9-43a0-b14a-2f829153eb65"
      },
      "source": [
        "pprint.pprint(params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_max_length': 426,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 300,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': (26062, 16),\n",
            " 'test_span_outofrange': 0,\n",
            " 'tokenizer_num_words': 80000,\n",
            " 'train_shape': (78183, 16),\n",
            " 'train_span_outofrange': 0,\n",
            " 'val_shape': (26061, 16),\n",
            " 'val_span_outofrange': 0,\n",
            " 'vocab_size': 100850}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mDzXjXa3MpP0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "bddc0d71-3fff-4a5e-bdc7-dda067bc7cf8"
      },
      "source": [
        "print(squad_df['clean_context'][10])\n",
        "print(train_context_sequence[110])\n",
        "print(squad_df['clean_question'][10])\n",
        "print(train_question_sequence[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "beyonc giselle knowlescarter bijnse beeyonsay born september 4 1981 american singer songwriter record producer actress born raised houston texas performed various singing dancing competitions child rose fame late 1990s lead singer rb girlgroup destinys child managed father mathew knowles group became one worlds bestselling girl groups time hiatus saw release beyoncs debut album dangerously love 2003 established solo artist worldwide earned five grammy awards featured billboard hot 100 numberone singles crazy love baby boy\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0    61  2155   317  1203  3024  4559  1690\n",
            " 31685  3523  1203  1130  3904    83  8724  7209   112   441  3200   112\n",
            "   441    31  5577  3767  9938  2249  2540  1896    53  8245 18669   266\n",
            "    45  8724    83 30865 37782   385    18    61  1203  5577  2390    31\n",
            "  1765   678  1203    83  2390 16114  7209  4549    61   317   445 16114\n",
            "  1203  3024    83  7209  1130  2874  1049   343  6121  6675   777  2758\n",
            "    44  1829    58   111    52  1203  3024 22571  1048 27913  1130  2874\n",
            "    83  5942  7209   120  6463  1881]\n",
            "what was the first album beyonc released as a solo artist\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    2  624 1359 2478 5369    1   36 1061   23]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V0TSjNkdXzuR"
      },
      "source": [
        "### 3.6 Create a common function to generate sequences (useful in prediction)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sq97Vq4kXTST",
        "colab": {}
      },
      "source": [
        "# function to generate sequences withg appropiate padding\n",
        "def generate_question_context_sequence(context, question):\n",
        "  question_seq = tokenizer.texts_to_sequences(question)\n",
        "  context_seq = tokenizer.texts_to_sequences(context)\n",
        "  question_seq = preprocessing.sequence.pad_sequences(question_seq,maxlen=params['question_max_length'])\n",
        "  context_seq = preprocessing.sequence.pad_sequences(context_seq,maxlen=params['context_max_length'])\n",
        "  return context_seq, question_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nkpMiW1HaqrL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "838d0d5c-78c0-4262-aaac-99a27117c6b5"
      },
      "source": [
        "print(train[\"clean_question\"].iloc[1])\n",
        "\n",
        "c='state among best prekindergarten education national institute early education research rated first united states regard standards quality access prekindergarten education 2004 calling model early childhood schooling high school dropout rate decreased 3 1 2 5 percent 2007 2008 oklahoma ranked among 18 states 3 percent less dropout rate 2004 state ranked 36th nation relative number adults high school diplomas though 85 2 percent highest rate among southern states'\n",
        "q='what term can be used to refer to the usable spectrum of an antennas frequency'\n",
        "cs,qs = generate_question_context_sequence([c],[q])\n",
        "print(cs.shape,qs.shape)\n",
        "train_question_sequence[1] == qs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "what does bermuda use the consumption tax for\n",
            "(1, 426) (1, 40)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nl55IUkVck82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "dc2f2b6c-4469-455e-cb73-58b23c303b8b"
      },
      "source": [
        "train_question_sequence[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    2,\n",
              "        140, 1941,   28,    1, 2047, 1442,   59], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wt51Se0SchIp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "019f8d5e-3b4c-4463-ee5a-29f007ca2ee5"
      },
      "source": [
        "q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'what term can be used to refer to the usable spectrum of an antennas frequency'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r6FSl5UDL_qD"
      },
      "source": [
        "## 4 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yS6fKEvieWrX"
      },
      "source": [
        "**Implements a baseline 0 in Deep Learning based approach per our project synopsis. This baseline model uses the following layers **\n",
        "0.   Input layer\n",
        "1.   Embedding Layer\n",
        "2.   List LSTM\n",
        "3.   a custom Bilinear Similarity layer \n",
        "4.   Prediction Layer\n",
        "5.   Output layer \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U9JFn3oWiU4y"
      },
      "source": [
        "### 4.2 Building Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RC6E5AVNoTDM"
      },
      "source": [
        "#### Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZFwN88XSjJER",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bde418d9-e79b-4daa-98e2-d53a807d9c41"
      },
      "source": [
        "# Check of GPU\n",
        "tf.config.experimental.list_physical_devices('CPU')\n",
        "# tf.debugging.get_log_device_placement()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GT9CaxRpoY_W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e2aece4c-c911-4fba-cbd1-950848718413"
      },
      "source": [
        "print(tf.config.experimental.list_physical_devices('GPU'))\n",
        "print(tf.config.experimental.list_logical_devices('GPU'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "[LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:0', device_type='GPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "10hBbjLed082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83c8db3d-d458-4f09-be92-81aa5453c697"
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  # Create 2 virtual GPUs with 1GB memory each\n",
        "  try:\n",
        "    tf.config.experimental.set_virtual_device_configuration(\n",
        "        gpus[0],\n",
        "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024),\n",
        "         tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Virtual devices must be set before GPUs have been initialized\n",
        "    print(e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Virtual devices cannot be modified after being initialized\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hknoQMpupNBt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "47e4c329-bd31-4189-d5df-39c37e8103dd"
      },
      "source": [
        "# Refer https://colab.research.google.com/notebooks/gpu.ipynb#scrollTo=Y04m-jvKRDsJ\n",
        "import timeit\n",
        "tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n",
            "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Add in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Assert in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Conv2D in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op BiasAdd in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Sum in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Conv2D in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op BiasAdd in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Sum in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "3.125542867999684\n",
            "GPU (s):\n",
            "0.05443457399996987\n",
            "GPU speedup over CPU: 57x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TOTSZc8_UeU2"
      },
      "source": [
        "#### Common Function - CUDNN LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VwjPKOsTUdgY",
        "colab": {}
      },
      "source": [
        "# As per https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM, it will use CuDNN Lstm\n",
        "# if below params match\n",
        "# activation == tanh\n",
        "# recurrent_activation == sigmoid\n",
        "# recurrent_dropout == 0\n",
        "# unroll is False\n",
        "# use_bias is True\n",
        "# Inputs are not masked or strictly right padded.\n",
        "\n",
        "def createCUDNNLstm(units,return_sequences,name):\n",
        "  return layers.LSTM(units=units,\n",
        "                     return_sequences=return_sequences, \n",
        "                     name = name,\n",
        "                     activation='tanh',\n",
        "                     recurrent_activation='sigmoid',\n",
        "                     recurrent_dropout=0,\n",
        "                     unroll=False,\n",
        "                     use_bias=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b9c9sCM-Tz0E"
      },
      "source": [
        "#### Load Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mGHXSG5qTzG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52a23dc5-8c7d-4aec-b0ba-23a4a634eafa"
      },
      "source": [
        "embedding_matrix = np.zeros((params['vocab_size']+1,300))\n",
        "\n",
        "with open(model_path + \"glove300dembedmatrix.pkl\",\"rb\") as f:\n",
        "  embedding_matrix=pickle.load(f)\n",
        "  \n",
        "embedding_matrix.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100851, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UmhiPPKrpCFv"
      },
      "source": [
        "#### Create TF Mirror Strategy for Multi-GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g1TCqo4_pBkL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4087e95e-e024-44ec-9f61-2c8bc454ad79"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "device_name = device_name.replace('/device:','/')\n",
        "strategy = tf.distribute.MirroredStrategy(devices=[device_name])\n",
        "strategy"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy at 0x7fa503949fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tLGurD9eijTh"
      },
      "source": [
        "#### Questions LSTM Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rLqUQHSjeVwq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "c3dfaa67-5735-4e65-9a09-ee5692704b92"
      },
      "source": [
        "# question embedding\n",
        "with strategy.scope():\n",
        "  q_input = layers.Input(shape=(params['question_max_length'],),name=\"QUESTION_INPUT\")\n",
        "  q_emb = layers.Embedding(input_dim=params['vocab_size']+1,\n",
        "                    output_dim=params['embedding_size'],\n",
        "                    weights=[embedding_matrix],\n",
        "                    trainable=False, mask_zero= False,\n",
        "                    name=\"QUESTION_EMBEDDING\")(q_input)\n",
        "\n",
        "  # encoder\n",
        "  q_0=createCUDNNLstm(units=params['rnn_units'],return_sequences=True, name = \"QUESTION_LSTM_1\")(q_emb)\n",
        "  q_1=createCUDNNLstm(units=params['rnn_units'],return_sequences=True, name = \"QUESTION_LSTM_2\")(q_0)\n",
        "  q_output = createCUDNNLstm(units=params['rnn_units'], return_sequences=False,name='QUESTION_LSTM')(q_1)\n",
        "  print(q_output.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Qr in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op DiagPart in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Sign in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Transpose in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Reshape in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op ConcatV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "(None, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4AR0UwcbZ-TT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f60a90c8-80f8-4b2f-807e-696cf7159fcc"
      },
      "source": [
        "# import numpy as np\n",
        "\n",
        "# import tensorflow as tf\n",
        "\n",
        "# from tensorflow.keras import layers\n",
        "\n",
        "# raw_inputs = [[83, 91, 1, 645, 1253, 927],[73, 8, 3215, 55, 927],[711, 632, 71]]\n",
        "# padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
        "#                                                               padding='pre')\n",
        "\n",
        "# print(padded_inputs)\n",
        "\n",
        "# embedding = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=False)\n",
        "# masked_output = embedding(padded_inputs)\n",
        "\n",
        "# print(masked_output._keras_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  83   91    1  645 1253  927]\n",
            " [   0   73    8 3215   55  927]\n",
            " [   0    0    0  711  632   71]]\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fZXtjwB1Xdy9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e94e9e57-49d2-4d39-a531-4327a28419f0"
      },
      "source": [
        "# # \n",
        "# # question embedding\n",
        "# q_input = layers.Input(shape=(params['question_max_length'],),name=\"QUESTION_INPUT\")\n",
        "# q_emb = layers.Embedding(input_dim=params['vocab_size']+1,\n",
        "#                   output_dim=params['embedding_size'],\n",
        "#                   weights=[embedding_matrix],\n",
        "#                   trainable=False, \n",
        "#                   name=\"QUESTION_EMBEDDING\")(q_input)\n",
        "\n",
        "# # encoder \n",
        "# q_0=tf.compat.v1.keras.layers.CuDNNLSTM(units=params['rnn_units'],return_sequences=True, name = \"QUESTION_LSTM_1\")(q_emb)\n",
        "# q_1=tf.compat.v1.keras.layers.CuDNNLSTM(units=params['rnn_units'],return_sequences=True, name = \"QUESTION_LSTM_2\")(q_0)\n",
        "# q_output = tf.compat.v1.keras.layers.CuDNNLSTM(units=params['rnn_units'], \n",
        "#                      name='QUESTION_LSTM')(q_1)\n",
        "# print(q_output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2eJ2ykC1megw"
      },
      "source": [
        "#### Context LSTM Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-glhG509P5Yh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78b6f307-251a-4565-b709-5902a7c8de6c"
      },
      "source": [
        "with strategy.scope():\n",
        "  c_input = layers.Input(shape=(params['context_max_length'],),name=\"CONTEXT_INPUT\")\n",
        "\n",
        "  # context embedding\n",
        "  c_emb = layers.Embedding(input_dim=params['vocab_size']+1,\n",
        "                    output_dim=params['embedding_size'],\n",
        "                    weights=[embedding_matrix], trainable=False, mask_zero=False,\n",
        "                    name=\"CONTEXT_EMBEDDING\")(c_input)\n",
        "\n",
        "\n",
        "  c_0=createCUDNNLstm(params['rnn_units'],return_sequences=True, name = \"CONTEXT_LSTM_1\")(c_emb)\n",
        "  c_1=createCUDNNLstm(params['rnn_units'],return_sequences=True, name = \"CONTEXT_LSTM_2\")(c_0)\n",
        "\n",
        "  c_output = createCUDNNLstm(params['rnn_units'],name='CONTEXT_LSTM_3',return_sequences=True)(c_1)\n",
        "\n",
        "  print(\"final output to bilinear \",c_output.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final output to bilinear  (None, 426, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g93054zrp9yp"
      },
      "source": [
        "#### Bilinear Term "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CNsrWO_tpppa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2ebe6a76-35b4-41dd-cd74-f0dfb33ed61d"
      },
      "source": [
        "# Reference -- https://github.com/kellywzhang/reading-comprehension/blob/master/attention.py\n",
        "# bilinear term ####\n",
        "print(\"Question context shape \",q_output.shape)\n",
        "print(\"final o/p of context \",c_output.shape)\n",
        "\n",
        "with strategy.scope():\n",
        "  ################ start prediction ######################\n",
        "  start = layers.Dense(params['rnn_units'],name=\"BILINEAR_AS_SPAN\")(q_output)\n",
        "  hidden_start_time_axis = tf.expand_dims(start, 2, name='BILINEAR_AS_ADD_DIM')\n",
        "\n",
        "  # squeeze remooves time slice we added before\n",
        "  # final shape = (batch_size,decoder_timesteps)\n",
        "  start_ = tf.squeeze(tf.matmul(c_output,hidden_start_time_axis,name=\"BILINEAR_AS_MATMUL_Q_C\"),2,name=\"BILINEAR_AS_DEL_DIM\")\n",
        "      \n",
        "  start_ = tf.nn.softmax(start_,axis = 1,name=\"BILINEAR_AS_SOFTMAX\")\n",
        "      \n",
        "  ################ end prediction ######################\n",
        "  end = layers.Dense(params['rnn_units'],name=\"BILINEAR_AE_SPAN\")(q_output)\n",
        "\n",
        "  hidden_end_time_axis = tf.expand_dims(end, 2, name=\"BILINEAR_AE_ADD_DIM\")\n",
        "\n",
        "  # squeeze remooves time slice we added before\n",
        "  # final shape = (batch_size,decoder_timesteps)\n",
        "  end_ = tf.squeeze(tf.matmul(c_output,hidden_end_time_axis,name=\"BILINEAR_AE_MATMUL_Q_C\"),2,name=\"BILINEAR_AE_DEL_DIM\")\n",
        "  end_ = tf.nn.softmax(end_,axis=1,name=\"BILINEAR_AE_SOFTMAX\")\n",
        "\n",
        "  prob_token_span = tf.concat((start_,end_),axis = 1,name=\"BILINEAR_AS_AE_CONCAT\")\n",
        "  print(\"Probab shape \",prob_token_span)\n",
        "\n",
        "\n",
        "  # logits = BilinearSimilarity(UNITS)(q_cont,c_)\n",
        "  # Y_prob = Prediction()(logits)\n",
        "  # print(\"Logits shape \",logits.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question context shape  (None, 256)\n",
            "final o/p of context  (None, 426, 256)\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Probab shape  Tensor(\"BILINEAR_AS_AE_CONCAT:0\", shape=(None, 852), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ibcGeRqUxzKN"
      },
      "source": [
        "#### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vFbuhviAyX7l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a6f105ca-551b-4e25-dc48-cf3b00b2a8c2"
      },
      "source": [
        "####### Prediction ### \n",
        "token_span = 20\n",
        "with strategy.scope():\n",
        "  start_prob = tf.identity(prob_token_span[:,:params['context_max_length']],\n",
        "                          name=\"START_PROBAB\")\n",
        "  # start_prob.name = \"START_PROBAB\"\n",
        "\n",
        "  end_prob = tf.identity(prob_token_span[:,params['context_max_length']:],\n",
        "                        name=\"END_PROBAB\")\n",
        "  # end_prob.name = \"END_PROBAB\"\n",
        "  print(\"Probab shape \",start_prob)\n",
        "\n",
        "  # do the outer product\n",
        "  outer = tf.matmul(tf.expand_dims(start_prob, axis=2, name=\"PREDICT_AS_PROBAB\"),tf.expand_dims(end_prob, axis=1, name=\"PREDICT_AS_PROBAB\"),name=\"PREDICT_AS_AE_MATMUL\")\n",
        "\n",
        "  # this is done to ensure load_model does not error out on\n",
        "  # inconsistency between dtype int32 and int64\n",
        "  num_lower = tf.constant(0,dtype='int32')\n",
        "  num_upper = tf.constant(token_span,dtype='int32')\n",
        "  outer = tf.linalg.band_part(outer, num_lower, num_upper,name=\"PREDICT_AS_AE_TOPTRIANGLE\")\n",
        "\n",
        "  # start_position will have shape of (batch_size,)\n",
        "  start_position = tf.reduce_max(outer, axis=2,name=\"PREDICT_AS_MAX\")\n",
        "  #end position will have shape of (batch_size,)\n",
        "  end_position = tf.reduce_max(outer, axis=1,name=\"PREDICT_AE_MAX\")\n",
        "\n",
        "  y_probab = tf.concat([start_position,end_position],axis=1,name=\"PREDICT_AS_AE\")\n",
        "\n",
        "print(y_probab.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probab shape  Tensor(\"START_PROBAB:0\", shape=(None, 426), dtype=float32)\n",
            "(None, 852)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PLtlPSfLxyzB"
      },
      "source": [
        "### 4.3 Custom Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tlOkeMveyCWM",
        "colab": {}
      },
      "source": [
        "def logits_loss(y_true,logits):\n",
        "    \"\"\"\n",
        "    Custom loss function which minimises log_loss.\n",
        "    Referance https://stackoverflow.com/questions/50063613/add-loss-function-in-keras\n",
        "    \"\"\"\n",
        "    \n",
        "    #y_true = tf.cast(y_true,dtype=tf.int32)\n",
        "    #logits = tf.cast(logits,dtype=tf.float32)\n",
        "    \n",
        "    # breaking the tensor into two half's to get start and end label.\n",
        "    start_label = y_true[:,:params['context_max_length']]\n",
        "    end_label = y_true[:,params['context_max_length']:]\n",
        "    \n",
        "    # braking the logits tensor into start and end part for loss calcultion.\n",
        "    start_logit = logits[:,:params['context_max_length']]\n",
        "    end_logit = logits[:,params['context_max_length']:]\n",
        "    \n",
        "    start_loss = tf.keras.backend.categorical_crossentropy(start_label,start_logit)\n",
        "    end_loss = tf.keras.backend.categorical_crossentropy(end_label,end_logit)\n",
        "    \n",
        "#     start_loss = tf.losses.sparse_softmax_cross_entropy(labels=start_label, logits=start_logit)\n",
        "#     end_loss = tf.losses.sparse_softmax_cross_entropy(labels=end_label, logits=end_logit)\n",
        "    \n",
        "    # as per paer\n",
        "    \n",
        "    loss = start_loss + end_loss\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dNiC79-tyLmq"
      },
      "source": [
        "### 4.4 Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rv9aw2EewJbr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4ab54ec8-19fd-407e-b088-fbfa901940d2"
      },
      "source": [
        "model = Model(inputs = [q_input,c_input],outputs =y_probab, name='mrc_deeplstm')\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op __inference_keras_scratch_graph_3153 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_3158 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_3163 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_3168 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_3173 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_3178 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_3183 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_3188 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_3193 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_3198 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_3203 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_3208 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_3213 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_3218 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_3223 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_3228 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Model: \"mrc_deeplstm\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "QUESTION_INPUT (InputLayer)     [(None, 40)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "QUESTION_EMBEDDING (Embedding)  (None, 40, 300)      30255300    QUESTION_INPUT[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "CONTEXT_INPUT (InputLayer)      [(None, 426)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "QUESTION_LSTM_1 (LSTM)          (None, 40, 256)      570368      QUESTION_EMBEDDING[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "CONTEXT_EMBEDDING (Embedding)   (None, 426, 300)     30255300    CONTEXT_INPUT[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "QUESTION_LSTM_2 (LSTM)          (None, 40, 256)      525312      QUESTION_LSTM_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "CONTEXT_LSTM_1 (LSTM)           (None, 426, 256)     570368      CONTEXT_EMBEDDING[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "QUESTION_LSTM (LSTM)            (None, 256)          525312      QUESTION_LSTM_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "CONTEXT_LSTM_2 (LSTM)           (None, 426, 256)     525312      CONTEXT_LSTM_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "BILINEAR_AS_SPAN (Dense)        (None, 256)          65792       QUESTION_LSTM[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "BILINEAR_AE_SPAN (Dense)        (None, 256)          65792       QUESTION_LSTM[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "CONTEXT_LSTM_3 (LSTM)           (None, 426, 256)     525312      CONTEXT_LSTM_2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AS_ADD_DIM [(None, 256, 1)]     0           BILINEAR_AS_SPAN[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AE_ADD_DIM [(None, 256, 1)]     0           BILINEAR_AE_SPAN[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2 (Tens [(None, 426, 1)]     0           CONTEXT_LSTM_3[0][0]             \n",
            "                                                                 tf_op_layer_BILINEAR_AS_ADD_DIM[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_1 (Te [(None, 426, 1)]     0           CONTEXT_LSTM_3[0][0]             \n",
            "                                                                 tf_op_layer_BILINEAR_AE_ADD_DIM[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AS_DEL_DIM [(None, 426)]        0           tf_op_layer_BatchMatMulV2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AE_DEL_DIM [(None, 426)]        0           tf_op_layer_BatchMatMulV2_1[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AS_SOFTMAX [(None, 426)]        0           tf_op_layer_BILINEAR_AS_DEL_DIM[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AE_SOFTMAX [(None, 426)]        0           tf_op_layer_BILINEAR_AE_DEL_DIM[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AS_AE_CONC [(None, 852)]        0           tf_op_layer_BILINEAR_AS_SOFTMAX[0\n",
            "                                                                 tf_op_layer_BILINEAR_AE_SOFTMAX[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [(None, 426)]        0           tf_op_layer_BILINEAR_AS_AE_CONCAT\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_1 (Te [(None, 426)]        0           tf_op_layer_BILINEAR_AS_AE_CONCAT\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_START_PROBAB (Tenso [(None, 426)]        0           tf_op_layer_strided_slice[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_END_PROBAB (TensorF [(None, 426)]        0           tf_op_layer_strided_slice_1[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_PREDICT_AS_PROBAB ( [(None, 426, 1)]     0           tf_op_layer_START_PROBAB[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_PREDICT_AS_PROBAB_1 [(None, 1, 426)]     0           tf_op_layer_END_PROBAB[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_2 (Te [(None, 426, 426)]   0           tf_op_layer_PREDICT_AS_PROBAB[0][\n",
            "                                                                 tf_op_layer_PREDICT_AS_PROBAB_1[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_PREDICT_AS_AE_TOPTR [(None, 426, 426)]   0           tf_op_layer_BatchMatMulV2_2[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_PREDICT_AS_MAX (Ten [(None, 426)]        0           tf_op_layer_PREDICT_AS_AE_TOPTRIA\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_PREDICT_AE_MAX (Ten [(None, 426)]        0           tf_op_layer_PREDICT_AS_AE_TOPTRIA\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_PREDICT_AS_AE (Tens [(None, 852)]        0           tf_op_layer_PREDICT_AS_MAX[0][0] \n",
            "                                                                 tf_op_layer_PREDICT_AE_MAX[0][0] \n",
            "==================================================================================================\n",
            "Total params: 63,884,168\n",
            "Trainable params: 3,373,568\n",
            "Non-trainable params: 60,510,600\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Biepd_j518BQ"
      },
      "source": [
        "### 4.5 Model Compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uAqT6LWbXxWE"
      },
      "source": [
        "**Tensorboard Logs and Model compilation** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kTB5bE8I2Al-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "137f78f0-1d0a-47a5-d18c-aa9633e38061"
      },
      "source": [
        "# using tensorboard instance for callbacks\n",
        "from time import time\n",
        "from datetime import datetime\n",
        "from tensorflow.python.keras.callbacks import TensorBoard\n",
        "\n",
        "log_dir = tensorboard_logpath +\"lstm-baseline0\"\n",
        "print('Tensprflow logs ',log_dir)\n",
        "tensorboard = TensorBoard(log_dir=log_dir,histogram_freq=1)\n",
        "with strategy.scope():\n",
        "  # model compilation\n",
        "  model.compile(optimizer=\"adamax\",loss=logits_loss,metrics=['accuracy'])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensprflow logs  /content/drive/My Drive/AIML-MRC-Capstone/models/tensorboard-logs/lstm-baseline0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4WuaPHlU8hnp"
      },
      "source": [
        "### 4.6 Generator Function for use in Model.fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yYIgojpb8g82",
        "colab": {}
      },
      "source": [
        "## Reference \n",
        "def generator_function(length,batch_size = 64,data_type = 'Train'):\n",
        "    \"\"\"\n",
        "    This function is generates batches of data to avoid strain on memory.\n",
        "    \"\"\"\n",
        "    X1, X2, y = list(), list(), list()\n",
        "    flag = True\n",
        "    if data_type == 'Val':\n",
        "        flag = False\n",
        "    n = 0\n",
        "    # loop forever over datapoints.\n",
        "    while 1:\n",
        "        for i in range(length):\n",
        "            n += 1\n",
        "            if flag:\n",
        "                X1.append(train_question_sequence[i])\n",
        "                X2.append(train_context_sequence[i])                \n",
        "                y.append(y_train[i])\n",
        "            else:\n",
        "                X1.append(val_question_sequence[i])\n",
        "                X2.append(val_context_sequence[i])                \n",
        "                y.append(y_val[i])\n",
        "            if n == batch_size:\n",
        "                yield ((array(X1),array(X2)),array(y))\n",
        "                X1,X2, y = list(), list(), list()\n",
        "                n=0"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vlGf9CAe-ZW-"
      },
      "source": [
        "### 4.7 Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bO-l9AhD-fPM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "1fb93108-9625-4432-d516-f5c9bf7a4aa2"
      },
      "source": [
        "params['training.epochs']=25\n",
        "params['training.batch_size']=64\n",
        "params['training.train_length']=len(y_train)\n",
        "params['training.val_length']=len(y_val)\n",
        "params['training.train_steps']=params['training.train_length']//params['training.batch_size']\n",
        "params['training.val_steps']=params['training.val_length']//32\n",
        "\n",
        "pprint.pprint(params)\n",
        "\n",
        "### SAVE PARAMS\n",
        "# Writing to sample.json \n",
        "updateparams()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_max_length': 426,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 300,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': (26062, 16),\n",
            " 'test_span_outofrange': 0,\n",
            " 'train_shape': (78183, 16),\n",
            " 'train_span_outofrange': 0,\n",
            " 'training.batch_size': 64,\n",
            " 'training.epochs': 25,\n",
            " 'training.train_length': 78183,\n",
            " 'training.train_steps': 1221,\n",
            " 'training.val_length': 26061,\n",
            " 'training.val_steps': 814,\n",
            " 'val_shape': (26061, 16),\n",
            " 'val_span_outofrange': 0,\n",
            " 'vocab_size': 100850}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-089557544d51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m### SAVE PARAMS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Writing to sample.json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mupdateparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'updateparams' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cEOFWZVEIpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model_checkpoint_callback = ModelCheckpoint(filepath=model_path,\n",
        "                                            save_weights_only=True,\n",
        "                                            monitor='val_accuracy',\n",
        "                                            mode='max',\n",
        "                                            save_best_only=True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dfbn-RnO_EOc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5144b5ff-35f5-439f-b867-8144498e0641"
      },
      "source": [
        "# with tf.device('/device:GPU:0'):  \n",
        "with strategy.scope():\n",
        "  for i in range(params['training.epochs']):\n",
        "      print(\"Epoch {} start at time \".format(i),datetime.now())    \n",
        "      train_generator = generator_function(params['training.train_length'],\n",
        "                                          params['training.batch_size'])    \n",
        "      val_generator = generator_function(params['training.val_length'],\n",
        "                                        32,\n",
        "                                        \"Val\")\n",
        "      model.fit(x=train_generator, epochs=1, \n",
        "                          steps_per_epoch=params['training.train_steps'],\n",
        "                          verbose=1,\n",
        "                          callbacks=[tensorboard],\n",
        "                          validation_data=val_generator,\n",
        "                          validation_steps=params['training.val_steps'])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 start at time  2020-06-20 18:55:30.730507\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Add in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op SummaryWriter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op CreateSummaryFileWriter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op WriteGraphSummary in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op LogicalAnd in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Identity in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op WriteSummary in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlushSummaryWriter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AnonymousMultiDeviceIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MultiDeviceIteratorInit in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MultiDeviceIteratorToStringHandle in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "Executing op __inference_train_function_16842 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op AssignAddVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Equal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "   1/1221 [..............................] - ETA: 0s - accuracy: 0.0156 - loss: 12.1233Executing op GreaterEqual in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "   2/1221 [..............................] - ETA: 9:13 - accuracy: 0.0391 - loss: 11.9395WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.377246). Check your callbacks.\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.3072 - loss: 9.1385Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "Executing op __inference_test_function_28400 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op DeleteMultiDeviceIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op LogicalAnd in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Identity in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op WriteScalarSummary in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op WriteHistogramSummary in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "1221/1221 [==============================] - 233s 191ms/step - accuracy: 0.3072 - loss: 9.1385 - val_accuracy: 0.3279 - val_loss: 8.9855\n",
            "Executing op CloseSummaryWriter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Epoch 1 start at time  2020-06-20 18:59:38.471535\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "   2/1221 [..............................] - ETA: 5:08 - accuracy: 0.3281 - loss: 8.9146WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.172738). Check your callbacks.\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.2235 - loss: 8.7750Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 229s 188ms/step - accuracy: 0.2235 - loss: 8.7750 - val_accuracy: 0.2211 - val_loss: 8.6939\n",
            "Epoch 2 start at time  2020-06-20 19:03:28.258330\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.2297 - loss: 8.2915Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 230s 188ms/step - accuracy: 0.2297 - loss: 8.2915 - val_accuracy: 0.2404 - val_loss: 8.2693\n",
            "Epoch 3 start at time  2020-06-20 19:07:18.417830\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.3330 - loss: 7.3038Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 230s 188ms/step - accuracy: 0.3330 - loss: 7.3038 - val_accuracy: 0.3993 - val_loss: 6.8523\n",
            "Epoch 4 start at time  2020-06-20 19:11:08.424336\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4021 - loss: 6.6363Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 230s 188ms/step - accuracy: 0.4021 - loss: 6.6363 - val_accuracy: 0.4303 - val_loss: 6.6506\n",
            "Epoch 5 start at time  2020-06-20 19:14:58.884279\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4175 - loss: 6.4498Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 230s 188ms/step - accuracy: 0.4175 - loss: 6.4498 - val_accuracy: 0.4236 - val_loss: 6.6800\n",
            "Epoch 6 start at time  2020-06-20 19:18:48.804771\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4317 - loss: 6.2507Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 229s 188ms/step - accuracy: 0.4317 - loss: 6.2507 - val_accuracy: 0.4176 - val_loss: 6.7885\n",
            "Epoch 7 start at time  2020-06-20 19:22:38.542209\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4402 - loss: 6.1108Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 229s 188ms/step - accuracy: 0.4402 - loss: 6.1108 - val_accuracy: 0.4076 - val_loss: 7.0715\n",
            "Epoch 8 start at time  2020-06-20 19:26:28.119360\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "   2/1221 [..............................] - ETA: 5:38 - accuracy: 0.4219 - loss: 6.4041WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.194544). Check your callbacks.\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4532 - loss: 5.9076Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 229s 188ms/step - accuracy: 0.4532 - loss: 5.9076 - val_accuracy: 0.4221 - val_loss: 6.8285\n",
            "Epoch 9 start at time  2020-06-20 19:30:17.969286\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4580 - loss: 5.7763Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 229s 188ms/step - accuracy: 0.4580 - loss: 5.7763 - val_accuracy: 0.4165 - val_loss: 6.9577\n",
            "Epoch 10 start at time  2020-06-20 19:34:07.833199\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4631 - loss: 5.6356Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 229s 188ms/step - accuracy: 0.4631 - loss: 5.6356 - val_accuracy: 0.4120 - val_loss: 7.2079\n",
            "Epoch 11 start at time  2020-06-20 19:37:57.692833\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4672 - loss: 5.5048Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 229s 188ms/step - accuracy: 0.4672 - loss: 5.5048 - val_accuracy: 0.4033 - val_loss: 7.4693\n",
            "Epoch 12 start at time  2020-06-20 19:41:47.317481\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4695 - loss: 5.3999Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 229s 188ms/step - accuracy: 0.4695 - loss: 5.3999 - val_accuracy: 0.3783 - val_loss: 7.7910\n",
            "Epoch 13 start at time  2020-06-20 19:45:36.887617\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4732 - loss: 5.2665Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 229s 188ms/step - accuracy: 0.4732 - loss: 5.2665 - val_accuracy: 0.3747 - val_loss: 7.8793\n",
            "Epoch 14 start at time  2020-06-20 19:49:26.462564\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4764 - loss: 5.1293Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 230s 188ms/step - accuracy: 0.4764 - loss: 5.1293 - val_accuracy: 0.3715 - val_loss: 7.9947\n",
            "Epoch 15 start at time  2020-06-20 19:53:16.643856\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4785 - loss: 5.0187Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 229s 188ms/step - accuracy: 0.4785 - loss: 5.0187 - val_accuracy: 0.3705 - val_loss: 8.4637\n",
            "Epoch 16 start at time  2020-06-20 19:57:06.441875\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4825 - loss: 4.8966Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 230s 188ms/step - accuracy: 0.4825 - loss: 4.8966 - val_accuracy: 0.3492 - val_loss: 8.8607\n",
            "Epoch 17 start at time  2020-06-20 20:00:56.672466\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4851 - loss: 4.7760Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 229s 188ms/step - accuracy: 0.4851 - loss: 4.7760 - val_accuracy: 0.3562 - val_loss: 8.9153\n",
            "Epoch 18 start at time  2020-06-20 20:04:46.177953\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4877 - loss: 4.6655Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 230s 188ms/step - accuracy: 0.4877 - loss: 4.6655 - val_accuracy: 0.3391 - val_loss: 9.4792\n",
            "Epoch 19 start at time  2020-06-20 20:08:36.323411\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4904 - loss: 4.5577Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 229s 188ms/step - accuracy: 0.4904 - loss: 4.5577 - val_accuracy: 0.3580 - val_loss: 10.0402\n",
            "Epoch 20 start at time  2020-06-20 20:12:25.919697\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4933 - loss: 4.4454Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 229s 188ms/step - accuracy: 0.4933 - loss: 4.4454 - val_accuracy: 0.3414 - val_loss: 9.9709\n",
            "Epoch 21 start at time  2020-06-20 20:16:15.457785\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "   2/1221 [..............................] - ETA: 8:12 - accuracy: 0.4609 - loss: 4.5308WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.322413). Check your callbacks.\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.4964 - loss: 4.3369Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 229s 188ms/step - accuracy: 0.4964 - loss: 4.3369 - val_accuracy: 0.3533 - val_loss: 10.3966\n",
            "Epoch 22 start at time  2020-06-20 20:20:05.314801\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "   2/1221 [..............................] - ETA: 5:12 - accuracy: 0.4766 - loss: 4.3174WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.176236). Check your callbacks.\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.5001 - loss: 4.2312Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 230s 188ms/step - accuracy: 0.5001 - loss: 4.2312 - val_accuracy: 0.3300 - val_loss: 10.7760\n",
            "Epoch 23 start at time  2020-06-20 20:23:55.292213\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.5030 - loss: 4.1129Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 231s 189ms/step - accuracy: 0.5030 - loss: 4.1129 - val_accuracy: 0.3293 - val_loss: 10.9287\n",
            "Epoch 24 start at time  2020-06-20 20:27:46.338283\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "   2/1221 [..............................] - ETA: 9:25 - accuracy: 0.5000 - loss: 3.9765WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.380893). Check your callbacks.\n",
            "1221/1221 [==============================] - ETA: 0s - accuracy: 0.5055 - loss: 4.0103Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 230s 189ms/step - accuracy: 0.5055 - loss: 4.0103 - val_accuracy: 0.3223 - val_loss: 11.2648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kRoOUajk492o"
      },
      "source": [
        "### 4.6 Serialize and Persist Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90p0DtMIFif9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(model_path + \"deeplstm/deeplstm-glove.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tnnjf-hX2FD7",
        "colab": {}
      },
      "source": [
        "model.save_weights(model_path + \"deeplstm/context_withoutstopwords_model_epoch_25_deeplstm_glove_nomask_gpu.h5\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ELL6OBOaFud5",
        "colab": {}
      },
      "source": [
        "# full model save\n",
        "model.save(model_path + \"deeplstm/full_context_withoutstopwords_model_epoch_25_deeplstm_glove_nomask_gpu.h5\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsoxmFleFn-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "5d2e13dc-3844-4f6c-91a7-b2e5ce32d007"
      },
      "source": [
        "# Store in Tensor Flow Serving\n",
        "tf.keras.models.save_model(\n",
        "    model,\n",
        "    model_path+'deeplstm/tf-serve',\n",
        "    overwrite=True,\n",
        "    include_optimizer=True,\n",
        "    save_format=None,\n",
        "    signatures=None,\n",
        "    options=None\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Executing op StaticRegexFullMatch in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Select in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op StringJoin in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ShardedFilename in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op SaveV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Identity in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op SaveV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Pack in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MergeV2Checkpoints in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/AIML-MRC-Capstone/models/deeplstm/tf-serve/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Jl0YsArymDdF"
      },
      "source": [
        "### 4.7 Load existing models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sBwGJN07mEGY",
        "colab": {}
      },
      "source": [
        "modelname = 'context_withoutstopwords_model_epoch_24.h5'\n",
        "# modelname = 'model_epoch_24.h5'\n",
        "model.load_weights(model_path + modelname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5tVohk7bORpH"
      },
      "source": [
        "### 4.8 Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r7pxr5yHOV6m"
      },
      "source": [
        "#### 4.8.1 Eval on Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8VEUBrVHN6c_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "d92b213a-e276-4661-c9ba-d262bfc99b02"
      },
      "source": [
        "y_prediction = model.predict([test_question_sequence,test_context_sequence])\n",
        "# print y_prediction[0] should return probabilty of of each index been a start and end token"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op RangeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MultiDeviceIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_distributed_function_482623 in device /job:localhost/replica:0/task:0/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CnVyS4ONOiNO",
        "colab": {}
      },
      "source": [
        "# y_test was a list changing to numpy array\n",
        "y_test_fixed = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9_XCfB-gOpuh",
        "colab": {}
      },
      "source": [
        "# argmax is used to get the index where the max value in a list appears, and hence \n",
        "# for every index i, we can get the place of start and end token of the max probab\n",
        "start_pred = []\n",
        "end_pred = []\n",
        "for i in range(26062):\n",
        "    start_pred.append(np.argmax(y_prediction[i,:params['context_max_length']]))\n",
        "    end_pred.append(np.argmax(y_prediction[i,params['context_max_length']:]))\n",
        "    \n",
        "# compute for y_test though in this case it the max of 0 and 1 for \n",
        "# the frist half od array size for start, and rest for end\n",
        "start = []\n",
        "end = []\n",
        "for i in range(26062):\n",
        "    start.append(np.argmax(y_test_fixed[i,:params['context_max_length']]))\n",
        "    end.append(np.argmax(y_test_fixed[i,params['context_max_length']:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "138CmIXnR7LS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "981e0260-07c7-4359-fc1a-110069295e88"
      },
      "source": [
        "print(start[100:120])\n",
        "print(end[100:120])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[425, 425, 22, 425, 425, 425, 40, 68, 4, 425, 425, 425, 425, 425, 425, 425, 29, 425, 49, 5]\n",
            "[425, 425, 22, 425, 425, 425, 40, 70, 4, 425, 425, 425, 425, 425, 425, 425, 30, 425, 51, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UPx7_OKMR8fX",
        "colab": {}
      },
      "source": [
        "y_predicted_new = np.zeros((26062,params['context_max_length']))\n",
        "for i in range(26062):\n",
        "    y_predicted_new[i,start_pred[i]:end_pred[i]+1] = 1\n",
        "    \n",
        "y_test_new = np.zeros((26062,params['context_max_length']))\n",
        "for i in range(26062):\n",
        "    y_test_new[i,start[i]:end[i]+1] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0tD4wUQ09SRb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0e4dba1-ca98-4ada-d37e-0efad693cf22"
      },
      "source": [
        "len(y_test_new[testindex])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "677"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 444
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v78fhG3Tdhx5"
      },
      "source": [
        "#### 4.8.2 Create a common function to predict and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v6KDfM25dhZr",
        "colab": {}
      },
      "source": [
        "def predit_test(context, question):\n",
        "  # get sequence for context and question\n",
        "  c_ = preprocess_text(context)\n",
        "  q_ = preprocess_text(question,stopword_removal=False)\n",
        "  c,q = generate_question_context_sequence(c_, q_)  \n",
        "  y_ = model.predict([q,c])    \n",
        "  # # for i in range(26062):\n",
        "  s = np.argmax(y_[0,:params['context_max_length']])\n",
        "  e = np.argmax(y_[0,params['context_max_length']:])\n",
        "  answer = span_to_answer((s,e),c_[0])\n",
        "  \n",
        "  # print(c.shape,q.shape,y_.shape,s,e,answer)  \n",
        "  # print(s, e)\n",
        "  return c_,q_,[s,e],y_,answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vNqWwnNX5EAF"
      },
      "source": [
        "##### 4.8.2.1 TEST 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aqKrcmCae0z8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "fd407491-5065-4f07-b20e-1ad3d1760daa"
      },
      "source": [
        "c='In the Mahayana, the Buddha tends not to be viewed as merely human, but as the earthly projection of a beginningless and endless, omnipresent being (see Dharmakaya) beyond the range and reach of thought. Moreover, in certain Mahayana sutras, the Buddha, Dharma and Sangha are viewed essentially as One: all three are seen as the eternal Buddha himself.'\n",
        "q='in what sutras are the buddha dharma and sangha viewed as one'\n",
        "\n",
        "# c_,q_,span,y_,answer = predit_test(test['context'].iloc[39],test['question'].iloc[39])\n",
        "c_,q_,span,y_,answer = predit_test([c],[q])\n",
        "print('ori c = ')\n",
        "pprint.pprint(test['context'].iloc[39])\n",
        "print('ori c c = ')\n",
        "pprint.pprint(test['clean_context'].iloc[39])\n",
        "print('ori q = ',test['clean_question'].iloc[39])\n",
        "print('new c')\n",
        "pprint.pprint(c_[0])\n",
        "print('new q',q_)\n",
        "\n",
        "print('predicted answer' ,answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ori c = \n",
            "('UNFPA began operations in 1969 as the United Nations Fund for Population '\n",
            " 'Activities (the name was changed in 1987) under the administration of the '\n",
            " 'United Nations Development Fund. In 1971 it was placed under the authority '\n",
            " 'of the United Nations General Assembly.')\n",
            "ori c c = \n",
            "('unfpa began operations 1969 united nations fund population activities name '\n",
            " 'changed 1987 administration united nations development fund 1971 placed '\n",
            " 'authority united nations general assembly')\n",
            "ori q =  what year did the united nations general assembly disband\n",
            "new c\n",
            "('mahayana buddha tends viewed merely human earthly projection beginningless '\n",
            " 'endless omnipresent see dharmakaya beyond range reach thought moreover '\n",
            " 'certain mahayana sutras buddha dharma sangha viewed essentially one three '\n",
            " 'seen eternal buddha')\n",
            "new q ['in what sutras are the buddha dharma and sangha viewed as one']\n",
            "predicted answer mahayana\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6PEKF0GU5SZg"
      },
      "source": [
        "##### 4.8.2.2 TEST 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YnSg9CSCxy2k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8590e314-efad-4374-cfff-c745b737bad0"
      },
      "source": [
        "c = 'Mary went to the bathroom. John is in the playground.John moved to the hallway. John picked up the football.Mary travelled to the office'\n",
        "q = 'Where is john?'\n",
        "c_,q_,span,y_,answer = predit_test([c],[q])\n",
        "print('predicted answer' ,answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted answer travelled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YUF1OjiM5Uh5"
      },
      "source": [
        "##### 4.8.2.3 TEST 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jSBOvRP90Rs9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8efcdbc2-6875-488e-df12-3edc09cf2d6b"
      },
      "source": [
        "c='The Union health ministry said that so far, 95,527 COVID-19 patients have recovered in the country.The recovery rate is now 48.07 percent, Lav Agrawal, Joint Secretary, Health Ministry claimed. We have asked all states to analyse the trajectory of the cases in their respective states. If a state thinks that it needs to set up temporary COVID-19 care centres then it must do so, he added.'\n",
        "q='what is the recovery rate'\n",
        "c_,q_,span,y_,answer = predit_test([c],[q])\n",
        "print('predicted answer' ,answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted answer ministry\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AHxti5JDP4UD"
      },
      "source": [
        "#### 4.8.3 See true vs predict for all samples in test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y9qs-no68n52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d4b94e03-b0d1-4932-b46a-e557b1295b62"
      },
      "source": [
        "testindex = 54\n",
        "print(\"Ori Cont = \")\n",
        "pprint.pprint(test['context'].iloc[testindex])\n",
        "print(\"CLean Cont = \")\n",
        "pprint.pprint(test['clean_context'].iloc[testindex])\n",
        "print('Question = ',test['question'].iloc[testindex])\n",
        "print('Clean Question = ',test['clean_question'].iloc[testindex])\n",
        "print('Answer = ',test['answer'].iloc[testindex])\n",
        "print('Clean Answer = ',test['clean_answer'].iloc[testindex])\n",
        "print('AS,AE = ',test['answer_word_span'].iloc[testindex])\n",
        "print('pAS,pAE = ',(start_pred[testindex],end_pred[testindex]))\n",
        "print(\"Predict answer =\",span_to_answer([start_pred[testindex],end_pred[testindex]],test['clean_context'].iloc[testindex]))\n",
        "# print(\"encoded len\", len(y_train[testindex]))\n",
        "# print(\"encoded \", len(y_test[testindex]))\n",
        "print(\"test data encoded \",y_test_new[testindex])\n",
        "print(\"predict data  encoded \",y_predicted_new[testindex])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ori Cont = \n",
            "('Christian missions established Western educational institutions in the '\n",
            " \"Protectorates. Under Britain's policy of indirect rule and validation of \"\n",
            " 'Islamic tradition, the Crown did not encourage the operation of Christian '\n",
            " 'missions in the northern, Islamic part of the country. Some children of the '\n",
            " 'southern elite went to Great Britain to pursue higher education. By '\n",
            " 'independence in 1960, regional differences in modern educational access were '\n",
            " 'marked. The legacy, though less pronounced, continues to the present-day. '\n",
            " \"Imbalances between North and South were expressed in Nigeria's political \"\n",
            " 'life as well. For instance, northern Nigeria did not outlaw slavery until '\n",
            " '1936 whilst in other parts of Nigeria slavery was abolished soon after '\n",
            " 'colonialism.')\n",
            "CLean Cont = \n",
            "('christian missions established western educational institutions '\n",
            " 'protectorates britains policy indirect rule validation islamic tradition '\n",
            " 'crown encourage operation christian missions northern islamic part country '\n",
            " 'children southern elite went great britain pursue higher education '\n",
            " 'independence 1960 regional differences modern educational access marked '\n",
            " 'legacy though less pronounced continues presentday imbalances north south '\n",
            " 'expressed nigerias political life well instance northern nigeria outlaw '\n",
            " 'slavery 1936 whilst parts nigeria slavery abolished soon colonialism')\n",
            "Question =  What religion built Western schools in Nigeria?\n",
            "Clean Question =  what religion built western schools in nigeria\n",
            "Answer =  Christian\n",
            "Clean Answer =  christian\n",
            "AS,AE =  (0, 0)\n",
            "pAS,pAE =  (0, 0)\n",
            "Predict answer = christian\n",
            "test data encoded  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "predict data  encoded  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DYHNErgrQILC"
      },
      "source": [
        "#### 4.8.4 Accuracy Metrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FmwzLM3WSriL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6648b298-8c97-4500-af90-725b6f07a6b9"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.metrics import f1_score,accuracy_score,precision_score\n",
        "params['prediction.accuracy.score'] = accuracy_score(y_test_new,y_predicted_new)\n",
        "params['prediction.macrof1.score'] = f1_score(y_test_new,y_predicted_new,average=\"macro\")\n",
        "params['prediction.microf1.score'] = f1_score(y_test_new,y_predicted_new,average=\"micro\")\n",
        "\n",
        "print(\"Micro f1-score on test data is \",params['prediction.microf1.score'])\n",
        "print(\"Macro f1-score on test data is \",params['prediction.macrof1.score'])\n",
        "print(\"Accuracy on test data is \",params['prediction.accuracy.score'])\n",
        "\n",
        "# update params\n",
        "updateparams()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Micro f1-score on test data is  0.23956708665048215\n",
            "Macro f1-score on test data is  0.0031982013964219195\n",
            "Accuracy on test data is  0.33097997083876907\n",
            "params.jsop updated and can be found in  /storage/models/params.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RY02U6dQSCMU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "7bc096c4-caf0-46fe-c375-67ea2c3538b4"
      },
      "source": [
        "pprint.pprint(params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_max_length': 426,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 100,\n",
            " 'prediction.accuracy.score': 0.3761798787506715,\n",
            " 'prediction.macrof1.score': 0.00583615881279302,\n",
            " 'prediction.microf1.score': 0.2751746082042751,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': (26062, 16),\n",
            " 'test_span_outofrange': 0,\n",
            " 'tokenizer_num_words': 80000,\n",
            " 'train_shape': (78183, 16),\n",
            " 'train_span_outofrange': 0,\n",
            " 'training.batch_size': 64,\n",
            " 'training.epochs': 25,\n",
            " 'training.train_length': 78183,\n",
            " 'training.train_steps': 1221,\n",
            " 'training.val_length': 26061,\n",
            " 'training.val_steps': 814,\n",
            " 'val_shape': (26061, 16),\n",
            " 'val_span_outofrange': 0,\n",
            " 'vocab_size': 100850}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rI40rd0bQZgn"
      },
      "source": [
        "#### 4.8.5 Store the result to build more meterics "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p5T9BSNgS-uG",
        "colab": {}
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "summary = PrettyTable()\n",
        "summary.title = \"Test vs Prediction\"\n",
        "summary.field_names = [\"ID\",\n",
        "                       \"Clean Question\",\n",
        "                       \"Clean Context\",\n",
        "                       \"True Answer\",\n",
        "                       \"True AS and AE\",\n",
        "                       \"Predict Answer\",\n",
        "                       \"Predict AS and AE\"]\n",
        "result_df = pd.DataFrame(columns=summary.field_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6TdUqImSC1_I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9097746e-2e76-4449-a3a5-99117e02be63"
      },
      "source": [
        "for i in tqdm(range(26062)):  \n",
        "  values = [test['id'].iloc[i], \n",
        "            test['clean_question'].iloc[i], \n",
        "            test['clean_context'].iloc[i], \n",
        "            test['clean_answer'].iloc[i], \n",
        "            test['answer_word_span'].iloc[i],\n",
        "            span_to_answer([start_pred[i],end_pred[i]],test['clean_context'].iloc[i]),\n",
        "            (start_pred[i],end_pred[i])]\n",
        "  zipped = zip(summary.field_names, values)\n",
        "  a_dictionary = dict(zipped)\n",
        "  result_df = result_df.append(a_dictionary,ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 26062/26062 [02:03<00:00, 211.59it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TySMZHmbJB1r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "ca78e092-4790-46e1-db4d-9923b7226cf0"
      },
      "source": [
        "result_df.to_csv(model_path + \"deeplstm_results.csv\")  \n",
        "result_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Clean Question</th>\n",
              "      <th>Clean Context</th>\n",
              "      <th>True Answer</th>\n",
              "      <th>True AS and AE</th>\n",
              "      <th>Predict Answer</th>\n",
              "      <th>Predict AS and AE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>572616bfec44d21400f3d8a8</td>\n",
              "      <td>who is the 1855 room named after</td>\n",
              "      <td>directly underneath state apartments suite sli...</td>\n",
              "      <td>emperor napoleon iii of france</td>\n",
              "      <td>(45, 49)</td>\n",
              "      <td></td>\n",
              "      <td>(70, 70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5ad2e80c604f3c001a3fd97f</td>\n",
              "      <td>what five great cardinals once ruled france</td>\n",
              "      <td>early modern times cardinals often important r...</td>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "      <td>(-1, -1)</td>\n",
              "      <td>cardinals ruled</td>\n",
              "      <td>(45, 46)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>57279185f1498d1400e8fc5e</td>\n",
              "      <td>by understanding what does vaisesika school be...</td>\n",
              "      <td>vaieika philosophy naturalist school form atom...</td>\n",
              "      <td>world of experience</td>\n",
              "      <td>(35, 37)</td>\n",
              "      <td>atomism</td>\n",
              "      <td>(5, 5)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5a566e5a6349e2001acdcd46</td>\n",
              "      <td>who does the prime minister appoint</td>\n",
              "      <td>king appoints prime minister legislature also ...</td>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "      <td>(-1, -1)</td>\n",
              "      <td></td>\n",
              "      <td>(50, 50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5725bcba38643c19005acc25</td>\n",
              "      <td>when did the first intifada break out</td>\n",
              "      <td>first intifada palestinian uprising israeli ru...</td>\n",
              "      <td>1987</td>\n",
              "      <td>(7, 7)</td>\n",
              "      <td>1987</td>\n",
              "      <td>(7, 7)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         ID  ... Predict AS and AE\n",
              "0  572616bfec44d21400f3d8a8  ...          (70, 70)\n",
              "1  5ad2e80c604f3c001a3fd97f  ...          (45, 46)\n",
              "2  57279185f1498d1400e8fc5e  ...            (5, 5)\n",
              "3  5a566e5a6349e2001acdcd46  ...          (50, 50)\n",
              "4  5725bcba38643c19005acc25  ...            (7, 7)\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kCKNvmOaQtx_"
      },
      "source": [
        "## 5 More Evaluations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b2emUc95Q53a"
      },
      "source": [
        "**Read the result dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "geCm-V3SQ0v7",
        "colab": {}
      },
      "source": [
        "result_df = result_df.read_csv(model_path + \"deeplstm_results.csv\")  \n",
        "result_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mz6uetkTRLrz"
      },
      "source": [
        "### 5.1 EM (Exact Match)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5uTD7fZZUhyw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "outputId": "a05b4f5c-0d3b-4c85-c656-97c3f1a1a2f7"
      },
      "source": [
        "result_df[result_df['Predict Answer'] == result_df['True Answer']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Clean Question</th>\n",
              "      <th>Clean Context</th>\n",
              "      <th>True Answer</th>\n",
              "      <th>True AS and AE</th>\n",
              "      <th>Predict Answer</th>\n",
              "      <th>Predict AS and AE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5725bcba38643c19005acc25</td>\n",
              "      <td>when did the first intifada break out</td>\n",
              "      <td>first intifada palestinian uprising israeli ru...</td>\n",
              "      <td>1987</td>\n",
              "      <td>(7, 7)</td>\n",
              "      <td>1987</td>\n",
              "      <td>(7, 7)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>57240b550ba9f01400d97b4c</td>\n",
              "      <td>what year was the public worship regulation ac...</td>\n",
              "      <td>1874 general election disraeli returned power ...</td>\n",
              "      <td>1874</td>\n",
              "      <td>(0, 0)</td>\n",
              "      <td>1874</td>\n",
              "      <td>(0, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5726aeff5951b619008f7a3e</td>\n",
              "      <td>when did commercial sea hunts on norfolk islan...</td>\n",
              "      <td>cetaceans historically abundant around island ...</td>\n",
              "      <td>1956</td>\n",
              "      <td>(9, 9)</td>\n",
              "      <td>1956</td>\n",
              "      <td>(9, 9)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>56dfb9fe231d4119001abd17</td>\n",
              "      <td>in what century was the process of using hops ...</td>\n",
              "      <td>traditional english ale made solely fermented ...</td>\n",
              "      <td>15th</td>\n",
              "      <td>(15, 15)</td>\n",
              "      <td>15th</td>\n",
              "      <td>(15, 15)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>5725da9f89a1e219009abfbe</td>\n",
              "      <td>where did the celts who settled in galatia pas...</td>\n",
              "      <td>celts settled galatia came thrace leadership l...</td>\n",
              "      <td>thrace</td>\n",
              "      <td>(4, 4)</td>\n",
              "      <td>thrace</td>\n",
              "      <td>(4, 4)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25894</th>\n",
              "      <td>572778755951b619008f8abb</td>\n",
              "      <td>in what year was phonautograms patented</td>\n",
              "      <td>phonautograph patented lon scott 1857 used vib...</td>\n",
              "      <td>1857</td>\n",
              "      <td>(4, 4)</td>\n",
              "      <td>1857</td>\n",
              "      <td>(4, 4)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25912</th>\n",
              "      <td>56fdfd72761e401900d28c92</td>\n",
              "      <td>what is the name of a computer that has many c...</td>\n",
              "      <td>supercomputers particular often highly unique ...</td>\n",
              "      <td>supercomputers</td>\n",
              "      <td>(0, 0)</td>\n",
              "      <td>supercomputers</td>\n",
              "      <td>(0, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25983</th>\n",
              "      <td>56bfb789a10cfb1400551273</td>\n",
              "      <td>what album did she rerelease in spanish</td>\n",
              "      <td>beyoncs music generally rb also incorporates p...</td>\n",
              "      <td>bday</td>\n",
              "      <td>(37, 37)</td>\n",
              "      <td>bday</td>\n",
              "      <td>(37, 37)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25990</th>\n",
              "      <td>57262c8738643c19005ad29f</td>\n",
              "      <td>what year was the republic of korea established</td>\n",
              "      <td>resultant south korean government promulgated ...</td>\n",
              "      <td>1948</td>\n",
              "      <td>(10, 10)</td>\n",
              "      <td>1948</td>\n",
              "      <td>(17, 17)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25994</th>\n",
              "      <td>5705f1f752bb8914006896fa</td>\n",
              "      <td>what year did the founders grandson succeed hi...</td>\n",
              "      <td>third john walter founders grandson succeeded ...</td>\n",
              "      <td>1847</td>\n",
              "      <td>(7, 7)</td>\n",
              "      <td>1847</td>\n",
              "      <td>(7, 7)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1405 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                             ID  ... Predict AS and AE\n",
              "4      5725bcba38643c19005acc25  ...            (7, 7)\n",
              "8      57240b550ba9f01400d97b4c  ...            (0, 0)\n",
              "9      5726aeff5951b619008f7a3e  ...            (9, 9)\n",
              "31     56dfb9fe231d4119001abd17  ...          (15, 15)\n",
              "35     5725da9f89a1e219009abfbe  ...            (4, 4)\n",
              "...                         ...  ...               ...\n",
              "25894  572778755951b619008f8abb  ...            (4, 4)\n",
              "25912  56fdfd72761e401900d28c92  ...            (0, 0)\n",
              "25983  56bfb789a10cfb1400551273  ...          (37, 37)\n",
              "25990  57262c8738643c19005ad29f  ...          (17, 17)\n",
              "25994  5705f1f752bb8914006896fa  ...            (7, 7)\n",
              "\n",
              "[1405 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rm4YmnfQNqQC",
        "colab": {}
      },
      "source": [
        "ematch = result_df[result_df['Predict Answer'] == result_df['True Answer']].shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BF44727PN1dq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a1056b7-8ba1-4e3a-b900-990973d74bbd"
      },
      "source": [
        "params['prediction.em.score'] = ematch / params['test_shape'][0]\n",
        "updateparams()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "params.jsop updated and can be found in  /content/drive/My Drive/AIML-MRC-Capstone/models/params.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZbO5yYzRTTyu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "bb4db338-38f2-42b6-bfce-4fc39787830c"
      },
      "source": [
        "showparams()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_max_length': 426,\n",
            " 'context_pad_seq': 'post',\n",
            " 'embedding_size': 300,\n",
            " 'prediction.accuracy.score': 0.05371805694114036,\n",
            " 'prediction.em.score': 0.05390990714450157,\n",
            " 'prediction.macrof1.score': 0.02226535434650852,\n",
            " 'prediction.microf1.score': 0.0851604180369802,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'post',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': (26062, 16),\n",
            " 'test_span_outofrange': 0,\n",
            " 'train_shape': (78183, 16),\n",
            " 'train_span_outofrange': 0,\n",
            " 'training.batch_size': 64,\n",
            " 'training.epochs': 25,\n",
            " 'training.train_length': 78183,\n",
            " 'training.train_steps': 1221,\n",
            " 'training.val_length': 26061,\n",
            " 'training.val_steps': 814,\n",
            " 'val_shape': (26061, 16),\n",
            " 'val_span_outofrange': 0,\n",
            " 'vocab_size': 100850}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vlR2BYOT66Lk"
      },
      "source": [
        "# **<font color=\"GREEN\">END OF THE NOTEBOOK </font>**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6u50QkJn6-om",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}