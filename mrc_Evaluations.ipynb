{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mrc_Evaluations.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOstDLIfz7AeI/3QjQmSAWs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandipanbasu/aiml-capstone/blob/master/mrc_Evaluations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DRLVpTJznGZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9fb2eb89-1e4c-4e0e-fdea-2db815c1a7bb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOGCXAgWaIsd",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaepomVyaJfm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "514891a3-4d61-4008-b183-4d175cfc838a"
      },
      "source": [
        "import warnings\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "tf.debugging.set_log_device_placement(False)\n",
        "import pickle\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pprint\n",
        "from tensorflow.keras.layers import Bidirectional,LSTM,Dense,Dropout,BatchNormalization,Flatten,Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from numpy import array\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import f1_score,accuracy_score,precision_score\n",
        "from prettytable import PrettyTable\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "model_path = \"/content/drive/My Drive/AIML-MRC-Capstone/models/\"\n",
        "dataset_path = \"/content/drive/My Drive/AIML-MRC-Capstone/datasets/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuIsS7WFh76y",
        "colab_type": "text"
      },
      "source": [
        "# Load Google Bucket as drive \n",
        "\n",
        "<font color=red>SKIP THIS SECTION</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCaxxOEXh8GK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "4daf1eaa-3b6f-482d-b161-dbb5162207d1"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "project_id = 'ai-ml-capstone'\n",
        "!gcloud config set project {project_id}\n",
        "!gsutil ls\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-70c76435d261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mproject_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ai-ml-capstone'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gcloud config set project {project_id}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporary\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mclear_output\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_noop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m       \u001b[0m_gcloud_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0m_install_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mcolab_tpu_addr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36m_gcloud_login\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# https://github.com/jupyter/notebook/issues/3159\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mgcloud_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         )\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3NaG4vBiPvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdNVzqJ_jfs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir gbucket\n",
        "!gcsfuse --implicit-dirs aiml-capstone gbucket \n",
        "# !umount gbucket"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in-L5Mi9kEir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58f97f72-6ef3-42a4-bafe-2104ab57d132"
      },
      "source": [
        "!ls gbucket/lstmbaseline-0/tf-serve/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saved_model.pb\tvariables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUPKTSR-GWt5",
        "colab_type": "text"
      },
      "source": [
        "# List of Models\n",
        "\n",
        "As part of our capstone, we are in process of evaluating the following models\n",
        "\n",
        "Data | Model | On GPU | Masking | Padding | Epoch | Location | \n",
        "--- | --- | --- | --- | --- | --- | --- | \n",
        "Without stopwords | SVM | No | - | - | - | [here](https://storage.cloud.google.com/aiml-capstone/svm/)\n",
        "Without stopwords | LSTM Baseline | No | No | Pre | 25 | [here](https://storage.cloud.google.com/aiml-capstone/lstmbaseline-0/full_context_withoutstopwords_model_epoch_lstmbaseline0_nomask_gpu.h5)\n",
        "Without stopwords | Deep LSTM + GloVe | Yes | No | Pre | 25 | [here](https://storage.cloud.google.com/aiml-capstone/deeplstm/full_context_withoutstopwords_model_epoch_deeplstm_gpu.h5)\n",
        "Without stopwords | Bi-LSTM + GloVe | No | No | Pre | 25 | [here](https://storage.cloud.google.com/aiml-capstone/bilstm/full_context_withoutstopwords_model_epoch_10_bilstm_cpu.h5)\n",
        "Without stopwords | Bi-LSTM + GloVe + Q2C Attention | Yes | No | Pre | 25 | [here](https://storage.cloud.google.com/aiml-capstone/bilstm-q2c-attention-glove/full_context_withoutstopwords_nomask_epoch_25_bilstm_q2c-attention_glove_gpu.h5)\n",
        "Without stopwords | Bi-LSTM + GloVe + Q2C-C2Q Attention | Yes | No | Pre | 25 | [here](https://storage.cloud.google.com/aiml-capstone/bilstm-bidaf-glove/full_context_withoutstopwords_model_epoch_25_bilstm_bidaf_glove_nomask_gpu.h5)\n",
        "With Stopwords | LSTM Baseline + Universal Sentence Encode | Yes | No | Pre | 25 |\n",
        "With Stopwords | Bi-LSTM + Universal Sentence Encoder | Yes | No | Pre | 25 | \n",
        "With Stopwords | Bi-LSTM + Q2C Attention + Universal Sentence Encoder | Yes | No | Pre | 25 |\n",
        "-- | -- | -- | -- | -- | -- |\n",
        "With Stopwords | BERT + Cased_L-12_H-768_A-12 + DeepPavlov | Transfer | Learing\n",
        "With Stopwords | BERT + Uncased_L-24_H-1024_A-24 + Huggingface | Transfer | Learing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_GOOYs6cXfu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "39fe5af9-f856-46a8-9304-0e5f17daf748"
      },
      "source": [
        "# List of all models and its meta info\n",
        "list_of_models = [\n",
        "                  {\n",
        "                    \"id\":\"lstm-baseline\",\n",
        "                    \"name\":\"LSTM Baseline\",\n",
        "                    \"type\":\"Without stopwords\",\n",
        "                    \"loc\":\"/content/drive/My Drive/AIML-MRC-Capstone/models/lstmbaseline-0/full_context_withoutstopwords_model_epoch_lstmbaseline0_nomask_gpu.h5\"\n",
        "                  },\n",
        "                  {\n",
        "                    \"id\":\"deeplstm-glove\",\n",
        "                    \"name\":\"Deep LSTM + GloVe\",\n",
        "                    \"type\":\"Without stopwords\",\n",
        "                    \"loc\":\"/content/drive/My Drive/AIML-MRC-Capstone/models/deeplstm/full_context_withoutstopwords_model_epoch_25_deeplstm_glove_nomask_gpu.h5\"\n",
        "                  },  \n",
        "                  {\n",
        "                    \"id\":\"bilstm-glove\",\n",
        "                    \"name\":\"Bi-LSTM + GloVe\",\n",
        "                    \"type\":\"Without stopwords\",\n",
        "                    \"loc\":\"/content/drive/My Drive/AIML-MRC-Capstone/models/bilstm/full_context_withoutstopwords_model_epoch_25_bilstm_glove_nomask_gpu.h5\"\n",
        "                  },\n",
        "                  {\n",
        "                    \"id\":\"bilstm-glove-q2c-attention\",\n",
        "                    \"name\":\"Bi-LSTM + GloVe + Q2C Attention\",\n",
        "                    \"type\":\"Without stopwords\",\n",
        "                    \"loc\":\"/content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-q2c-attention-glove/full_context_withoutstopwords_model_epoch_25_bilstm_q2c-attention_glove.h5\"\n",
        "                  },  \n",
        "                  {\n",
        "                    \"id\":\"bilstm-bidaf-glove\",\n",
        "                    \"name\":\"Bi-LSTM + GloVe + Q2C-C2Q Attention\",\n",
        "                    \"type\":\"Without stopwords\",\n",
        "                    \"loc\":\"/content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-bidaf-glove/full_context_withoutstopwords_model_epoch_25_bilstm_bidaf_glove_nomask_gpu_after_fix.h5\"\n",
        "                  },\n",
        "                  {\n",
        "                    \"id\":\"lstmbaseline-use-withstop\",\n",
        "                    \"name\":\"LSTM Baseline + Universal Sentence Encode\",\n",
        "                    \"type\":\"With stopwords\",\n",
        "                    \"loc\":\"/content/drive/My Drive/AIML-MRC-Capstone/models/lstmbaseline-use-withstop/full_context_withstopwords_model_epoch_25_lstmbaseline0_nomask_gpu.h5\"\n",
        "                  }, \n",
        "                  {\n",
        "                    \"id\":\"bilstm-use-withstop\",\n",
        "                    \"name\":\"Bi-LSTM + Universal Sentence Encode\",\n",
        "                    \"type\":\"With stopwords\",\n",
        "                    \"loc\":\"/content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-use-withstop/full_context_withstopwords_model_epoch_25_bilstm_use_nomask_gpu.h5\"\n",
        "                  },  \n",
        "                  {\n",
        "                    \"id\":\"bilstm-q2c-attention-use-withstop\",\n",
        "                    \"name\":\"Bi-LSTM + Q2C Attention + Universal Sentence Encode\",\n",
        "                    \"type\":\"With stopwords\",\n",
        "                    \"loc\":\"/content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-q2c-attention-use-withstop/full_context_withstopwords_model_epoch_25_bilstm_q2c-attention_use.h5\"\n",
        "                  },                                                       \n",
        "                  {\n",
        "                    \"id\":\"bert-deeppavlov\",\n",
        "                    \"name\":\"BERT + Cased_L-12_H-768_A-12 + DeepPavlov\",\n",
        "                    \"type\":\"BERT\",\n",
        "                    \"loc\":\"/content/drive/My Drive/AIML-MRC-Capstone/models/bert/bert-results.csv\"\n",
        "                  },\n",
        "                  {\n",
        "                    \"id\":\"bert-huggingface\",\n",
        "                    \"name\":\"BERT + Uncased_L-24_H-1024_A-24 + Huggingface\",\n",
        "                    \"type\":\"BERT\",\n",
        "                    \"loc\":\"/content/drive/My Drive/AIML-MRC-Capstone/models/bert/bert-huggingface-results.csv\"\n",
        "                  }                                                                                          \n",
        "                  ]\n",
        "\n",
        "list_of_models\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 'lstm-baseline',\n",
              "  'loc': '/content/drive/My Drive/AIML-MRC-Capstone/models/lstmbaseline-0/full_context_withoutstopwords_model_epoch_lstmbaseline0_nomask_gpu.h5',\n",
              "  'name': 'LSTM Baseline',\n",
              "  'type': 'Without stopwords'},\n",
              " {'id': 'deeplstm-glove',\n",
              "  'loc': '/content/drive/My Drive/AIML-MRC-Capstone/models/deeplstm/full_context_withoutstopwords_model_epoch_25_deeplstm_glove_nomask_gpu.h5',\n",
              "  'name': 'Deep LSTM + GloVe',\n",
              "  'type': 'Without stopwords'},\n",
              " {'id': 'bilstm-glove',\n",
              "  'loc': '/content/drive/My Drive/AIML-MRC-Capstone/models/bilstm/full_context_withoutstopwords_model_epoch_25_bilstm_glove_nomask_gpu.h5',\n",
              "  'name': 'Bi-LSTM + GloVe',\n",
              "  'type': 'Without stopwords'},\n",
              " {'id': 'bilstm-glove-q2c-attention',\n",
              "  'loc': '/content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-q2c-attention-glove/full_context_withoutstopwords_model_epoch_25_bilstm_q2c-attention_glove.h5',\n",
              "  'name': 'Bi-LSTM + GloVe + Q2C Attention',\n",
              "  'type': 'Without stopwords'},\n",
              " {'id': 'bilstm-bidaf-glove',\n",
              "  'loc': '/content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-bidaf-glove/full_context_withoutstopwords_model_epoch_25_bilstm_bidaf_glove_nomask_gpu_after_fix.h5',\n",
              "  'name': 'Bi-LSTM + GloVe + Q2C-C2Q Attention',\n",
              "  'type': 'Without stopwords'},\n",
              " {'id': 'lstmbaseline-use-withstop',\n",
              "  'loc': '/content/drive/My Drive/AIML-MRC-Capstone/models/lstmbaseline-use-withstop/full_context_withstopwords_model_epoch_25_lstmbaseline0_nomask_gpu.h5',\n",
              "  'name': 'LSTM Baseline + Universal Sentence Encode',\n",
              "  'type': 'With stopwords'},\n",
              " {'id': 'bilstm-use-withstop',\n",
              "  'loc': '/content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-use-withstop/full_context_withstopwords_model_epoch_25_bilstm_use_nomask_gpu.h5',\n",
              "  'name': 'Bi-LSTM + Universal Sentence Encode',\n",
              "  'type': 'With stopwords'},\n",
              " {'id': 'bilstm-q2c-attention-use-withstop',\n",
              "  'loc': '/content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-q2c-attention-use-withstop/full_context_withstopwords_model_epoch_25_bilstm_q2c-attention_use.h5',\n",
              "  'name': 'Bi-LSTM + Q2C Attention + Universal Sentence Encode',\n",
              "  'type': 'With stopwords'},\n",
              " {'id': 'bert-deeppavlov',\n",
              "  'loc': '/content/drive/My Drive/AIML-MRC-Capstone/models/bert/bert-results.csv',\n",
              "  'name': 'BERT + Cased_L-12_H-768_A-12 + DeepPavlov',\n",
              "  'type': 'BERT'},\n",
              " {'id': 'bert-huggingface',\n",
              "  'loc': '/content/drive/My Drive/AIML-MRC-Capstone/models/bert/bert-huggingface-results.csv',\n",
              "  'name': 'BERT + Uncased_L-24_H-1024_A-24 + Huggingface',\n",
              "  'type': 'BERT'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfm8h4IBSGbh",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEtw1J-aPecV",
        "colab_type": "text"
      },
      "source": [
        "## bAbi \n",
        "\n",
        "Reference Paper = https://arxiv.org/pdf/1502.05698.pdf \n",
        "\n",
        "GitHub - https://github.com/facebookarchive/bAbI-tasks\n",
        "\n",
        "![alt text](https://storage.cloud.google.com/aiml-capstone/Screenshot%202020-06-20%20at%2011.11.50%20AM.png)\n",
        "![alt text](https://storage.cloud.google.com/aiml-capstone/Screenshot%202020-06-20%20at%2011.11.03%20AM.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ5nidQ8SVog",
        "colab_type": "text"
      },
      "source": [
        "## SQuAD test dataset and published dev set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACmlhKB1S1ZF",
        "colab_type": "text"
      },
      "source": [
        "Refer to this eval metrics - https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/\n",
        "\n",
        "Eval dataset from SQuAD - https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGFyqInm7ZD0",
        "colab_type": "text"
      },
      "source": [
        "## News Domain Specific Evaluations\n",
        "\n",
        "Test on Sample News Context, Question and Answer pairs ??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Yw8C9nY7uXT",
        "colab_type": "text"
      },
      "source": [
        "## "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDyvisumUImJ",
        "colab_type": "text"
      },
      "source": [
        "# Common Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XtBcy2Qwm2-c"
      },
      "source": [
        "## Custom function for preprocessing of context and question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LFr3-S_Gm9FX",
        "colab": {}
      },
      "source": [
        "# remove unwanted chars\n",
        "# convert to lowercase\n",
        "# remove unwanted spaces\n",
        "# remove stop words\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "## reference \n",
        "def decontracted(phrase):\n",
        "    \"\"\"\n",
        "    This function remooves punctuation from given sentence.\n",
        "    \"\"\"\n",
        "\n",
        "    if(phrase is np.nan):\n",
        "      return 'impossible'      \n",
        "\n",
        "    try:      \n",
        "      # specific\n",
        "      phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "      phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "      # general\n",
        "      phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "      phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "      phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "      phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "      phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "      phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "      phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "      phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "      \n",
        "      # string operation\n",
        "      phrase = phrase.replace('\\\\r', ' ')\n",
        "      phrase = phrase.replace('\\\\\"', ' ')\n",
        "      phrase = phrase.replace('\\\\n', ' ')\n",
        "\n",
        "      phrase = re.sub('[^A-Za-z0-9]+', ' ', phrase.lower())\n",
        "    except:\n",
        "      print(phrase)  \n",
        "    \n",
        "    return phrase\n",
        "\n",
        "def preprocess_text(corpus, text_lower_case=True, \n",
        "                      special_char_removal=True, stopword_removal=True, remove_digits=False):    \n",
        "    normalized_text = []\n",
        "    # normalize each document in the corpus\n",
        "    for doc in corpus:\n",
        "        # doc = decontracted(doc)\n",
        "        # lowercase the text    \n",
        "        if text_lower_case:\n",
        "            doc = doc.lower()\n",
        "        # remove special characters and\\or digits    \n",
        "        if special_char_removal:\n",
        "            # insert spaces between special characters to isolate them    \n",
        "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
        "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
        "            doc = remove_special_characters(doc, remove_digits=remove_digits) \n",
        "\n",
        "        if stopword_removal:\n",
        "            doc = remove_stopwords(doc)\n",
        "\n",
        "        normalized_text.append(doc)\n",
        "        \n",
        "    return normalized_text\n",
        "\n",
        "def remove_special_characters(text, remove_digits=False):\n",
        "    #Using regex\n",
        "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "def remove_stopwords(text):  \n",
        "    word_tokens = word_tokenize(text) \n",
        "    filtered_sentence = [w for w in word_tokens if not w in stop_words]   \n",
        "    filtered_sentence = [] \n",
        "    for w in word_tokens: \n",
        "        if w not in stop_words: \n",
        "            filtered_sentence.append(w)                 \n",
        "    return ' '.join(filtered_sentence)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "20-D8HBeOf_p"
      },
      "source": [
        "## Answer Span from Context and Answer, and reverse for predicted spans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vbM8z2AEjxKK",
        "colab": {}
      },
      "source": [
        "def tokenize(sentence):\n",
        "    \"\"\"\n",
        "    Returns tokenised words.\n",
        "    \"\"\"\n",
        "    return nltk.word_tokenize(sentence)\n",
        "\n",
        "def answer_span(context,ans):\n",
        "    \"\"\"\n",
        "    This funtion returns anwer span start index and end index.\n",
        "    \"\"\"\n",
        "    ans_token = tokenize(ans)\n",
        "    con_token = tokenize(context)\n",
        "    ans_len = len(ans_token)\n",
        "    \n",
        "    if ans_len!=0 and ans_token[0] in con_token:\n",
        "    \n",
        "        indices = [i for i, x in enumerate(con_token) if x == ans_token[0]]        \n",
        "        try:\n",
        "\n",
        "            if(len(indices)>1):\n",
        "                start = [i for i in indices if (con_token[i:i+ans_len] == ans_token) ]\n",
        "                end = start[0] + ans_len - 1\n",
        "                return start[0],end\n",
        "\n",
        "            else:\n",
        "                start = con_token.index(ans_token[0])\n",
        "                end = start + ans_len - 1\n",
        "                return start,end\n",
        "        except:\n",
        "            return -1,-1\n",
        "    else:\n",
        "        return -1,-1\n",
        "\n",
        "def span_to_answer(span, context):\n",
        "  con_token = tokenize(context)  \n",
        "  return ' '.join(con_token[span[0]:span[1]+1])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_sveyxKK5j8q"
      },
      "source": [
        "## Update and persist params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K170rfN15qGP",
        "colab": {}
      },
      "source": [
        "### SAVE PARAMS\n",
        "# Writing to sample.json \n",
        "\n",
        "def updateparams():\n",
        "  with open(model_path + \"params.json\", \"w\") as p: \n",
        "    p.write(json.dumps(params))\n",
        "  print(\"params.jsop updated and can be found in \", model_path + \"params.json\")  \n",
        "\n",
        "# updateparams()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yYMDmMJNU9mw",
        "colab": {}
      },
      "source": [
        "def showparams(params):\n",
        "  pprint.pprint(params)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SklWt_NbVzOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "84cf5e14-7d79-47d8-c129-5bf695c334bd"
      },
      "source": [
        "def loadparams(name='params_withoutstopwords.json'):\n",
        "  with open(model_path + name) as f:\n",
        "    params = json.load(f)\n",
        "  return params  \n",
        "\n",
        "params = loadparams(name='params_withoutstopwords.json')\n",
        "showparams(params)\n",
        "showparams(loadparams())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_max_length': 426,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 300,\n",
            " 'prediction.accuracy.score': 0.3322461821809531,\n",
            " 'prediction.macrof1.score': 0.011907387665813255,\n",
            " 'prediction.microf1.score': 0.25672221926414995,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': [26062, 16],\n",
            " 'test_span_outofrange': 0,\n",
            " 'train_shape': [78183, 16],\n",
            " 'train_span_outofrange': 0,\n",
            " 'training.batch_size': 64,\n",
            " 'training.epochs': 25,\n",
            " 'training.train_length': 78183,\n",
            " 'training.train_steps': 1221,\n",
            " 'training.val_length': 26061,\n",
            " 'training.val_steps': 814,\n",
            " 'val_shape': [26061, 16],\n",
            " 'val_span_outofrange': 0,\n",
            " 'vocab_size': 100850}\n",
            "{'context_length_99': 285,\n",
            " 'context_max_length': 426,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 300,\n",
            " 'prediction.accuracy.score': 0.3322461821809531,\n",
            " 'prediction.macrof1.score': 0.011907387665813255,\n",
            " 'prediction.microf1.score': 0.25672221926414995,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': [26062, 16],\n",
            " 'test_span_outofrange': 0,\n",
            " 'train_shape': [78183, 16],\n",
            " 'train_span_outofrange': 0,\n",
            " 'training.batch_size': 64,\n",
            " 'training.epochs': 25,\n",
            " 'training.train_length': 78183,\n",
            " 'training.train_steps': 1221,\n",
            " 'training.val_length': 26061,\n",
            " 'training.val_steps': 814,\n",
            " 'val_shape': [26061, 16],\n",
            " 'val_span_outofrange': 0,\n",
            " 'vocab_size': 100850}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSJXR52VTWsf",
        "colab_type": "text"
      },
      "source": [
        "## Load Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5FJHi14rHNTX",
        "colab": {}
      },
      "source": [
        "def load_tokenizer(params=params, name=\"glove\"):\n",
        "  if(name=='glove'):\n",
        "    print('Loading GloVe 300D')\n",
        "    with open(model_path + \"tokenizer.pkl\",\"rb\") as infile:\n",
        "        tokenizer = pickle.load(infile)\n",
        "    print('Vocab Loaded - ',len(tokenizer.word_index))\n",
        "    if(params):\n",
        "      params['vocab_size'] = len(tokenizer.word_index)\n",
        "    return tokenizer\n",
        "  elif (name=='use'):\n",
        "    print('Loading Universal Sentence Encoder')\n",
        "    with open(model_path + \"tokenizerwithstopwordspunct.pkl\",\"rb\") as infile:\n",
        "        tokenizer = pickle.load(infile)\n",
        "    print('Vocab Loaded - ',len(tokenizer.word_index))\n",
        "    if(params):\n",
        "      params['vocab_size'] = len(tokenizer.word_index)    \n",
        "    return tokenizer       "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V0TSjNkdXzuR"
      },
      "source": [
        "## Create a common function to generate sequences (useful in prediction)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sq97Vq4kXTST",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7dff041a-d7f4-4fd3-8f37-78b446f65083"
      },
      "source": [
        "# function to generate sequences withg appropiate padding\n",
        "tokenizer = load_tokenizer()\n",
        "def generate_question_context_sequence(context,question,question_max_length,padding,context_max_length):\n",
        "  question_seq = tokenizer.texts_to_sequences(question)\n",
        "  context_seq = tokenizer.texts_to_sequences(context)\n",
        "  question_seq = preprocessing.sequence.pad_sequences(question_seq,\n",
        "                                                      maxlen=question_max_length,\n",
        "                                                      padding=padding)\n",
        "  context_seq = preprocessing.sequence.pad_sequences(context_seq,\n",
        "                                                     maxlen=context_max_length,\n",
        "                                                     padding=padding)\n",
        "  return context_seq, question_seq"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading GloVe 300D\n",
            "Vocab Loaded -  100850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v78fhG3Tdhx5"
      },
      "source": [
        "## Create a common function to predict and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v6KDfM25dhZr",
        "colab": {}
      },
      "source": [
        "def predit_test(context, question, modeltoUse, params=params):\n",
        "  # get sequence for context and question\n",
        "  c_ = preprocess_text(context,stopword_removal=False)\n",
        "  q_ = preprocess_text(question,stopword_removal=False)\n",
        "  answer=[]\n",
        "  spans=[]\n",
        "\n",
        "  \n",
        "\n",
        "  c,q = generate_question_context_sequence(context=c_,\n",
        "                                           question=q_,\n",
        "                                           question_max_length=params['question_max_length'],\n",
        "                                           padding=params['question_pad_seq'],\n",
        "                                           context_max_length=params['context_max_length'])\n",
        "\n",
        "  context_token = []\n",
        "  print(c)\n",
        "  # tokenizer.word_docs\n",
        "  tokenizer.word_index['how']\n",
        "  print(list(tokenizer.word_index.keys())[list(tokenizer.word_index.values()).index(39)])\n",
        "  for ci in c:    \n",
        "    tokens = {}\n",
        "    for i in ci:\n",
        "      if(i != 0):\n",
        "        print(tokenizer.word_docs[i])\n",
        "        # tokens[tokenizer.word_index[i]] = i\n",
        "    # context_token.append(ci)\n",
        "  # print(context_token)\n",
        "\n",
        "\n",
        "  y_ = modeltoUse.predict([q,c])    \n",
        "  # print(y_)\n",
        "  pred_token = {}\n",
        "  for i in range(len(context)):    \n",
        "    s = np.argmax(y_[i,:params['context_max_length']])\n",
        "    e = np.argmax(y_[i,params['context_max_length']:])\n",
        "    answer.append(span_to_answer((s,e),c_[i]))\n",
        "    spans.append([s,e])\n",
        "    # pred_token[]\n",
        "  \n",
        "  # print(c.shape,q.shape,y_.shape,s,e,answer)  \n",
        "  # print(s, e)\n",
        "  return c_,q_,spans,y_,answer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIjvBaQ4WFZQ",
        "colab_type": "text"
      },
      "source": [
        "## Load Test Data with Ground Truth Known"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYkWpLxxWFii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample,shuffle\n",
        "\n",
        "def load_data_withoutstopwords():\n",
        "  #### NOTE THE 2 data frames's\n",
        "  df_nostopwords = 'test_squad_data_final_context_withoutstopwords.csv'\n",
        "  # df_withstopwords = 'squad_data_final_withstopword_withpunctuation.csv'\n",
        "  test_squad_df = pd.read_csv(project_path+df_nostopwords)\n",
        "  test_squad_df.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "\n",
        "\n",
        "  test_squad_df[\"answer_word_span\"] = test_squad_df[\"answer_word_span\"].apply(lambda x :eval(x))\n",
        "  print(test_squad_df.info())\n",
        "  return test_squad_df"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH025QzmyMAJ",
        "colab_type": "text"
      },
      "source": [
        "## Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDX397bcyMZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logits_loss(y_true,logits):\n",
        "    \"\"\"\n",
        "    Custom loss function which minimises log_loss.\n",
        "    Referance https://stackoverflow.com/questions/50063613/add-loss-function-in-keras\n",
        "    \"\"\"\n",
        "    \n",
        "    #y_true = tf.cast(y_true,dtype=tf.int32)\n",
        "    #logits = tf.cast(logits,dtype=tf.float32)\n",
        "    \n",
        "    # breaking the tensor into two half's to get start and end label.\n",
        "    start_label = y_true[:,:params['context_max_length']]\n",
        "    end_label = y_true[:,params['context_max_length']:]\n",
        "    \n",
        "    # braking the logits tensor into start and end part for loss calcultion.\n",
        "    start_logit = logits[:,:params['context_max_length']]\n",
        "    end_logit = logits[:,params['context_max_length']:]\n",
        "    \n",
        "    start_loss = tf.keras.backend.categorical_crossentropy(start_label,start_logit)\n",
        "    end_loss = tf.keras.backend.categorical_crossentropy(end_label,end_logit)\n",
        "    \n",
        "#     start_loss = tf.losses.sparse_softmax_cross_entropy(labels=start_label, logits=start_logit)\n",
        "#     end_loss = tf.losses.sparse_softmax_cross_entropy(labels=end_label, logits=end_logit)\n",
        "    \n",
        "    # as per paer\n",
        "    \n",
        "    loss = start_loss + end_loss\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP43qWYkewja",
        "colab_type": "text"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pSzIAlTe07P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "def load_mrc_model(model_path):\n",
        "  print('Loading model from', model_path)\n",
        "  custom_objects = {\"logits_loss\": logits_loss}\n",
        "  new_model = keras.models.load_model(model_path,custom_objects=custom_objects)\n",
        "  ### Check its architecture\n",
        "  # new_model.summary()  \n",
        "  return new_model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2fUNm7uPWSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# strategy = tf.distribute.MirroredStrategy()\n",
        "# with strategy.scope():\n",
        "#   model = load_mrc_model('/content/drive/My Drive/AIML-MRC-Capstone/models/bilstm/full_context_withoutstopwords_model_epoch_25_bilstm_glove_nomask_gpu.h5')\n",
        "  \n",
        "# model.summary()\n",
        "# # list_of_models['bilstm-glove-q2c-c2q-attention']['loc'].replace('https://storage.cloud.google.com/aiml-capstone/','gbucket/')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DURR8zGyUpy6",
        "colab_type": "text"
      },
      "source": [
        "## Load Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWgeXhRLUrj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_test_data(name='test-withoutstopwords.csv'):\n",
        "  test = pd.read_csv(model_path +name)\n",
        "  test.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "  test[\"answer_word_span\"] = test[\"answer_word_span\"].apply(lambda x :eval(x))\n",
        "  test.loc[test['answer'].isna(), 'answer'] = ''\n",
        "  test.loc[test['plausible_answer'].isna(), 'plausible_answer'] = ''\n",
        "  print(test.shape)\n",
        "  return test"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2P1tCiIn3a3",
        "colab_type": "text"
      },
      "source": [
        "## Load CNN dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdQS49J4n4D8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cnndf = pd.read_csv(dataset_path + 'CNN/TrainingDatasets/cnnTrainingData.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFKbElDgn35o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cnndf.head(5)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-EuIRXxPFZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# del cnndf"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2iBIhFlpE_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import textwrap\n",
        "# wrapper = textwrap.TextWrapper(width=80) \n",
        "# print(wrapper.fill(cnndf['context'].iloc[0]))\n",
        "# print()\n",
        "# print(wrapper.fill(cnndf['question'].iloc[4]))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoXsJRF_Vah4",
        "colab_type": "text"
      },
      "source": [
        "## Create Answer Sequence for test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rregOZyRS_Da",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_answer_sequence(test, context_length):\n",
        "  # for test data\n",
        "  y_test = []\n",
        "  for i in range(len(test)):    \n",
        "      s = np.zeros(context_length,dtype = \"int\")\n",
        "      e = np.zeros(context_length,dtype = \"int\")        \n",
        "      start,end = test[\"answer_word_span\"].iloc[i]    \n",
        "      s[start] = 1\n",
        "      e[end] = 1\n",
        "      y_test.append(np.concatenate((s,e)))\n",
        "  return y_test\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDeMi7IWeb6_",
        "colab_type": "text"
      },
      "source": [
        "## Create a combined y_test array having both start and end vectors in OHE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3S3SB2cfFR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combine_y(y, test_sample_size):\n",
        "  # argmax is used to get the index where the max value in a list appears, and hence \n",
        "  # for every index i, we can get the place of start and end token of the max probab\n",
        "  start = []\n",
        "  end = []\n",
        "  for i in range(test_sample_size):\n",
        "      start.append(np.argmax(y[i,:params['context_max_length']]))\n",
        "      end.append(np.argmax(y[i,params['context_max_length']:]))\n",
        "      \n",
        "  y_new = np.zeros((test_sample_size,params['context_max_length']))\n",
        "  for i in range(test_sample_size):\n",
        "      y_new[i,start[i]:end[i]+1] = 1\n",
        "  return y_new,start,end"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUd9-eqtioBM",
        "colab_type": "text"
      },
      "source": [
        "## Accuracy Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0e-TuininW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy_metrics(y_true,y_pred):\n",
        "  acc_score = accuracy_score(y_true,y_pred)\n",
        "  macro_f1_score = f1_score(y_true,y_pred,average=\"macro\")\n",
        "  micro_f1_score = f1_score(y_true,y_pred,average=\"micro\")\n",
        "  return acc_score,macro_f1_score,micro_f1_score\n",
        "  "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqs4OxyjszkY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60aadf7d-1f5c-486d-b0ec-cfb090618151"
      },
      "source": [
        "accuracy_metrics([1,1,1],[0,1,1])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6666666666666666, 0.4, 0.6666666666666666)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnoYgva4_iEI",
        "colab_type": "text"
      },
      "source": [
        "## Exact Match Count per Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf3h0HWD_iyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def checkEMMatch(test, start, end):\n",
        "  field_names = [\"True Answer\",\n",
        "                \"True AS and AE\",\n",
        "                \"Predict Answer\",\n",
        "                \"Predict AS and AE\"]\n",
        "  result_df = pd.DataFrame(columns=field_names)\n",
        "  print('Checking for equality match percentage')\n",
        "  for i in tqdm(range(test.shape[0])):  \n",
        "    values = [test['clean_answer'].iloc[i], \n",
        "              test['answer_word_span'].iloc[i],\n",
        "              span_to_answer([start_pred[i],end_pred[i]],test['clean_context'].iloc[i]),\n",
        "              (start_pred[i],end_pred[i])]\n",
        "    zipped = zip(field_names, values)\n",
        "    a_dictionary = dict(zipped)\n",
        "    result_df = result_df.append(a_dictionary,ignore_index=True)\n",
        "\n",
        "  ematch = result_df[result_df['Predict Answer'] == result_df['True Answer']].shape[0]  / test.shape[0]\n",
        "  del result_df\n",
        "\n",
        "  return ematch\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvVeDCNqX5pr",
        "colab_type": "text"
      },
      "source": [
        "## Generate y_preds in text from predicted start and end span"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eDXknqOX5Cq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_y_preds_text(test, start, end):\n",
        "  y_preds = []\n",
        "  for i in tqdm(range(test.shape[0])):\n",
        "    y_preds.append(span_to_answer([start_pred[i],end_pred[i]],test['context'].iloc[i]))\n",
        "  return y_preds"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvA32P7IjPSZ",
        "colab_type": "text"
      },
      "source": [
        "## Load all model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xDin7-igafk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_all_models():\n",
        "  loaded_models = {}\n",
        "  for model in list_of_models:\n",
        "    print('Loading model ',model['name'],' from ', model['loc'])  \n",
        "    if(model['type'] == 'BERT'):\n",
        "      print('BERT is WIP !!')\n",
        "      continue    \n",
        "    tfmodel = load_mrc_model(model['loc'])\n",
        "    loaded_models[model['name']] = tfmodel\n",
        "  return loaded_models"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p87BPm-enj0t",
        "colab_type": "text"
      },
      "source": [
        "## SQuAD Official Evaluation Script\n",
        "\n",
        "Refer to https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsd_6KDXtTOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import collections\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import sys"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AJyEUWDzIrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getpred(test, y_predict):\n",
        "  pred = {}\n",
        "  for i in range(test.shape[0]):\n",
        "    pred[test['id'].iloc[i]] = y_predict[i]\n",
        "\n",
        "  return pred  "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGn2mA7atJEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_answer(s):\n",
        "  \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "  def remove_articles(text):\n",
        "    regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n",
        "    return re.sub(regex, ' ', text)\n",
        "  def white_space_fix(text):\n",
        "    if(text != text):\n",
        "      return ''\n",
        "    return ' '.join(text.split())\n",
        "  def remove_punc(text):\n",
        "    exclude = set(string.punctuation)\n",
        "    return ''.join(ch for ch in text if ch not in exclude)\n",
        "  def lower(text):\n",
        "    return text.lower()\n",
        "  return white_space_fix(remove_articles(remove_punc(lower(s))))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKsIlANKnvuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_qid_to_has_ans(test):\n",
        "  qid_to_has_ans = {}\n",
        "  for i in range(test.shape[0]):\n",
        "    qid_to_has_ans[test['id'].iloc[i]] = bool(test['answer'].iloc[i])\n",
        "  return qid_to_has_ans"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHL-JtnCx70o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tokens(s):\n",
        "  if not s: return []\n",
        "  return normalize_answer(s).split()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWjFQTjLx51X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d08ffbc5-179c-4efe-c84e-1ceb88aba621"
      },
      "source": [
        "def compute_exact(a_gold, a_pred, type='a'):\n",
        "  if(type=='a'):\n",
        "    return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n",
        "  else:\n",
        "    return int((normalize_answer(a_gold) != '') and (normalize_answer(a_gold) == normalize_answer(a_pred)))\n",
        "\n",
        "def compute_f1(a_gold, a_pred,  type='a'):\n",
        "  gold_toks = get_tokens(a_gold)\n",
        "  pred_toks = get_tokens(a_pred)\n",
        "  # find number of common tokens\n",
        "  common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
        "  # count the common tokens\n",
        "  num_same = sum(common.values())\n",
        "  if (len(gold_toks) == 0 or len(pred_toks) == 0) and type == 'a':\n",
        "    # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
        "    return int(gold_toks == pred_toks)\n",
        "  if num_same == 0:\n",
        "    return 0\n",
        "  # precision is always to y_pred - 1 * (ratio of common token / total tokens in y_pred)\n",
        "  precision = 1.0 * num_same / len(pred_toks)\n",
        "  # recal is always to y_true - 1 * (ratio of common token / total tokens in y_true)\n",
        "  recall = 1.0 * num_same / len(gold_toks)\n",
        "  # F1 score formulais as below - 2*((precision*recall)/(precision+recall))\n",
        "  f1 = (2 * precision * recall) / (precision + recall)\n",
        "  return f1\n",
        "\n",
        "# Test the sklearn f1 versus SQuAD F1 metrics func\n",
        "print('scklearn F1 =',f1_score(['by marriage through coburgs'],['by marriage through the Coburgs'],average=\"macro\"))\n",
        "print('custom F1 =',compute_f1('by marriage through coburgs','by marriage through the Coburgs')) \n",
        "\n",
        "print('scklearn F1 =',f1_score(['1990 new cases'],['1990'],average=\"macro\"))\n",
        "print('custom F1 =',compute_f1('1990 new cases','1990')) \n",
        "\n",
        "# equals\n",
        "print('custom exact =',compute_exact('by marriage through coburgs','by marriage through the Coburgs'))  \n",
        "print('exact exact =',int('by marriage through coburgs' == 'by marriage through the Coburgs'))  \n",
        "\n",
        "print('custom exact =',compute_exact('1990 new cases','1990'))\n",
        "print('exact exact =',int('Dr Balaram Bhargava' == 'Balaram Bhargava')) \n",
        "\n",
        "## Clearly the custom f1 and exact makes so much sense "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scklearn F1 = 0.0\n",
            "custom F1 = 1.0\n",
            "scklearn F1 = 0.0\n",
            "custom F1 = 0.5\n",
            "custom exact = 1\n",
            "exact exact = 0\n",
            "custom exact = 0\n",
            "exact exact = 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHykDpVjUQz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_eval_dict(exact_scores, f1_scores,exact_scores_pa,f1_scores_pa, qid_list=None):\n",
        "  total = len(exact_scores)\n",
        "  # return collections.OrderedDict([\n",
        "  #     ('exact', 100.0 * sum(exact_scores.values()) / total),\n",
        "  #     ('f1', 100.0 * sum(f1_scores.values()) / total),\n",
        "  #     ('total', total),\n",
        "  # ])\n",
        "  exact = 100.0 * sum(exact_scores.values()) / total\n",
        "  f1 = 100.0 * sum(f1_scores.values()) / total\n",
        "  exact_pa = 100.0 * sum(exact_scores_pa.values()) / total\n",
        "  f1_pa = 100.0 * sum(f1_scores_pa.values()) / total\n",
        "  return exact, f1, exact_pa, f1_pa, total"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpGEMJJasDap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  preds = {\n",
        "#     \"id\" : 'predicted answer'    \n",
        "#      }\n",
        "def get_raw_scores(test, preds):\n",
        "    exact_scores = {}\n",
        "    f1_scores = {}    \n",
        "    exact_scores_pa = {}\n",
        "    f1_scores_pa = {}        \n",
        "    for i in range(test.shape[0]):\n",
        "      if 'id' in test.columns:\n",
        "        qid = test['id'].iloc[i]\n",
        "      else:\n",
        "        qid = i\n",
        "      gold_a = normalize_answer(test['answer'].iloc[i])\n",
        "      gold_pa = normalize_answer(test['plausible_answer'].iloc[i])\n",
        "      if not gold_a:\n",
        "        # For unanswerable questions, only correct answer is empty string\n",
        "        gold_a = ''\n",
        "\n",
        "      exact_scores[qid] = compute_exact(gold_a, preds[i])\n",
        "      f1_scores[qid] = compute_f1(gold_a, preds[i])\n",
        "      exact_scores_pa[qid] = compute_exact(gold_pa, preds[i], type='pa')\n",
        "      f1_scores_pa[qid] = compute_f1(gold_pa, preds[i], type='pa')      \n",
        "\n",
        "    return exact_scores, f1_scores,exact_scores_pa,f1_scores_pa"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C42zkDJ-o4JF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5cf1094-b990-4b17-84f9-bfe9d1248c73"
      },
      "source": [
        "test = load_test_data()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(26062, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_XZUPY400oC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "d2d6fbec-05b0-4f73-92ab-1fce8324409c"
      },
      "source": [
        "test = test.head(5)\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>id</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer</th>\n",
              "      <th>plausible_answer_start</th>\n",
              "      <th>plausible_answer</th>\n",
              "      <th>is_impossible</th>\n",
              "      <th>clean_context</th>\n",
              "      <th>clean_question</th>\n",
              "      <th>clean_answer</th>\n",
              "      <th>answer_len</th>\n",
              "      <th>answer_end</th>\n",
              "      <th>answer_span</th>\n",
              "      <th>answer_word_span</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Queen_Victoria</td>\n",
              "      <td>Internationally, Victoria took a keen interest...</td>\n",
              "      <td>How was the House of Orleans and the British R...</td>\n",
              "      <td>5722d1770dadf01500fa1f04</td>\n",
              "      <td>218</td>\n",
              "      <td>by marriage through the Coburgs</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>internationally victoria took keen interest im...</td>\n",
              "      <td>how was the house of orleans and the british r...</td>\n",
              "      <td>by marriage through the coburgs</td>\n",
              "      <td>31</td>\n",
              "      <td>249</td>\n",
              "      <td>(218, 249)</td>\n",
              "      <td>(-1, -1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Southampton</td>\n",
              "      <td>Southampton's largest retail centre, and 35th ...</td>\n",
              "      <td>What's the largest retail center in Southampton?</td>\n",
              "      <td>56f8afe39e9bad19000a031d</td>\n",
              "      <td>72</td>\n",
              "      <td>WestQuay Shopping Centre</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>southamptons largest retail centre 35th larges...</td>\n",
              "      <td>whats the largest retail center in southampton</td>\n",
              "      <td>westquay shopping centre</td>\n",
              "      <td>24</td>\n",
              "      <td>96</td>\n",
              "      <td>(72, 96)</td>\n",
              "      <td>(7, 9)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Immunology</td>\n",
              "      <td>Other immune system disorders include various ...</td>\n",
              "      <td>What characterizes a hypersensitivity?</td>\n",
              "      <td>5706aa0a75f01819005e7ce8</td>\n",
              "      <td>110</td>\n",
              "      <td>respond inappropriately to otherwise harmless ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>immune system disorders include various hypers...</td>\n",
              "      <td>what characterizes a hypersensitivity</td>\n",
              "      <td>respond inappropriately to otherwise harmless ...</td>\n",
              "      <td>56</td>\n",
              "      <td>166</td>\n",
              "      <td>(110, 166)</td>\n",
              "      <td>(8, 13)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Steven_Spielberg</td>\n",
              "      <td>Spielberg won the Academy Award for Best Direc...</td>\n",
              "      <td>When was Jaws released?</td>\n",
              "      <td>57318afba5e9cc1400cdc01f</td>\n",
              "      <td>143</td>\n",
              "      <td>1975</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>spielberg academy award best director schindle...</td>\n",
              "      <td>when was jaws released</td>\n",
              "      <td>1975</td>\n",
              "      <td>4</td>\n",
              "      <td>147</td>\n",
              "      <td>(143, 147)</td>\n",
              "      <td>(15, 15)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Electric_motor</td>\n",
              "      <td>Because the rotor is much lighter in weight (m...</td>\n",
              "      <td>What advantage doesn't a coreless rotor have o...</td>\n",
              "      <td>5ad168ad645df0001a2d1a12</td>\n",
              "      <td>-1</td>\n",
              "      <td></td>\n",
              "      <td>141.0</td>\n",
              "      <td>accelerate much more rapidly</td>\n",
              "      <td>True</td>\n",
              "      <td>rotor much lighter weight mass conventional ro...</td>\n",
              "      <td>what advantage doesnt a coreless rotor have ov...</td>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>(-1, -1)</td>\n",
              "      <td>(-1, -1)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              title  ... answer_word_span\n",
              "0    Queen_Victoria  ...         (-1, -1)\n",
              "1       Southampton  ...           (7, 9)\n",
              "2        Immunology  ...          (8, 13)\n",
              "3  Steven_Spielberg  ...         (15, 15)\n",
              "4    Electric_motor  ...         (-1, -1)\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIYtmXgrQ9i_",
        "colab_type": "text"
      },
      "source": [
        "<font color='red'>**DO NOT EXECUTE THIS**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57EsT35XyxGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = ['',\n",
        "          'WestQuay Shopping Centre',\n",
        "          'inappropriately to otherwise harmless compounds.',\n",
        "          '1975',\n",
        "          'accelerate much more rapidly']\n",
        "# preds = getpred(test,y_pred)\n",
        "# preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6ahjxlWq03p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "051eec57-0841-489f-e1d8-87d63f4e62a4"
      },
      "source": [
        "test[test['id']=='5a56d7bd6349e2001acdcf92']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>id</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer</th>\n",
              "      <th>plausible_answer_start</th>\n",
              "      <th>plausible_answer</th>\n",
              "      <th>is_impossible</th>\n",
              "      <th>clean_context</th>\n",
              "      <th>clean_question</th>\n",
              "      <th>clean_answer</th>\n",
              "      <th>answer_len</th>\n",
              "      <th>answer_end</th>\n",
              "      <th>answer_span</th>\n",
              "      <th>answer_word_span</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>611</th>\n",
              "      <td>Ministry_of_Defence_(United_Kingdom)</td>\n",
              "      <td>Henry VIII's wine cellar at the Palace of Whit...</td>\n",
              "      <td>What was the Palace of Whitehall built with in...</td>\n",
              "      <td>5a56d7bd6349e2001acdcf92</td>\n",
              "      <td>-1</td>\n",
              "      <td></td>\n",
              "      <td>225.0</td>\n",
              "      <td>steel and concrete</td>\n",
              "      <td>True</td>\n",
              "      <td>henry viiis wine cellar palace whitehall built...</td>\n",
              "      <td>what was the palace of whitehall built with in...</td>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>(-1, -1)</td>\n",
              "      <td>(-1, -1)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    title  ... answer_word_span\n",
              "611  Ministry_of_Defence_(United_Kingdom)  ...         (-1, -1)\n",
              "\n",
              "[1 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHK2TaOho-9j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "16d1f6cc-b7cb-4861-d519-9152905168cf"
      },
      "source": [
        "# preds = getpred(test,y_pred)\n",
        "# qid_to_has_ans = make_qid_to_has_ans(test)  # maps qid to True/False\n",
        "# has_ans_qids = [k for k, v in qid_to_has_ans.items() if v]\n",
        "# no_ans_qids = [k for k, v in qid_to_has_ans.items() if not v]\n",
        "exact_raw, f1_raw,exact_scores_pa,f1_scores_pa = get_raw_scores(test, y_pred)\n",
        "pprint.pprint(exact_raw)\n",
        "pprint.pprint(f1_raw)\n",
        "pprint.pprint(exact_scores_pa)\n",
        "pprint.pprint(f1_scores_pa)\n",
        "exact, f1,exact_pa, f1_pa, total = make_eval_dict(exact_raw,f1_raw,exact_scores_pa,f1_scores_pa)\n",
        "\n",
        "print(exact, f1,exact_pa, f1_pa, total)\n",
        "\n",
        "# print(test['id'].iloc[2] + ' = ', compute_f1(test['answer'].iloc[2],y_pred[2]))\n",
        "# print(test['id'].iloc[0] + ' = ', compute_f1(test['answer'].iloc[0],y_pred[2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'56f8afe39e9bad19000a031d': 1,\n",
            " '5706aa0a75f01819005e7ce8': 0,\n",
            " '5722d1770dadf01500fa1f04': 0,\n",
            " '57318afba5e9cc1400cdc01f': 1,\n",
            " '5ad168ad645df0001a2d1a12': 0}\n",
            "{'56f8afe39e9bad19000a031d': 1.0,\n",
            " '5706aa0a75f01819005e7ce8': 0.9090909090909091,\n",
            " '5722d1770dadf01500fa1f04': 0,\n",
            " '57318afba5e9cc1400cdc01f': 1.0,\n",
            " '5ad168ad645df0001a2d1a12': 0}\n",
            "{'56f8afe39e9bad19000a031d': 0,\n",
            " '5706aa0a75f01819005e7ce8': 0,\n",
            " '5722d1770dadf01500fa1f04': 0,\n",
            " '57318afba5e9cc1400cdc01f': 0,\n",
            " '5ad168ad645df0001a2d1a12': 1}\n",
            "{'56f8afe39e9bad19000a031d': 0,\n",
            " '5706aa0a75f01819005e7ce8': 0,\n",
            " '5722d1770dadf01500fa1f04': 0,\n",
            " '57318afba5e9cc1400cdc01f': 0,\n",
            " '5ad168ad645df0001a2d1a12': 1.0}\n",
            "40.0 58.18181818181819 20.0 20.0 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVPxnPRWWJ1V",
        "colab_type": "text"
      },
      "source": [
        "# Evaluations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIVrjx6YNTsi",
        "colab_type": "text"
      },
      "source": [
        "## Import BERT pretrained from Hugging Face for QnA whole word masking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeJNCZS9NSif",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "53e1ffaa-ed5c-423e-dcc6-13373b00d916"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlmI9YDNNxrd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "6fc509b8-05cc-4f30-f434-d179b6534d8a"
      },
      "source": [
        "from transformers import BertTokenizer, TFBertForQuestionAnswering\n",
        "\n",
        "berthugtokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "berthugmodel = TFBertForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint weights were used when initializing TFBertForQuestionAnswering.\n",
            "\n",
            "All the weights of TFBertForQuestionAnswering were initialized from the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV04yElJPeze",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1f70b1b3-f2d4-4645-a318-7baf0801fe2e"
      },
      "source": [
        "berthugmodel.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_question_answering\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  335141888 \n",
            "_________________________________________________________________\n",
            "qa_outputs (Dense)           multiple                  2050      \n",
            "=================================================================\n",
            "Total params: 335,143,938\n",
            "Trainable params: 335,143,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI_FkpHkPKms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predBERTHuggingface(question, context):  \n",
        "  input_dict = berthugtokenizer(question, context, return_tensors='tf')\n",
        "  start_scores, end_scores = berthugmodel(input_dict)\n",
        "  all_tokens = berthugtokenizer.convert_ids_to_tokens(input_dict[\"input_ids\"].numpy()[0])\n",
        "  # print(all_tokens)\n",
        "  answer = ' '.join(all_tokens[tf.math.argmax(start_scores, 1)[0] : tf.math.argmax(end_scores, 1)[0]+1])\n",
        "  # print(answer)\n",
        "  # Find the tokens with the highest `start` and `end` scores.\n",
        "  answer_start = np.argmax(start_scores)\n",
        "  answer_end = np.argmax(end_scores)\n",
        "  # Combine the tokens in the answer and print it out.\n",
        "  answer = ' '.join(all_tokens[answer_start:answer_end+1])\n",
        "  # Start with the first token.\n",
        "  answer = all_tokens[answer_start]\n",
        "\n",
        "  # Select the remaining answer tokens and join them with whitespace.\n",
        "  for i in range(answer_start + 1, answer_end + 1):      \n",
        "      # If it's a subword token, then recombine it with the previous token.\n",
        "      if all_tokens[i][0:2] == '##':\n",
        "          answer += all_tokens[i][2:]    \n",
        "      # Otherwise, add a space then the token.\n",
        "      else:\n",
        "          answer += ' ' + all_tokens[i]\n",
        "\n",
        "  return answer "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udQXeS9CPVa3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80f0e450-ecb6-4537-8580-4f10deb3bf96"
      },
      "source": [
        "import textwrap\n",
        "wrapper = textwrap.TextWrapper(width=80) \n",
        "# print(wrapper.fill(cnndf['context'].iloc[0]))\n",
        "q1, c1  = \"what was the death toll\", \"With a record 15968 coronavirus cases reported in the past 24 hours,the total count in India crossed the 4.5 lakh mark. The death toll has gone up to 14476\"\n",
        "q2, c2 = 'how many cases in mumbai', 'Delhi, which already is the second worst hit state in terms of coronavirus caseload and fatalities, overtook Mumbai after the number of cases soared by 3788 to touch 70390. Mumbai has so far recorded 69625 cases, according to official figures.'\n",
        "\n",
        "# input_dict = berthugtokenizer(text=[q1,q2],text_pair =[c1,c2],is_pretokenized=True, return_tensors='tf')\n",
        "# print(input_dict)\n",
        "\n",
        "# input_dict_noar = berthugtokenizer(q2,c2, return_tensors='tf')\n",
        "# print(input_dict_noar)\n",
        "\n",
        "\n",
        "# all_tokens = berthugtokenizer.convert_ids_to_tokens(input_dict[\"input_ids\"][0])\n",
        "# print(all_tokens)\n",
        "\n",
        "# all_tokens = berthugtokenizer.convert_ids_to_tokens(input_dict_noar[\"input_ids\"][0])\n",
        "# print(all_tokens)\n",
        "\n",
        "print(predBERTHuggingface(q1,c1))\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3OYR2U5Tnhs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "84088ed0-d8e4-474d-92ba-0db1a0cd8251"
      },
      "source": [
        "# bert_pred=pd.DataFrame(columns=['c','q','true','pred'])\n",
        "test = load_test_data(name='test-withstopwordspunct.csv')\n",
        "bert_h_pred = test[['id','context','question','answer','plausible_answer']].copy()\n",
        "preds = []\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "# a better way is to batch its and tokenize \n",
        "# for a batch a record at a time and do inference \n",
        "# I was able to do for deeppavlov, for hugginface I felt lazy\n",
        "with strategy.scope():\n",
        "  for i in tqdm(range(test.shape[0])):\n",
        "    try:\n",
        "      p = ''\n",
        "      p = predBERTHuggingface(test['question'].iloc[i],test['context'].iloc[i])\n",
        "    except:\n",
        "      print('error in prediction')\n",
        "    preds = preds + [p]\n",
        "\n",
        "bert_h_pred['prediction'] = preds\n",
        "\n",
        "bert_h_pred.head()\n",
        "# remove na pls\n",
        "bert_h_pred.loc[bert_h_pred['prediction'].isna(), 'prediction'] = ''\n",
        "bert_h_pred.to_csv(model_path + 'bert/bert-huggingface-results.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(26062, 16)\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 73/26062 [00:22<2:12:52,  3.26it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (14 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 119/26062 [00:36<2:15:50,  3.18it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (11 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  3%|         | 723/26062 [03:44<2:14:36,  3.14it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (29 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  3%|         | 732/26062 [03:47<2:10:45,  3.23it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (10 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|         | 932/26062 [04:49<2:13:24,  3.14it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (8 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|         | 1004/26062 [05:12<2:12:01,  3.16it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (12 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  6%|         | 1536/26062 [07:59<2:07:52,  3.20it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (9 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 12%|        | 3185/26062 [16:36<2:00:35,  3.16it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (17 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 21%|        | 5469/26062 [28:36<1:49:41,  3.13it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (8 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 21%|       | 5580/26062 [29:11<1:46:09,  3.22it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (13 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|       | 5994/26062 [31:21<1:46:25,  3.14it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (14 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (16 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n",
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 28%|       | 7218/26062 [37:46<1:38:18,  3.19it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (10 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|       | 7881/26062 [41:15<1:37:11,  3.12it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (10 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|      | 9047/26062 [47:24<1:27:16,  3.25it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (12 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|      | 9098/26062 [47:40<1:29:16,  3.17it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (13 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|      | 9254/26062 [48:28<1:28:01,  3.18it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (11 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|      | 9278/26062 [48:36<1:27:24,  3.20it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (9 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 38%|      | 9914/26062 [51:56<1:24:25,  3.19it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (11 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 39%|      | 10255/26062 [53:43<1:21:21,  3.24it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (10 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|     | 11095/26062 [58:08<1:19:14,  3.15it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (8 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 44%|     | 11562/26062 [1:00:36<1:15:46,  3.19it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (12 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|     | 11679/26062 [1:01:12<1:15:38,  3.17it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (13 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 47%|     | 12220/26062 [1:04:04<1:15:08,  3.07it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (17 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 47%|     | 12287/26062 [1:04:25<1:13:52,  3.11it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (11 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 48%|     | 12600/26062 [1:06:04<1:10:50,  3.17it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (15 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 49%|     | 12831/26062 [1:07:17<1:10:13,  3.14it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (10 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|    | 13671/26062 [1:11:45<1:05:41,  3.14it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (7 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|    | 14771/26062 [1:17:33<1:00:43,  3.10it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (14 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 67%|   | 17403/26062 [1:31:31<45:49,  3.15it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (7 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 71%|   | 18395/26062 [1:36:46<40:15,  3.17it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (24 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 72%|  | 18670/26062 [1:38:13<39:11,  3.14it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (8 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 72%|  | 18715/26062 [1:38:27<38:29,  3.18it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (12 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 73%|  | 18950/26062 [1:39:42<38:23,  3.09it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (9 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 73%|  | 19134/26062 [1:40:40<36:43,  3.14it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (12 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 78%|  | 20266/26062 [1:46:38<30:31,  3.16it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (6 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|  | 20624/26062 [1:48:31<28:44,  3.15it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (10 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|  | 20714/26062 [1:49:00<28:14,  3.16it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (11 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%| | 22055/26062 [1:56:05<21:22,  3.13it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (11 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 88%| | 22932/26062 [2:00:44<16:13,  3.22it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (10 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 94%|| 24594/26062 [2:09:35<07:40,  3.19it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (10 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 95%|| 24642/26062 [2:09:50<07:31,  3.14it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (6 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 96%|| 25079/26062 [2:12:08<05:08,  3.19it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (10 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 97%|| 25340/26062 [2:13:31<03:45,  3.20it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (8 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 99%|| 25840/26062 [2:16:10<01:10,  3.13it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (9 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "error in prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 26062/26062 [2:17:20<00:00,  3.16it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>plausible_answer</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5722d1770dadf01500fa1f04</td>\n",
              "      <td>Internationally, Victoria took a keen interest...</td>\n",
              "      <td>How was the House of Orleans and the British R...</td>\n",
              "      <td>by marriage through the Coburgs</td>\n",
              "      <td></td>\n",
              "      <td>by marriage through the coburgs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56f8afe39e9bad19000a031d</td>\n",
              "      <td>Southampton's largest retail centre, and 35th ...</td>\n",
              "      <td>What's the largest retail center in Southampton?</td>\n",
              "      <td>WestQuay Shopping Centre</td>\n",
              "      <td></td>\n",
              "      <td>westquay shopping centre</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5706aa0a75f01819005e7ce8</td>\n",
              "      <td>Other immune system disorders include various ...</td>\n",
              "      <td>What characterizes a hypersensitivity?</td>\n",
              "      <td>respond inappropriately to otherwise harmless ...</td>\n",
              "      <td></td>\n",
              "      <td>respond inappropriately to otherwise harmless ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>57318afba5e9cc1400cdc01f</td>\n",
              "      <td>Spielberg won the Academy Award for Best Direc...</td>\n",
              "      <td>When was Jaws released?</td>\n",
              "      <td>1975</td>\n",
              "      <td></td>\n",
              "      <td>1975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5ad168ad645df0001a2d1a12</td>\n",
              "      <td>Because the rotor is much lighter in weight (m...</td>\n",
              "      <td>What advantage doesn't a coreless rotor have o...</td>\n",
              "      <td></td>\n",
              "      <td>accelerate much more rapidly</td>\n",
              "      <td>accelerate much more rapidly</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         id  ...                                         prediction\n",
              "0  5722d1770dadf01500fa1f04  ...                    by marriage through the coburgs\n",
              "1  56f8afe39e9bad19000a031d  ...                           westquay shopping centre\n",
              "2  5706aa0a75f01819005e7ce8  ...  respond inappropriately to otherwise harmless ...\n",
              "3  57318afba5e9cc1400cdc01f  ...                                               1975\n",
              "4  5ad168ad645df0001a2d1a12  ...                       accelerate much more rapidly\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP13NC14X47t",
        "colab_type": "text"
      },
      "source": [
        "## Eval on test data\n",
        "\n",
        "Metrics would be F1 score micro, EM, Accuracy Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAUtNL4tkGut",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "b3302580-c9d4-4ec9-b1f5-e05dd0e5aee1"
      },
      "source": [
        "# test = load_test_data(name='train-withstopwordspunct.csv')\n",
        "# params = loadparams(name='params_withoutstopwords.json')\n",
        "# tokenizer = load_tokenizer(name='use')\n",
        "# showparams(params)\n",
        "# print(test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(26062, 16)\n",
            "Loading Universal Sentence Encoder\n",
            "Vocab Loaded -  82505\n",
            "{'context_length_99': 285,\n",
            " 'context_max_length': 426,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 300,\n",
            " 'prediction.accuracy.score': 0.3322461821809531,\n",
            " 'prediction.macrof1.score': 0.011907387665813255,\n",
            " 'prediction.microf1.score': 0.25672221926414995,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': [26062, 16],\n",
            " 'test_span_outofrange': 0,\n",
            " 'train_shape': [78183, 16],\n",
            " 'train_span_outofrange': 0,\n",
            " 'training.batch_size': 64,\n",
            " 'training.epochs': 25,\n",
            " 'training.train_length': 78183,\n",
            " 'training.train_steps': 1221,\n",
            " 'training.val_length': 26061,\n",
            " 'training.val_steps': 814,\n",
            " 'val_shape': [26061, 16],\n",
            " 'val_span_outofrange': 0,\n",
            " 'vocab_size': 82505}\n",
            "26062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4xL4rRSV5JW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "model_results = pd.DataFrame(columns=['Model Name','F1(Ans)','EM(Ans)','F1(Plau Ans)','EM(Plau Ans)'])\n",
        "with strategy.scope():\n",
        "\n",
        "  # y_test = create_answer_sequence(test,params['context_max_length'])\n",
        "  # y_test was a list changing to numpy array\n",
        "  # y_test_fixed = np.array(y_test)\n",
        "  # compute for y_test though in this case it the max of 0 and 1 for \n",
        "  # the frist half od array size for start, and rest for end\n",
        "  # y_test_new,_,_ = combine_y(y_test_fixed,test.shape[0])\n",
        "\n",
        "  test_map = {\n",
        "      'With stopwords': load_test_data(name='test-withstopwordspunct.csv'),\n",
        "      'Without stopwords': load_test_data(name='test-withoutstopwords.csv'),\n",
        "  }\n",
        "\n",
        "  test_seq_map = {\n",
        "      'With stopwords': [],\n",
        "      'Without stopwords': []\n",
        "  }\n",
        "\n",
        "  for model in list_of_models:\n",
        "    print('Loading model ',model['name'],' from ', model['loc'])\n",
        "    if((model['type']=='BERT')):\n",
        "      # print('BERT eval will be handled separately. Skipping')\n",
        "      bert_results = pd.read_csv(model['loc'])\n",
        "      bert_results.loc[bert_results['answer'].isna(), 'answer'] = '' \n",
        "      bert_results.loc[bert_results['plausible_answer'].isna(), 'plausible_answer'] = ''\n",
        "      bert_results.loc[bert_results['prediction'].isna(), 'prediction'] = ''\n",
        "      exact_raw, f1_raw, exact_scores_pa,f1_scores_pa = get_raw_scores(bert_results, bert_results['prediction'].values.tolist())\n",
        "      exact, f1,exact_pa, f1_pa, total = make_eval_dict(exact_raw,f1_raw, exact_scores_pa,f1_scores_pa)\n",
        "      values = [model['name'],              \n",
        "                f1,\n",
        "                exact,\n",
        "                f1_pa,\n",
        "                exact_pa]\n",
        "      zipped = zip(model_results.columns, values)\n",
        "      a_dictionary = dict(zipped)\n",
        "      model_results = model_results.append(a_dictionary,ignore_index=True)   \n",
        "      continue\n",
        "    \n",
        "    if(model['type']=='With stopwords'):\n",
        "      test = test_map['With stopwords']\n",
        "      params = loadparams(name='params_withstopwords_withuse.json')\n",
        "      tokenizer = load_tokenizer(name='use')\n",
        "      if not test_seq_map['With stopwords']:\n",
        "        print('Generating question sequnce for with stopwords ...')\n",
        "        test_context_sequence, test_question_sequence = generate_question_context_sequence(context=test[\"clean_context\"].values,\n",
        "                                      question=test[\"clean_question\"].values,\n",
        "                                      question_max_length=params['question_max_length'],\n",
        "                                      padding=params['question_pad_seq'],\n",
        "                                      context_max_length=params['context_max_length']\n",
        "                                      )      \n",
        "        test_seq_map['With stopwords'] = [test_context_sequence,test_question_sequence]\n",
        "      else:\n",
        "        print('Using question sequnce for with stopwords ...')\n",
        "        test_context_sequence = test_seq_map['With stopwords'][0]\n",
        "        test_question_sequence = test_seq_map['With stopwords'][1]\n",
        "    elif(model['type']=='Without stopwords'):\n",
        "      test = test_map['Without stopwords']\n",
        "      params = loadparams(name='params_withoutstopwords.json')\n",
        "      tokenizer = load_tokenizer(name='glove')\n",
        "      if not test_seq_map['Without stopwords']:\n",
        "        print('Generating question sequnce for without stopwords ...')\n",
        "        test_context_sequence, test_question_sequence = generate_question_context_sequence(context=test[\"clean_context\"].values,\n",
        "                                      question=test[\"clean_question\"].values,\n",
        "                                      question_max_length=params['question_max_length'],\n",
        "                                      padding=params['question_pad_seq'],\n",
        "                                      context_max_length=params['context_max_length']\n",
        "                                      )      \n",
        "        test_seq_map['Without stopwords'] = [test_context_sequence,test_question_sequence]\n",
        "      else:\n",
        "        print('Using question sequnce for without stopwords ...')\n",
        "        test_context_sequence = test_seq_map['Without stopwords'][0]\n",
        "        test_question_sequence = test_seq_map['Without stopwords'][1]      \n",
        "\n",
        "    tfmodel = load_mrc_model(model['loc'])\n",
        "    print(model['name'],' model successfuly. Starting eval')\n",
        "    # tfmodel.summary()  \n",
        "    y_prediction = tfmodel.predict([test_question_sequence,test_context_sequence])\n",
        "    y_prediction_new,start_pred,end_pred = combine_y(y_prediction,test.shape[0])\n",
        "    # acc_score,macro_f1_score,micro_f1_score = accuracy_metrics(y_test_new,y_prediction_new)\n",
        "    y_pred_text = generate_y_preds_text(test,start_pred,end_pred)\n",
        "    exact_raw, f1_raw, exact_scores_pa,f1_scores_pa = get_raw_scores(test, y_pred_text)\n",
        "    exact, f1,exact_pa, f1_pa, total = make_eval_dict(exact_raw,f1_raw, exact_scores_pa,f1_scores_pa)\n",
        "    values = [model['name'],              \n",
        "              f1,\n",
        "              exact,\n",
        "              f1_pa,\n",
        "              exact_pa]\n",
        "    zipped = zip(model_results.columns, values)\n",
        "    a_dictionary = dict(zipped)\n",
        "    model_results = model_results.append(a_dictionary,ignore_index=True)   \n",
        "    del tokenizer\n",
        "    del params      \n",
        "    del y_prediction\n",
        "    del y_pred_text  \n",
        "    del start_pred\n",
        "    del end_pred\n",
        "    del tfmodel\n",
        "\n",
        "model_results.head(10)   \n",
        "model_results.to_csv(model_path + \"model_results_\" + datetime.now().strftime(\"%d-%m-%Y_%I-%M-%S_%p\") + \".csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHx9KbHZ8pNb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "c0efcb31-d47a-4adc-903d-9e211688b8de"
      },
      "source": [
        "model_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Name</th>\n",
              "      <th>F1(Ans)</th>\n",
              "      <th>EM(Ans)</th>\n",
              "      <th>F1(Plau Ans)</th>\n",
              "      <th>EM(Plau Ans)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LSTM Baseline</td>\n",
              "      <td>29.001121</td>\n",
              "      <td>28.225002</td>\n",
              "      <td>0.214623</td>\n",
              "      <td>0.053718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Deep LSTM + GloVe</td>\n",
              "      <td>26.666439</td>\n",
              "      <td>26.030236</td>\n",
              "      <td>0.276301</td>\n",
              "      <td>0.069066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bi-LSTM + GloVe</td>\n",
              "      <td>28.021961</td>\n",
              "      <td>27.526667</td>\n",
              "      <td>0.281106</td>\n",
              "      <td>0.126621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bi-LSTM + GloVe + Q2C Attention</td>\n",
              "      <td>33.095119</td>\n",
              "      <td>33.094160</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bi-LSTM + GloVe + Q2C-C2Q Attention</td>\n",
              "      <td>29.622157</td>\n",
              "      <td>29.130535</td>\n",
              "      <td>0.200039</td>\n",
              "      <td>0.069066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LSTM Baseline + Universal Sentence Encode</td>\n",
              "      <td>24.545255</td>\n",
              "      <td>22.952958</td>\n",
              "      <td>0.618575</td>\n",
              "      <td>0.099762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Bi-LSTM + Universal Sentence Encode</td>\n",
              "      <td>32.025226</td>\n",
              "      <td>31.544010</td>\n",
              "      <td>0.068411</td>\n",
              "      <td>0.023022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Bi-LSTM + Q2C Attention + Universal Sentence E...</td>\n",
              "      <td>30.695975</td>\n",
              "      <td>30.120482</td>\n",
              "      <td>0.146946</td>\n",
              "      <td>0.042207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>BERT + Cased_L-12_H-768_A-12 + DeepPavlov</td>\n",
              "      <td>59.096928</td>\n",
              "      <td>51.362136</td>\n",
              "      <td>22.539289</td>\n",
              "      <td>18.179725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>BERT + Uncased_L-24_H-1024_A-24 + Huggingface</td>\n",
              "      <td>57.513153</td>\n",
              "      <td>49.769780</td>\n",
              "      <td>22.158168</td>\n",
              "      <td>17.753818</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          Model Name  ...  EM(Plau Ans)\n",
              "0                                      LSTM Baseline  ...      0.053718\n",
              "1                                  Deep LSTM + GloVe  ...      0.069066\n",
              "2                                    Bi-LSTM + GloVe  ...      0.126621\n",
              "3                    Bi-LSTM + GloVe + Q2C Attention  ...      0.000000\n",
              "4                Bi-LSTM + GloVe + Q2C-C2Q Attention  ...      0.069066\n",
              "5          LSTM Baseline + Universal Sentence Encode  ...      0.099762\n",
              "6                Bi-LSTM + Universal Sentence Encode  ...      0.023022\n",
              "7  Bi-LSTM + Q2C Attention + Universal Sentence E...  ...      0.042207\n",
              "8          BERT + Cased_L-12_H-768_A-12 + DeepPavlov  ...     18.179725\n",
              "9      BERT + Uncased_L-24_H-1024_A-24 + Huggingface  ...     17.753818\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCkMUNLEFYwG",
        "colab_type": "text"
      },
      "source": [
        "## Out of domain handing \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bppIF0J_Fews",
        "colab_type": "text"
      },
      "source": [
        "### Different language \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmEXz0ORFhIw",
        "colab_type": "text"
      },
      "source": [
        "### Totally irrelevant question given a known context from train domain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OOCtgDAFj-X",
        "colab_type": "text"
      },
      "source": [
        "### Totally different context say from Medicine and ask answer from it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwvNDiQRFZql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WulPny3Z00mm",
        "colab_type": "text"
      },
      "source": [
        "## Eval on manual input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v33J0DrkgSh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "19740284-575a-4bac-a955-7b1750783af5"
      },
      "source": [
        "all_models = load_all_models()\n",
        "all_models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model  LSTM Baseline  from  /content/drive/My Drive/AIML-MRC-Capstone/models/lstmbaseline-0/full_context_withoutstopwords_model_epoch_lstmbaseline0_nomask_gpu.h5\n",
            "Loading model  Deep LSTM + GloVe  from  /content/drive/My Drive/AIML-MRC-Capstone/models/deeplstm/full_context_withoutstopwords_model_epoch_25_deeplstm_glove_nomask_gpu.h5\n",
            "Loading model  Bi-LSTM + GloVe  from  /content/drive/My Drive/AIML-MRC-Capstone/models/bilstm/full_context_withoutstopwords_model_epoch_25_bilstm_glove_nomask_gpu.h5\n",
            "Loading model  Bi-LSTM + GloVe + Q2C Attention  from  /content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-q2c-attention-glove/full_context_withoutstopwords_model_epoch_25_bilstm_q2c-attention_glove.h5\n",
            "Loading model  Bi-LSTM + GloVe + Q2C-C2Q Attention  from  /content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-bidaf-glove/full_context_withoutstopwords_model_epoch_25_bilstm_bidaf_glove_nomask_gpu_after_fix.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Bi-LSTM + GloVe': <tensorflow.python.keras.engine.training.Model at 0x7fcbe0ff4da0>,\n",
              " 'Bi-LSTM + GloVe + Q2C Attention': <tensorflow.python.keras.engine.training.Model at 0x7fcbe0c5c550>,\n",
              " 'Bi-LSTM + GloVe + Q2C-C2Q Attention': <tensorflow.python.keras.engine.training.Model at 0x7fcbe0812ac8>,\n",
              " 'Deep LSTM + GloVe': <tensorflow.python.keras.engine.training.Model at 0x7fcc8058fcf8>,\n",
              " 'LSTM Baseline': <tensorflow.python.keras.engine.training.Model at 0x7fcc8070bb70>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcuhAMQNrgi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del all_models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R03OP9TxDc6P",
        "colab_type": "text"
      },
      "source": [
        "### TEST1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPHnb86cJdZL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "84dc5759-b688-48dd-94d7-8a547c00e68e"
      },
      "source": [
        "all_params = {\n",
        "    \"params_withoutstopwords\": loadparams(name='params_withoutstopwords.json'),\n",
        "    \"params_withstopwords_withuse\": loadparams(name='params_withstopwords_withuse.json')\n",
        "}\n",
        "all_tokenizers = {\n",
        "    \"glove\": load_tokenizer(all_params['params_withoutstopwords']),\n",
        "    \"use\": load_tokenizer(all_params['params_withstopwords_withuse'],'use')\n",
        "}\n",
        "all_params\n",
        "all_models = load_all_models()\n",
        "params = all_params['params_withoutstopwords']\n",
        "tokenizer = all_tokenizers['glove']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading GloVe 300D\n",
            "Vocab Loaded -  100850\n",
            "Loading Universal Sentence Encoder\n",
            "Vocab Loaded -  82505\n",
            "Loading model  LSTM Baseline  from  /content/drive/My Drive/AIML-MRC-Capstone/models/lstmbaseline-0/full_context_withoutstopwords_model_epoch_lstmbaseline0_nomask_gpu.h5\n",
            "Loading model  Deep LSTM + GloVe  from  /content/drive/My Drive/AIML-MRC-Capstone/models/deeplstm/full_context_withoutstopwords_model_epoch_25_deeplstm_glove_nomask_gpu.h5\n",
            "Loading model  Bi-LSTM + GloVe  from  /content/drive/My Drive/AIML-MRC-Capstone/models/bilstm/full_context_withoutstopwords_model_epoch_25_bilstm_glove_nomask_gpu.h5\n",
            "Loading model  Bi-LSTM + GloVe + Q2C Attention  from  /content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-q2c-attention-glove/full_context_withoutstopwords_model_epoch_25_bilstm_q2c-attention_glove.h5\n",
            "Loading model  Bi-LSTM + GloVe + Q2C-C2Q Attention  from  /content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-bidaf-glove/full_context_withoutstopwords_model_epoch_25_bilstm_bidaf_glove_nomask_gpu_after_fix.h5\n",
            "Loading model  LSTM Baseline + Universal Sentence Encode  from  /content/drive/My Drive/AIML-MRC-Capstone/models/lstmbaseline-use-withstop/full_context_withstopwords_model_epoch_25_lstmbaseline0_nomask_gpu.h5\n",
            "Loading model  Bi-LSTM + Universal Sentence Encode  from  /content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-use-withstop/full_context_withstopwords_model_epoch_25_bilstm_use_nomask_gpu.h5\n",
            "Loading model  Bi-LSTM + Q2C Attention + Universal Sentence Encode  from  /content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-q2c-attention-use-withstop/full_context_withstopwords_model_epoch_25_bilstm_q2c-attention_use.h5\n",
            "Loading model  BERT + Cased_L-12_H-768_A-12 + DeepPavlov  from  /content/drive/My Drive/AIML-MRC-Capstone/models/bert/bert-results.csv\n",
            "BERT is WIP !!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSw9oBmEc_BR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9817088c-1636-4a61-8ca0-43e371321aeb"
      },
      "source": [
        "test[test['id']=='57318afba5e9cc1400cdc01f']['question'].iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'When was Jaws released?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTNhlpswRbMW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "outputId": "59061f79-2aed-4538-9841-895f1ccc7e51"
      },
      "source": [
        "c1='Spielberg born on 1993. Three of Spielbergs films Jaws released on 1975, E.T. the Extra-Terrestrial (1982), and Jurassic Park (1993)achieved box office records, originated and came to epitomize the blockbuster film. The unadjusted gross of all Spielberg-directed films exceeds $9 billion worldwide, making him the highest-grossing director in history. His personal net worth is estimated to be more than $3 billion. He has been associated with composer John Williams since 1974, who composed music for all save five of Spielbergs feature films.'\n",
        "q1='when was jaws released'\n",
        "\n",
        "cs = [c1]\n",
        "qs = [q1]\n",
        "# c_,q_,span,y_,answer = predit_test(test['context'].iloc[39],test['question'].iloc[39])\n",
        "df = pd.DataFrame(columns=[\"Model\",\"Context\", \"Question\",\"Predicted Ans\"])\n",
        "# for m in all_models:\n",
        "m = 'Bi-LSTM + GloVe + Q2C Attention'\n",
        "c_,q_,span,y_,answer = predit_test(cs,qs, all_models[m], params=params)\n",
        "print('Prediction for model - ', m)\n",
        "for i in range(len(cs)):    \n",
        "  values = [m,cs[i],qs[i],answer[i]]\n",
        "  zipped = zip(df.columns, values)\n",
        "  a_dictionary = dict(zipped)\n",
        "  df = df.append(a_dictionary,ignore_index=True)     \n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0  1605   842   138  2155    51     3\n",
            "   4922   775  7170   238   138  2861   191 20474     1 11603  2687    66\n",
            "   4304   397  2155  1457  2499   384   418  1900    66   268    10 40435\n",
            "      1 12291   190     1 38358  4246     3  2119 37194   775  7027   403\n",
            "    406   834   410  8667     1 15716  1360     5   149  1100   737  3021\n",
            "   2715    14   646    10   300  1579  1705   111   406  2892   501  1262\n",
            "    427   172  4025   133  3627    42  2450    37  1230    57    59  2119\n",
            "   3097   242     3  4922   927   775]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-024aff593e61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# for m in all_models:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Bi-LSTM + GloVe + Q2C Attention'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredit_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prediction for model - '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-82-1fb77f20c1c1>\u001b[0m in \u001b[0;36mpredit_test\u001b[0;34m(context, question, modeltoUse, params)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m# tokens[tokenizer.word_index[i]] = i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# context_token.append(ci)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 1605"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkyTSbDp1Jfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkeEqGBKFbAo",
        "colab_type": "text"
      },
      "source": [
        "# Eval on News "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQJzz9F3FfW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import textwrap\n",
        "\n",
        "#Let's download the data from inshorts website.\n",
        "# Strictly inshort URL\n",
        "def load_news_from_url(url='https://inshorts.com/en/read/technology'):\n",
        "  # url = 'https://inshorts.com/en/read/technology'\n",
        "  news_category = url.split('/')[-1]\n",
        "  news_category\n",
        "  data = requests.get(url)\n",
        "  data.content\n",
        "  soup = BeautifulSoup(data.content, 'html.parser')\n",
        "  news_data = []\n",
        "  news_articles = [{'news_headline': headline.find('span', attrs={'itemprop': 'headline'}).string,\n",
        "                    'news_article': article.find('div', attrs={'itemprop': 'articleBody'}).string,\n",
        "                    'news_category': news_category} \n",
        "                  for headline, article in zip(soup.find_all('div', \n",
        "                                                              class_ = ['news-card-title news-right-box']), \n",
        "                                                soup.find_all('div', class_=['news-card-content news-right-box']))]\n",
        "  #Check news data\n",
        "  news_data.extend(news_articles)\n",
        "  news_data                    \n",
        "  #Building dataframe\n",
        "  df = pd.DataFrame(news_data, columns=['news_headline', 'news_article', 'news_category'])\n",
        "  df.info()  \n",
        "  return df"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2wTYX9wGpkN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "46d6f4e3-9bdf-4a4d-bc1f-d22307666902"
      },
      "source": [
        "df = load_news_from_url('https://inshorts.com/en/news/gileads-covid19-drug-remdesivir-to-cost-$2340-for-5day-treatment-1593438701842')\n",
        "wrapper = textwrap.TextWrapper(width=80) \n",
        "print(wrapper.fill(df['news_article'].iloc[0]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1 entries, 0 to 0\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   news_headline  1 non-null      object\n",
            " 1   news_article   1 non-null      object\n",
            " 2   news_category  1 non-null      object\n",
            "dtypes: object(3)\n",
            "memory usage: 152.0+ bytes\n",
            "American biopharmaceutical company Gilead has said that it will charge $390\n",
            "(29,450) per vial or about $2,340 (over 1.76 lakh) for a typical five-day\n",
            "course of treatment of its coronavirus-fighting drug remdesivir. The company on\n",
            "Monday said it would offer this price to the US government and other developed\n",
            "countries. The $390 per vial price is for government entities.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0-v0tJkL86C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80edb6eb-6848-42a9-c4ac-13ed5584ce6e"
      },
      "source": [
        "tfm = all_models['Bi-LSTM + GloVe + Q2C Attention']\n",
        "params = all_params['params_withoutstopwords']\n",
        "tokenizer = all_tokenizers['glove']\n",
        "c_,q_,span,y_,answer = predit_test([df['news_article'].iloc[0]],['what is per vial price'],tfm, params=params)                \n",
        "print(answer)         "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LH06OA9sFht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "566d336e-6ae3-4e90-c700-5500e04d3c78"
      },
      "source": [
        "print(predBERTHuggingface('what is per vial price',df['news_article'].iloc[0]))\n",
        "print(predBERTHuggingface('who is the company',df['news_article'].iloc[0]))\n",
        "print(predBERTHuggingface('what is the drug name',df['news_article'].iloc[0]))\n",
        "print(predBERTHuggingface('which government will the company offer',df['news_article'].iloc[0]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "$ 390\n",
            "gilead\n",
            "remdesivir\n",
            "us government\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ayh30ooSxTf-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "9eed4979-dfe8-426d-eea6-d1ebc6728f52"
      },
      "source": [
        "df = load_news_from_url('https://inshorts.com/en/news/worlds-secondlargest-data-centre-inaugurated-near-mumbai-1594205937864')\n",
        "wrapper = textwrap.TextWrapper(width=80) \n",
        "print(wrapper.fill(df['news_article'].iloc[0]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1 entries, 0 to 0\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   news_headline  1 non-null      object\n",
            " 1   news_article   1 non-null      object\n",
            " 2   news_category  1 non-null      object\n",
            "dtypes: object(3)\n",
            "memory usage: 152.0+ bytes\n",
            "Maharashtra CM Uddhav Thackeray virtually inaugurated the largest Tier IV Data\n",
            "Centre 'Yotta NM1' certified by Uptime Institute in Asia and second-largest in\n",
            "the world in Panvel near Mumbai. Built by Hiranandani Group subsidiary Yotta\n",
            "Infrastructure, 'Yotta NM1' is first of five data centre buildings. Once fully\n",
            "built, it'll have an overall capacity of 30,000 racks and 250 MW power.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIX_ati5xaM7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ea1fee20-ffcd-4f9d-83c6-2e5d16d1fed1"
      },
      "source": [
        "print(predBERTHuggingface('who is CM',df['news_article'].iloc[0]))\n",
        "print(predBERTHuggingface('who certified',df['news_article'].iloc[0]))\n",
        "print(predBERTHuggingface('where is panvel',df['news_article'].iloc[0]))\n",
        "print(predBERTHuggingface('who built',df['news_article'].iloc[0]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "maharashtra cm uddhav thackeray\n",
            "uptime institute\n",
            "mumbai\n",
            "hiranandani group subsidiary yotta infrastructure\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncB__cjC6T88",
        "colab_type": "text"
      },
      "source": [
        "# Serving API "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li214BwR8PaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "44e0fb6f-4ed4-4799-e0aa-930ea9cbf94e"
      },
      "source": [
        "# A nice and nifty way done by this fellow - https://medium.com/@kshitijvijay271199/flask-on-google-colab-f6525986797b\n",
        "# and of course ngrok saves the day !!\n",
        "!pip install flask-ngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMeXDG-y6WAC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "0a46a458-4202-4daf-9efa-2e6c42b72289"
      },
      "source": [
        "all_params = {\n",
        "    \"params_withoutstopwords\": loadparams(name='params_withoutstopwords.json'),\n",
        "    \"params_withstopwords_withuse\": loadparams(name='params_withstopwords_withuse.json')\n",
        "}\n",
        "all_tokenizers = {\n",
        "    \"glove\": load_tokenizer(all_params['params_withoutstopwords']),\n",
        "    \"use\": load_tokenizer(all_params['params_withstopwords_withuse'],'use')\n",
        "}\n",
        "all_params\n",
        "all_models = load_all_models()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading GloVe 300D\n",
            "Vocab Loaded -  100850\n",
            "Loading Universal Sentence Encoder\n",
            "Vocab Loaded -  82505\n",
            "Loading model  LSTM Baseline  from  /content/drive/My Drive/AIML-MRC-Capstone/models/lstmbaseline-0/full_context_withoutstopwords_model_epoch_lstmbaseline0_nomask_gpu.h5\n",
            "Loading model  Deep LSTM + GloVe  from  /content/drive/My Drive/AIML-MRC-Capstone/models/deeplstm/full_context_withoutstopwords_model_epoch_25_deeplstm_glove_nomask_gpu.h5\n",
            "Loading model  Bi-LSTM + GloVe  from  /content/drive/My Drive/AIML-MRC-Capstone/models/bilstm/full_context_withoutstopwords_model_epoch_25_bilstm_glove_nomask_gpu.h5\n",
            "Loading model  Bi-LSTM + GloVe + Q2C Attention  from  /content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-q2c-attention-glove/full_context_withoutstopwords_model_epoch_25_bilstm_q2c-attention_glove.h5\n",
            "Loading model  Bi-LSTM + GloVe + Q2C-C2Q Attention  from  /content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-bidaf-glove/full_context_withoutstopwords_model_epoch_25_bilstm_bidaf_glove_nomask_gpu_after_fix.h5\n",
            "Loading model  LSTM Baseline + Universal Sentence Encode  from  /content/drive/My Drive/AIML-MRC-Capstone/models/lstmbaseline-use-withstop/full_context_withstopwords_model_epoch_25_lstmbaseline0_nomask_gpu.h5\n",
            "Loading model  Bi-LSTM + Universal Sentence Encode  from  /content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-use-withstop/full_context_withstopwords_model_epoch_25_bilstm_use_nomask_gpu.h5\n",
            "Loading model  Bi-LSTM + Q2C Attention + Universal Sentence Encode  from  /content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-q2c-attention-use-withstop/full_context_withstopwords_model_epoch_25_bilstm_q2c-attention_use.h5\n",
            "Loading model  BERT + Cased_L-12_H-768_A-12 + DeepPavlov  from  /content/drive/My Drive/AIML-MRC-Capstone/models/bert/bert-results.csv\n",
            "BERT is WIP !!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cepdwTqD8Syx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flask import Flask\n",
        "from flask import request\n",
        "from flask import jsonify\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)  # Start ngrok when app is run\n",
        "\n",
        "# for / root, return Hello Word\n",
        "@app.route(\"/\")\n",
        "def root():\n",
        "    url = request.method\n",
        "    return f\"Welcome to the AIML Batch 4 - MRC Capstone\"\n",
        "\n",
        "@app.route(\"/models\")\n",
        "def listmodels():\n",
        "    url = request.method\n",
        "    return {'models':list_of_models}\n",
        "\n",
        "# for / root, return Hello Word\n",
        "@app.route(\"/predict\", methods=['POST'])\n",
        "def predict():\n",
        "    if request.method == 'POST':\n",
        "        try:\n",
        "            data = request.get_json()\n",
        "            modelid = data[\"model\"] \n",
        "            context = data[\"c\"]\n",
        "            question = data[\"q\"]\n",
        "\n",
        "            if(modelid == 'BERT'):\n",
        "              return jsonify(\"BERT is not yet supported\")            \n",
        "\n",
        "            thatmodel = [m for m in list_of_models if m['id']==modelid][0]\n",
        "            print('Running with model ',thatmodel['name'])\n",
        "            if(thatmodel['type']=='With stopwords'):\n",
        "              params = all_params['params_withstopwords_withuse']\n",
        "              tokenizer = all_tokenizers['use']\n",
        "            elif(thatmodel['type']=='Without stopwords'):\n",
        "              params = all_params['params_withoutstopwords']\n",
        "              tokenizer = all_tokenizers['glove']\n",
        "            \n",
        "            tfmodel = all_models[thatmodel['name']]            \n",
        "            c_,q_,span,y_,answer = predit_test([context],[question],tfmodel, params=params)                \n",
        "            print(context, question, answer)         \n",
        "            # lin_reg = joblib.load(\"./linear_regression_model.pkl\")\n",
        "        except err:\n",
        "            print(err)\n",
        "            return jsonify(\"Some thing is not right !!\")\n",
        "        finally:\n",
        "          del tfmodel\n",
        "\n",
        "        return jsonify({'context': context, 'question':question, 'answer': answer})\n",
        "\n",
        "# for / root, return Hello Word\n",
        "@app.route(\"/predict_from_url\", methods=['POST'])\n",
        "def predictfromnewurl():\n",
        "    if request.method == 'POST':\n",
        "        try:\n",
        "            data = request.get_json()\n",
        "            modelid = data[\"model\"] \n",
        "            url = data[\"url\"]\n",
        "            df = load_news_from_url(url)\n",
        "            context = df['news_article'].iloc[0]\n",
        "            question = data[\"q\"]\n",
        "\n",
        "            if(modelid == 'BERT'):\n",
        "              return jsonify(\"BERT is not yet supported\")            \n",
        "\n",
        "            thatmodel = [m for m in list_of_models if m['id']==modelid][0]\n",
        "            print('Running with model ',thatmodel['name'])\n",
        "            if(thatmodel['type']=='With stopwords'):\n",
        "              params = all_params['params_withstopwords_withuse']\n",
        "              tokenizer = all_tokenizers['use']\n",
        "            elif(thatmodel['type']=='Without stopwords'):\n",
        "              params = all_params['params_withoutstopwords']\n",
        "              tokenizer = all_tokenizers['glove']\n",
        "            \n",
        "            tfmodel = all_models[thatmodel['name']]            \n",
        "            c_,q_,span,y_,answer = predit_test([context],[question],tfmodel, params=params)                \n",
        "            print(context, question, answer)         \n",
        "            # lin_reg = joblib.load(\"./linear_regression_model.pkl\")\n",
        "        except err:\n",
        "            print(err)\n",
        "            return jsonify(\"Some thing is not right !!\")\n",
        "        finally:\n",
        "          del tfmodel\n",
        "\n",
        "        return jsonify({'context': context, 'question':question, 'answer': answer})\n",
        "\n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqy24lzf_1yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYpdBUf8bnFg",
        "colab_type": "text"
      },
      "source": [
        "# Test Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmrQ9PkQtr57",
        "colab_type": "text"
      },
      "source": [
        "## Question Category "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JkjxJ11bohR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d6698bc2-a587-48ec-8ed6-2dfac3b5b3f5"
      },
      "source": [
        "test = load_test_data()\n",
        "train = load_test_data(name='train-withoutstopwords.csv')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(26062, 16)\n",
            "(78183, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRq7jpR7btGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_question_category_distri(data):\n",
        "  stpwrds_ques = ['when', 'what', 'which', 'who', 'how', 'where', 'whom', 'why']\n",
        "\n",
        "  def get_categ(token1,token2):\n",
        "      if token1 in stpwrds_ques:\n",
        "          return token1\n",
        "      elif token2 in stpwrds_ques:\n",
        "          return token2\n",
        "      else:\n",
        "          return \"Other\"\n",
        "\n",
        "  #stpwrds_ques = ['when', 'what', 'which', 'who', 'how', 'where', 'whom', 'why']\n",
        "  data['Token1'] = data.clean_question.str.split(' ').str[0]\n",
        "  data['Token2'] = data.clean_question.str.split(' ').str[1]\n",
        "  data['ques_category'] = data.apply(lambda x: get_categ(x['Token1'],x['Token2']),axis=1)\n",
        "  return data['ques_category'].value_counts(normalize=True)*100, data"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DeJ1mLRP9h3",
        "colab_type": "text"
      },
      "source": [
        "### Q-category for train test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kXMNsTDddzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ques_cat, test = get_question_category_distri(data=test)\n",
        "tques_cat, train = get_question_category_distri(data=train)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmjHS2ZTotlP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "5640b98a-dd00-4275-a77b-aa26f357d06e"
      },
      "source": [
        "df = pd.DataFrame([tques_cat,ques_cat])\n",
        "df = df.transpose()\n",
        "df.columns = ['train','test']\n",
        "df"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>what</th>\n",
              "      <td>50.439354</td>\n",
              "      <td>51.039828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Other</th>\n",
              "      <td>13.972347</td>\n",
              "      <td>13.732638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>who</th>\n",
              "      <td>9.686249</td>\n",
              "      <td>9.749827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>how</th>\n",
              "      <td>9.288464</td>\n",
              "      <td>9.120559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>when</th>\n",
              "      <td>6.124093</td>\n",
              "      <td>6.100836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>which</th>\n",
              "      <td>5.122597</td>\n",
              "      <td>5.149259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>where</th>\n",
              "      <td>3.779594</td>\n",
              "      <td>3.491674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>why</th>\n",
              "      <td>1.413351</td>\n",
              "      <td>1.477247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>whom</th>\n",
              "      <td>0.173951</td>\n",
              "      <td>0.138132</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           train       test\n",
              "what   50.439354  51.039828\n",
              "Other  13.972347  13.732638\n",
              "who     9.686249   9.749827\n",
              "how     9.288464   9.120559\n",
              "when    6.124093   6.100836\n",
              "which   5.122597   5.149259\n",
              "where   3.779594   3.491674\n",
              "why     1.413351   1.477247\n",
              "whom    0.173951   0.138132"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV-0QIT7sAwZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "bbbedff5-6677-46f3-e49c-d908e18b5824"
      },
      "source": [
        "df['ori'] = [55.908318,10.497034,10.184376,8.416479,5.726700,4.255368,3.411651,1.542600,0.057474]    \n",
        "df"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>ori</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>what</th>\n",
              "      <td>50.439354</td>\n",
              "      <td>51.039828</td>\n",
              "      <td>55.908318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Other</th>\n",
              "      <td>13.972347</td>\n",
              "      <td>13.732638</td>\n",
              "      <td>10.497034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>who</th>\n",
              "      <td>9.686249</td>\n",
              "      <td>9.749827</td>\n",
              "      <td>10.184376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>how</th>\n",
              "      <td>9.288464</td>\n",
              "      <td>9.120559</td>\n",
              "      <td>8.416479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>when</th>\n",
              "      <td>6.124093</td>\n",
              "      <td>6.100836</td>\n",
              "      <td>5.726700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>which</th>\n",
              "      <td>5.122597</td>\n",
              "      <td>5.149259</td>\n",
              "      <td>4.255368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>where</th>\n",
              "      <td>3.779594</td>\n",
              "      <td>3.491674</td>\n",
              "      <td>3.411651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>why</th>\n",
              "      <td>1.413351</td>\n",
              "      <td>1.477247</td>\n",
              "      <td>1.542600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>whom</th>\n",
              "      <td>0.173951</td>\n",
              "      <td>0.138132</td>\n",
              "      <td>0.057474</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           train       test        ori\n",
              "what   50.439354  51.039828  55.908318\n",
              "Other  13.972347  13.732638  10.497034\n",
              "who     9.686249   9.749827  10.184376\n",
              "how     9.288464   9.120559   8.416479\n",
              "when    6.124093   6.100836   5.726700\n",
              "which   5.122597   5.149259   4.255368\n",
              "where   3.779594   3.491674   3.411651\n",
              "why     1.413351   1.477247   1.542600\n",
              "whom    0.173951   0.138132   0.057474"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRE1Lg0coBeT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "9fba1018-2f74-468a-faad-b189936c5d77"
      },
      "source": [
        "sns.lineplot(data=df)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc90d5120f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcZ11cdgRjpH",
        "colab_type": "text"
      },
      "source": [
        "### Update Answer Length in test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYRpTX3lRmY_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "38ab7ceb-d979-482f-9714-9a695a6993ca"
      },
      "source": [
        "def get_ans_token_length(ans):\n",
        "    if ans == 'IMPOSSIBLE':\n",
        "        return 0    \n",
        "    else:\n",
        "        return len(ans.split())\n",
        "\n",
        "test['ans_token_len'] = test.apply(lambda x: get_ans_token_length(x['clean_answer']),axis=1)\n",
        "test.head(5)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>id</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer</th>\n",
              "      <th>plausible_answer_start</th>\n",
              "      <th>plausible_answer</th>\n",
              "      <th>is_impossible</th>\n",
              "      <th>clean_context</th>\n",
              "      <th>clean_question</th>\n",
              "      <th>clean_answer</th>\n",
              "      <th>answer_len</th>\n",
              "      <th>answer_end</th>\n",
              "      <th>answer_span</th>\n",
              "      <th>answer_word_span</th>\n",
              "      <th>Token1</th>\n",
              "      <th>Token2</th>\n",
              "      <th>ques_category</th>\n",
              "      <th>ans_token_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Queen_Victoria</td>\n",
              "      <td>Internationally, Victoria took a keen interest...</td>\n",
              "      <td>How was the House of Orleans and the British R...</td>\n",
              "      <td>5722d1770dadf01500fa1f04</td>\n",
              "      <td>218</td>\n",
              "      <td>by marriage through the Coburgs</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>internationally victoria took keen interest im...</td>\n",
              "      <td>how was the house of orleans and the british r...</td>\n",
              "      <td>by marriage through the coburgs</td>\n",
              "      <td>31</td>\n",
              "      <td>249</td>\n",
              "      <td>(218, 249)</td>\n",
              "      <td>(-1, -1)</td>\n",
              "      <td>how</td>\n",
              "      <td>was</td>\n",
              "      <td>how</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Southampton</td>\n",
              "      <td>Southampton's largest retail centre, and 35th ...</td>\n",
              "      <td>What's the largest retail center in Southampton?</td>\n",
              "      <td>56f8afe39e9bad19000a031d</td>\n",
              "      <td>72</td>\n",
              "      <td>WestQuay Shopping Centre</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>southamptons largest retail centre 35th larges...</td>\n",
              "      <td>whats the largest retail center in southampton</td>\n",
              "      <td>westquay shopping centre</td>\n",
              "      <td>24</td>\n",
              "      <td>96</td>\n",
              "      <td>(72, 96)</td>\n",
              "      <td>(7, 9)</td>\n",
              "      <td>whats</td>\n",
              "      <td>the</td>\n",
              "      <td>Other</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Immunology</td>\n",
              "      <td>Other immune system disorders include various ...</td>\n",
              "      <td>What characterizes a hypersensitivity?</td>\n",
              "      <td>5706aa0a75f01819005e7ce8</td>\n",
              "      <td>110</td>\n",
              "      <td>respond inappropriately to otherwise harmless ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>immune system disorders include various hypers...</td>\n",
              "      <td>what characterizes a hypersensitivity</td>\n",
              "      <td>respond inappropriately to otherwise harmless ...</td>\n",
              "      <td>56</td>\n",
              "      <td>166</td>\n",
              "      <td>(110, 166)</td>\n",
              "      <td>(8, 13)</td>\n",
              "      <td>what</td>\n",
              "      <td>characterizes</td>\n",
              "      <td>what</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Steven_Spielberg</td>\n",
              "      <td>Spielberg won the Academy Award for Best Direc...</td>\n",
              "      <td>When was Jaws released?</td>\n",
              "      <td>57318afba5e9cc1400cdc01f</td>\n",
              "      <td>143</td>\n",
              "      <td>1975</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>spielberg academy award best director schindle...</td>\n",
              "      <td>when was jaws released</td>\n",
              "      <td>1975</td>\n",
              "      <td>4</td>\n",
              "      <td>147</td>\n",
              "      <td>(143, 147)</td>\n",
              "      <td>(15, 15)</td>\n",
              "      <td>when</td>\n",
              "      <td>was</td>\n",
              "      <td>when</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Electric_motor</td>\n",
              "      <td>Because the rotor is much lighter in weight (m...</td>\n",
              "      <td>What advantage doesn't a coreless rotor have o...</td>\n",
              "      <td>5ad168ad645df0001a2d1a12</td>\n",
              "      <td>-1</td>\n",
              "      <td></td>\n",
              "      <td>141.0</td>\n",
              "      <td>accelerate much more rapidly</td>\n",
              "      <td>True</td>\n",
              "      <td>rotor much lighter weight mass conventional ro...</td>\n",
              "      <td>what advantage doesnt a coreless rotor have ov...</td>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>(-1, -1)</td>\n",
              "      <td>(-1, -1)</td>\n",
              "      <td>what</td>\n",
              "      <td>advantage</td>\n",
              "      <td>what</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              title  ... ans_token_len\n",
              "0    Queen_Victoria  ...             5\n",
              "1       Southampton  ...             3\n",
              "2        Immunology  ...             6\n",
              "3  Steven_Spielberg  ...             1\n",
              "4    Electric_motor  ...             0\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id3jfolLQLEq",
        "colab_type": "text"
      },
      "source": [
        "### Model perf per question category for BERT and bilstm-glove-q2c-attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tmwDQ_rQUP1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "b85c4bcb-c741-4f87-bc79-d48c3f0da93b"
      },
      "source": [
        "loc = [m for m in list_of_models if m['id']=='bilstm-glove-q2c-attention'][0]['loc']\n",
        "loc\n",
        "bilstm_glove_q2c_attention = load_mrc_model(loc)\n",
        "params = loadparams(name='params_withoutstopwords.json')\n",
        "tokenizer = load_tokenizer(name='glove')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model from /content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-q2c-attention-glove/full_context_withoutstopwords_model_epoch_25_bilstm_q2c-attention_glove.h5\n",
            "Loading GloVe 300D\n",
            "Vocab Loaded -  100850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lucI52zRQ399",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7e15bf0c-4a43-4b05-a0b0-6e852e4f465d"
      },
      "source": [
        "# Ensure that BERT is loaded from above cell\n",
        "print(bilstm_glove_q2c_attention)\n",
        "print(berthugmodel)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.training.Model object at 0x7f759ab29128>\n",
            "<transformers.modeling_tf_bert.TFBertForQuestionAnswering object at 0x7f759f7194a8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDqJ_16WTJQv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0e87eb15-57a3-4337-9e9d-edb0eb8b9066"
      },
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "with strategy.scope():\n",
        "  test_context_sequence, test_question_sequence = generate_question_context_sequence(context=test[\"clean_context\"].values,\n",
        "                                question=test[\"clean_question\"].values,\n",
        "                                question_max_length=params['question_max_length'],\n",
        "                                padding=params['question_pad_seq'],\n",
        "                                context_max_length=params['context_max_length']\n",
        "                                )  \n",
        "  y_prediction = bilstm_glove_q2c_attention.predict([test_question_sequence,test_context_sequence])\n",
        "  y_prediction_new,start_pred,end_pred = combine_y(y_prediction,test.shape[0])\n",
        "  # acc_score,macro_f1_score,micro_f1_score = accuracy_metrics(y_test_new,y_prediction_new)\n",
        "  y_pred_text = generate_y_preds_text(test,start_pred,end_pred)\n",
        "  test['predictions'] = y_pred_text"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 26062/26062 [00:29<00:00, 875.43it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awNcA46oTfz9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e9faccc-ce77-4211-edc7-980036ce8a16"
      },
      "source": [
        "exact_raw, f1_raw, exact_scores_pa,f1_scores_pa = get_raw_scores(test, y_pred_text)\n",
        "exact, f1,exact_pa, f1_pa, total = make_eval_dict(exact_raw,f1_raw, exact_scores_pa,f1_scores_pa)\n",
        "\n",
        "print(exact, f1,exact_pa, f1_pa, total)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33.09416007980968 33.09511933082649 0.0 0.0 26062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2di9kbONaxhj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "f12998b4-b845-4c5a-ffe5-526ed08782fa"
      },
      "source": [
        "qc = test['ques_category'].value_counts(normalize=True)*100\n",
        "qcdf = pd.DataFrame().append(qc)\n",
        "# qcdf.columns = ['Data Distri']\n",
        "qcdf\n",
        "# ','F1(Ans)','EM(Ans)','F1(Plau Ans)','EM(Plau Ans)']"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Other</th>\n",
              "      <th>how</th>\n",
              "      <th>what</th>\n",
              "      <th>when</th>\n",
              "      <th>where</th>\n",
              "      <th>which</th>\n",
              "      <th>who</th>\n",
              "      <th>whom</th>\n",
              "      <th>why</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ques_category</th>\n",
              "      <td>13.732638</td>\n",
              "      <td>9.120559</td>\n",
              "      <td>51.039828</td>\n",
              "      <td>6.100836</td>\n",
              "      <td>3.491674</td>\n",
              "      <td>5.149259</td>\n",
              "      <td>9.749827</td>\n",
              "      <td>0.138132</td>\n",
              "      <td>1.477247</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Other       how       what  ...       who      whom       why\n",
              "ques_category  13.732638  9.120559  51.039828  ...  9.749827  0.138132  1.477247\n",
              "\n",
              "[1 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DENVk4eyh4g4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "708328cb-f421-4715-9c04-5d8549ccfbc2"
      },
      "source": [
        "gcdf_idx = list(qcdf.columns)\n",
        "print(gcdf_idx)\n",
        "gcdf_idx.index('Other')"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Other', 'how', 'what', 'when', 'where', 'which', 'who', 'whom', 'why']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b1VnKXYkvBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.to_pickle(model_path + 'test_with_q-cate_a_lenth.pkl')"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EslzVbHkZw8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def qc_results():\n",
        "  gcdf_idx = list(qcdf.columns)\n",
        "  qc_results = {'F1(Ans)': [0,0,0,0,0,0,0,0,0],\n",
        "                'EM(Ans)':[0,0,0,0,0,0,0,0,0],\n",
        "                'F1(Plau Ans)':[0,0,0,0,0,0,0,0,0],\n",
        "                'EM(Plau Ans)':[0,0,0,0,0,0,0,0,0]\n",
        "                }\n",
        "  for id in exact_raw:\n",
        "    # print(id)\n",
        "    ques_category = test[test['id'] == id]['ques_category'].iloc[0]\n",
        "    # print(ques_category)  \n",
        "    q_in = gcdf_idx.index(ques_category)\n",
        "    # print(q_in)  \n",
        "    # exact on ans\n",
        "    # print(exact_raw[id], f1_raw[id])\n",
        "    if(exact_raw[id] == 1):\n",
        "      qc_results['EM(Ans)'][q_in] = qc_results['EM(Ans)'][q_in] + 1\n",
        "    if(f1_raw[id] == 1):\n",
        "      qc_results['F1(Ans)'][q_in] = qc_results['F1(Ans)'][q_in] + 1\n",
        "    if(exact_scores_pa[id] == 1):\n",
        "      qc_results['EM(Plau Ans)'][q_in] = qc_results['EM(Plau Ans)'][q_in] + 1\n",
        "    if(f1_scores_pa[id] == 1):\n",
        "      qc_results['F1(Plau Ans)'][q_in] = qc_results['F1(Plau Ans)'][q_in] + 1\n",
        "\n",
        "    # if(np.isnan(qc_results[ques_category])):\n",
        "\n",
        "    # print(qc_results[ques_category])\n",
        "    # break\n",
        "  \n",
        "  return qc_results"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fPyekYXuo3L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "adc3d704-2b46-4295-a511-3f77c5dcdf16"
      },
      "source": [
        "bilstm_qc_results = qc_results()\n",
        "bilstm_qc_results"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'EM(Ans)': [872, 726, 4837, 516, 280, 356, 894, 9, 135],\n",
              " 'EM(Plau Ans)': [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " 'F1(Ans)': [872, 726, 4837, 516, 280, 356, 894, 9, 135],\n",
              " 'F1(Plau Ans)': [0, 0, 0, 0, 0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql5YuvqhuZCw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec94b69d-b270-49d8-961e-169347348c69"
      },
      "source": [
        "loc = [m for m in list_of_models if m['id']=='bert-huggingface'][0]['loc']\n",
        "bert_results = pd.read_csv(loc)\n",
        "bert_results.loc[bert_results['answer'].isna(), 'answer'] = '' \n",
        "bert_results.loc[bert_results['plausible_answer'].isna(), 'plausible_answer'] = ''\n",
        "bert_results.loc[bert_results['prediction'].isna(), 'prediction'] = ''\n",
        "exact_raw, f1_raw, exact_scores_pa,f1_scores_pa = get_raw_scores(bert_results, bert_results['prediction'].values.tolist())\n",
        "exact, f1,exact_pa, f1_pa, total = make_eval_dict(exact_raw,f1_raw, exact_scores_pa,f1_scores_pa)  \n",
        "\n",
        "print(exact, f1,exact_pa, f1_pa, total)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49.76977975596654 57.513153394439584 17.753817819046887 22.158168097512167 26062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv9uInScxqnf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "fd2d5b29-6502-4d62-c214-6fab11943ef3"
      },
      "source": [
        "bert_qc_results = qc_results()\n",
        "bert_qc_results"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'EM(Ans)': [2015, 923, 6264, 918, 478, 837, 1384, 25, 127],\n",
              " 'EM(Plau Ans)': [524, 294, 2465, 331, 157, 220, 586, 9, 41],\n",
              " 'F1(Ans)': [2015, 923, 6264, 918, 478, 837, 1384, 25, 127],\n",
              " 'F1(Plau Ans)': [524, 294, 2465, 331, 157, 220, 586, 9, 41]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUOUnFyq0BHH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d21d5baa-9f60-4f1e-a704-7d420056fd20"
      },
      "source": [
        "list(qcdf.columns)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Other', 'how', 'what', 'when', 'where', 'which', 'who', 'whom', 'why']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObPWH3LPzXlF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "9b2fff1a-c767-4bab-d3a8-62192c4184cc"
      },
      "source": [
        "q = pd.DataFrame(data=bert_qc_results)\n",
        "q.drop(['EM(Ans)','EM(Plau Ans)'],axis=1, inplace=True)\n",
        "q.columns = ['BERT-Hugginface- F1(Ans)','BERT-Hugginface- F1(Pl Ans)']\n",
        "q['Question Category'] = qcdf.columns\n",
        "q.set_index('Question Category',inplace=True)\n",
        "q['BiLSTM-Q2C-F1(Ans)'] = bilstm_qc_results['F1(Ans)'] \n",
        "q['BiLSTM-Q2C-F1(Ans)'] = bilstm_qc_results['F1(Ans)']\n",
        "q['Question Category'] = test['ques_category'].value_counts()\n",
        "q"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BERT-Hugginface- F1(Ans)</th>\n",
              "      <th>BERT-Hugginface- F1(Pl Ans)</th>\n",
              "      <th>BiLSTM-Q2C-F1(Ans)</th>\n",
              "      <th>Question Category</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Question Category</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Other</th>\n",
              "      <td>2015</td>\n",
              "      <td>524</td>\n",
              "      <td>872</td>\n",
              "      <td>3579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>how</th>\n",
              "      <td>923</td>\n",
              "      <td>294</td>\n",
              "      <td>726</td>\n",
              "      <td>2377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>what</th>\n",
              "      <td>6264</td>\n",
              "      <td>2465</td>\n",
              "      <td>4837</td>\n",
              "      <td>13302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>when</th>\n",
              "      <td>918</td>\n",
              "      <td>331</td>\n",
              "      <td>516</td>\n",
              "      <td>1590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>where</th>\n",
              "      <td>478</td>\n",
              "      <td>157</td>\n",
              "      <td>280</td>\n",
              "      <td>910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>which</th>\n",
              "      <td>837</td>\n",
              "      <td>220</td>\n",
              "      <td>356</td>\n",
              "      <td>1342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>who</th>\n",
              "      <td>1384</td>\n",
              "      <td>586</td>\n",
              "      <td>894</td>\n",
              "      <td>2541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>whom</th>\n",
              "      <td>25</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>why</th>\n",
              "      <td>127</td>\n",
              "      <td>41</td>\n",
              "      <td>135</td>\n",
              "      <td>385</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   BERT-Hugginface- F1(Ans)  ...  Question Category\n",
              "Question Category                            ...                   \n",
              "Other                                  2015  ...               3579\n",
              "how                                     923  ...               2377\n",
              "what                                   6264  ...              13302\n",
              "when                                    918  ...               1590\n",
              "where                                   478  ...                910\n",
              "which                                   837  ...               1342\n",
              "who                                    1384  ...               2541\n",
              "whom                                     25  ...                 36\n",
              "why                                     127  ...                385\n",
              "\n",
              "[9 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywe6NIAv32Vp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "bdb3b263-2357-4169-a954-413ddf2e252d"
      },
      "source": [
        "q.plot(kind='barh',figsize=(5,5))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f759f1e6588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymfnh9JZG1Oi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, f1_raw_bert, _,f1_scores_pa_bert = get_raw_scores(bert_results, bert_results['prediction'].values.tolist())"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWIZjC93M2HK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1_raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aUN_E1446YW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cc690595-7508-48ad-c61b-aee1b77ded41"
      },
      "source": [
        "# 1,2,3,4, >5\n",
        "ans_length_results = {'BERT-Hugginface-F1(Ans)': [0,0,0,0,0],\n",
        "                'BERT-Hugginface-F1(Plau Ans)':[0,0,0,0,0],\n",
        "                'BiLSTM-Q2C-F1(Ans)':[0,0,0,0,0]\n",
        "                }\n",
        "for id in exact_raw:\n",
        "  # print(id)\n",
        "  ans_token_len = test[test['id'] == id]['ans_token_len'].iloc[0]  \n",
        "\n",
        "  if(f1_scores_pa_bert[id] == 1):\n",
        "    pl_ans_token_len = get_ans_token_length(test[test['id'] == id]['plausible_answer'].iloc[0])\n",
        "    if(pl_ans_token_len == 1):\n",
        "      ans_length_results['BERT-Hugginface-F1(Plau Ans)'][0] = ans_length_results['BERT-Hugginface-F1(Plau Ans)'][0] + 1       \n",
        "    elif(pl_ans_token_len == 2):\n",
        "      ans_length_results['BERT-Hugginface-F1(Plau Ans)'][1] = ans_length_results['BERT-Hugginface-F1(Plau Ans)'][1] + 1       \n",
        "    elif(pl_ans_token_len == 3):      \n",
        "      ans_length_results['BERT-Hugginface-F1(Plau Ans)'][2] = ans_length_results['BERT-Hugginface-F1(Plau Ans)'][2] + 1                \n",
        "    elif(pl_ans_token_len == 4):      \n",
        "        ans_length_results['BERT-Hugginface-F1(Plau Ans)'][3] = ans_length_results['BERT-Hugginface-F1(Plau Ans)'][3] + 1           \n",
        "    elif(pl_ans_token_len > 4):      \n",
        "        ans_length_results['BERT-Hugginface-F1(Plau Ans)'][4] = ans_length_results['BERT-Hugginface-F1(Plau Ans)'][4] + 1      \n",
        "\n",
        "  # print(ques_category)  \n",
        "  if(ans_token_len == 1):      \n",
        "    if(f1_raw[id] == 1):\n",
        "      ans_length_results['BiLSTM-Q2C-F1(Ans)'][0] = ans_length_results['BiLSTM-Q2C-F1(Ans)'][0] + 1\n",
        "    if(f1_raw_bert[id] == 1):\n",
        "      ans_length_results['BERT-Hugginface-F1(Ans)'][0] = ans_length_results['BERT-Hugginface-F1(Ans)'][0] + 1      \n",
        "  elif(ans_token_len == 2):\n",
        "    if(f1_raw[id] == 1):\n",
        "      ans_length_results['BiLSTM-Q2C-F1(Ans)'][1] = ans_length_results['BiLSTM-Q2C-F1(Ans)'][1] + 1\n",
        "    if(f1_raw_bert[id] == 1):\n",
        "      ans_length_results['BERT-Hugginface-F1(Ans)'][1] = ans_length_results['BERT-Hugginface-F1(Ans)'][1] + 1\n",
        "  elif(ans_token_len == 3): \n",
        "    if(f1_raw[id] == 1):\n",
        "      ans_length_results['BiLSTM-Q2C-F1(Ans)'][2] = ans_length_results['BiLSTM-Q2C-F1(Ans)'][2] + 1\n",
        "    if(f1_raw_bert[id] == 1):\n",
        "      ans_length_results['BERT-Hugginface-F1(Ans)'][2] = ans_length_results['BERT-Hugginface-F1(Ans)'][2] + 1\n",
        "  elif(ans_token_len == 4):\n",
        "      if(f1_raw[id] == 1):\n",
        "        ans_length_results['BiLSTM-Q2C-F1(Ans)'][3] = ans_length_results['BiLSTM-Q2C-F1(Ans)'][3] + 1\n",
        "      if(f1_raw_bert[id] == 1):\n",
        "        ans_length_results['BERT-Hugginface-F1(Ans)'][3] = ans_length_results['BERT-Hugginface-F1(Ans)'][3] + 1\n",
        "  elif(ans_token_len > 4):  \n",
        "      if(f1_raw[id] == 1):\n",
        "        ans_length_results['BiLSTM-Q2C-F1(Ans)'][4] = ans_length_results['BiLSTM-Q2C-F1(Ans)'][4] + 1\n",
        "      if(f1_raw_bert[id] == 1):\n",
        "        ans_length_results['BERT-Hugginface-F1(Ans)'][4] = ans_length_results['BERT-Hugginface-F1(Ans)'][4] + 1\n",
        "\n",
        "\n",
        "ans_length_results                "
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'BERT-Hugginface-F1(Ans)': [4883, 3527, 2031, 876, 1615],\n",
              " 'BERT-Hugginface-F1(Plau Ans)': [1758, 1187, 730, 342, 610],\n",
              " 'BiLSTM-Q2C-F1(Ans)': [3500, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNCI2AJqNIEt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "59bbd16b-9947-4ebf-ee4e-ba809f2dec30"
      },
      "source": [
        "w = pd.DataFrame(ans_length_results)\n",
        "w['Answer length'] = ['Len 1', 'Len 2', 'Len 3', 'Len 4', 'Len > 4']\n",
        "w.set_index('Answer length',inplace=True)\n",
        "# w.drop(['BiLSTM-Q2C-F1(Ans)'],axis=1,inplace=True)\n",
        "w"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BERT-Hugginface-F1(Ans)</th>\n",
              "      <th>BERT-Hugginface-F1(Plau Ans)</th>\n",
              "      <th>BiLSTM-Q2C-F1(Ans)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Answer length</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Len 1</th>\n",
              "      <td>4883</td>\n",
              "      <td>1758</td>\n",
              "      <td>3500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Len 2</th>\n",
              "      <td>3527</td>\n",
              "      <td>1187</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Len 3</th>\n",
              "      <td>2031</td>\n",
              "      <td>730</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Len 4</th>\n",
              "      <td>876</td>\n",
              "      <td>342</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Len &gt; 4</th>\n",
              "      <td>1615</td>\n",
              "      <td>610</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               BERT-Hugginface-F1(Ans)  ...  BiLSTM-Q2C-F1(Ans)\n",
              "Answer length                           ...                    \n",
              "Len 1                             4883  ...                3500\n",
              "Len 2                             3527  ...                   0\n",
              "Len 3                             2031  ...                   0\n",
              "Len 4                              876  ...                   0\n",
              "Len > 4                           1615  ...                   0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOqsKtfjOwmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "faf08410-7be4-4131-f170-36c0582f35b6"
      },
      "source": [
        "w.plot(kind='barh',figsize=(8,5))"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f759f18cbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAEvCAYAAADPf1JOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7TUdb3/8ecbJEBQRAVFUVFEDLlsNqihclJLI/GgeCn4ad61y5EulqW/NKloZS6O8rOlKZoH9HigSPFCpQdN8JJlgHBAREXdGmIoKCIp98/vj5k9Z2/4bhhwDzNsno+1ZjHf+3s+S2de+/O9fCKlhCRJ0saalbsASZJUmQwJkiQpkyFBkiRlMiRIkqRMhgRJkpTJkCBJkjLtUu4CKsnee++dunTpUu4yJEnaLmbOnLk0pdShoeWGhDq6dOnCjBkzyl2GJEnbRUS8sbnlnm6QJEmZDAmSJCmTIUGSJGXymgRJO621a9eyaNEiVq1aVe5SpJJq1aoVnTt3pkWLFlu1nSFB0k5r0aJF7LbbbnTp0oWIKHc5UkmklFi2bBmLFi3i4IMP3qptPd0gaae1atUq9tprLwOCmrSIYK+99tqmHjNDgqSdmgFBO4Nt/e/ckCBJZdS8eXOqqqro06cP1dXV/PnPfwagpqaG1q1bU1VVVXjdfffdQO6ZLr169aJ379589rOf5Y033mDo0KFUVVVx6KGH0q5du8I2tfur1bZt23rT48aN4/LLL2/0z/XQQw9x/fXXb3G9K6+8kiOOOIIrr7yy0WuA7HZcs2YNCxYsYMCAAbRs2ZLRo0fX2+bjjz/ms5/9LOvXry/MGzNmDK1ateKDDz7Y5lq+973v8ac//Wmbty8Hr0mQpLwuV/2+UfdXc/3gLa7TunVrZs+eDcCjjz7K1VdfzfTp0wHo2rVrYdnGnnjiCfbee2+uu+46Ro0axeTJkwGYNm0ao0ePZsqUKY30KbbNkCFDGDJkyBbXGzt2LO+99x7NmzcvWS1Z7bjnnnty880388ADD2yy/l133cUZZ5xRr6YJEyZw5JFHcv/993PhhRduUx0jRozg0ksv5cQTT9ym7cvBngRJqhArVqygffv2W7XNgAEDeOuttxrl+BdccAG/+93vCtO1vQ4bNmzgG9/4BocffjgnnXQSp5xySmG9P/zhDxx++OH069ePb37zm5x66qlA/R6KCy64gG9+85scc8wxHHLIIYVthwwZwsqVK+nXrx+/+c1vePjhhzn66KPp27cvn//851myZAkAK1eu5MILLyz0ntx3330A/Pd//zcDBgygurqas88+m5UrVxb9WTt27MiRRx6ZebX/vffey2mnnVaYfvXVV1m5ciWjRo1iwoQJhfnjxo3jjDPOYNCgQXTr1o3vf//7AKxfv54LLriAnj170qtXL2666SYADjroIJYtW8Y//vGPoussN3sSJKmMPv74Y6qqqli1ahVvv/12ve7oV199laqqqsL0L3/5SwYOHFhv+0ceeYTTTz99q49X67333tviX/z3338/NTU1zJ8/n3feeYdPf/rTXHTRRaxatYqvfvWrPPnkkxx88MEMHz68wX28/fbbPP300yxYsIAhQ4Zw1lln8dBDD9G2bdvCX/nvv/8+f/nLX4gI7rzzTm644Qb+/d//nZ/+9Ke0a9eOuXPnFtZbunQpo0aN4rHHHqNNmzb84he/4MYbb+RHP/rRJseu247HHnsst9xyS4N1rlmzhtdee4264/hMnDiRYcOGMXDgQF566SWWLFnCPvvsA8Ds2bN5/vnnadmyJd27d2fEiBG88847vPXWW8ybNw+A5cuXF/ZVXV3NM888w5lnnrnZNq8UhgRJKqO6pxueffZZzjvvvMKPy+ZON5xwwgm89957tG3blp/+9KfbdDzI/TW8pTFrnn76ac4++2yaNWvGvvvuywknnADAggULOOSQQwq31Q0fPpyxY8dm7uP000+nWbNm9OjRo9BDsLFFixbx5S9/mbfffps1a9YU9vvYY48xceLEwnrt27dnypQpzJ8/n2OPPRbI/bgPGDAgc7+ba8eNLV26lD322KPevAkTJjB58mSaNWvGmWeeyaRJkwq9JJ/73Odo164dAD169OCNN97giCOO4LXXXmPEiBEMHjyYk08+ubCvjh07snjx4qJqqQSebpCkCjFgwACWLl3Ku+++u8V1n3jiCd544w2qqqq47rrrMtf5+9//XrhY77bbbtviPnfZZRc2bNgA5E4xrFmzZus+wGa0bNmy8D6llLnOiBEjuPzyy5k7dy633377Zm/ZSylx0kknMXv2bGbPns38+fP59a9/zV//+tfCZ37ooYe2us7WrVvXO+7cuXN55ZVXOOmkk+jSpQsTJ06sd8qh7udq3rw569ato3379syZM4fjjz+e2267jUsuuaSwzqpVq2jduvVW11UuhgRJqhALFixg/fr17LXXXkWtv8suuzBmzBjuvvtu3nvvvU2WH3DAAYUf0a997Wtb3F+XLl2YOXMmkLs7Ye3atUCui/6+++5jw4YNLFmyhGnTpgHQvXt3XnvtNWpqagD4zW9+U1TdDfnggw/Yf//9ARg/fnxh/kknnVTvFMH777/PZz7zGZ555hkWLlwIwD//+U9efvlljj766MJnLubCyY21b9+e9evXF4LChAkTGDlyJDU1NdTU1LB48WIWL17MG280PHji0qVL2bBhA2eeeSajRo1i1qxZhWUvv/wyPXv23Oq6ysWQIEllVHuNQFVVFV/+8pcZP3584ar62nPpta+bb755k+07derE8OHDN3uevViXXnop06dPp0+fPjz77LO0adMGgDPPPJPOnTvTo0cPzj33XKqrq2nXrh2tW7fm1ltvZdCgQfTr14/ddtut0PW+LUaOHMnZZ59Nv3792HvvvQvzr7nmGt5//3169uxJnz59eOKJJ+jQoQPjxo1j+PDh9O7dmwEDBrBgwYKij/WPf/yDzp07c+ONNzJq1Cg6d+7MihUrADj55JN5+umngdz1CEOHDq237dChQ+ud/tjYW2+9xfHHH09VVRXnnnsuP//5z4HcY8AXLlxI//79i66z3KKhbp+dUf/+/dOWzs1JajpefPFFPv3pT5e7jB3CypUradu2LcuWLeOoo47imWeeYd999y3MTynxb//2b3Tr1o3vfOc75S73E5k1axY33XQT99xzT6Pud/LkycyaNWurriFpTFn/vUfEzJRSg6nFCxclSVt06qmnsnz5ctasWcO1117LvvvuC8Add9zB+PHjWbNmDX379uWrX/1qmSv95KqrqznhhBNYv359oz6/Yd26dXz3u99ttP1tD/Yk1GFPgrRzsSdBO5Nt6UnwmgRJkpTJkCBJkjIZEiRJUqaSXbgYEStTSm23vGZpRcR3gdFAh5TS0s2uvPh5GLntt+9UpJHbPmKZJGnntkP1JETEVo18EhEHACcDb5amIkn6ZBwqurKHiq67fY8ePfja177Ghg0bqKmpadSHIq1bt44OHTpw1VVXbfM+3n33XQYNGtRoNcF2vgUyIroCtwAdgI+AS1NKCyJiHLAC6A/sC3w/pfS7jF3MiIi/AL8GnkhbvjXjJuD7wION9BEkNWWN3ZNYRE+eQ0VX/lDRtduvW7eOE088kQceeIDq6upGrXHq1KkcdthhTJo0iZ///OdExFbvo0OHDnTq1IlnnnmmMKbFJ7W9exLGAiNSSv2A7wG31lnWCTgOOBVoKH4eBkwALgfmR8T/jYj9slaMiNOAt1JKcxqreEkqJYeKrsyhomvtsssuHHPMMYVHQdeqqalh4MCBVFdX1+sNmjZtWqE9AC6//HLGjRuXWc+ECRP41re+xYEHHsizzz5bmN+lSxeuu+46qqur6dWrV+GpktOnTy/0jPTt25cPP/wQyA2kde+99xbdDluy3XoSIqItcAwwqU5CallnlQdSShvI/fjvk7WPlNJ6YAowJSI6AD8H3oyIY1JKz9U51q7A/yV3qmFLdV0GXAZwYLutT26S9Ek4VHTlDxVd66OPPuLxxx/nJz/5Sb35HTt2ZOrUqbRq1YpXXnmF4cOHb3FkzbpWrVrFY489xu23387y5cuZMGECxxxzTGH53nvvzaxZs7j11lsZPXo0d955J6NHj+aWW27h2GOPZeXKlbRq1QqA/v37c8011xR97C3ZnqcbmgHLU0pVDSxfXed9g7/WEdEOGAZcAKwBLgL+Z6PVugIHA3PygaQzMCsijkop/aPuiimlseR6OOi/X3OfLCVpu3Ko6P9VqUNF14aMiOC0007ji1/8YmFQK8iNyXD55Zcze/Zsmjdvzssvv1zUsWpNmTKFE044gdatW3PmmWfy05/+lDFjxhROd5xxxhkA9OvXj/vvvx/IhZ0rrriCc845hzPOOIPOnTsDjT8U9XY73ZBSWgG8HhFnA0ROn63ZR0T8JzCLXAA4L6X02ZTS3SmleuOJppTmppQ6ppS6pJS6AIuA6o0DgiRVEoeKrryhouF/Q8bzzz/PyJEjN9nmpptuYp999mHOnDnMmDGj0G512xNo8PNMmDCBxx57jC5dutCvXz+WLVtWr0eptu1qh6IGuOqqq7jzzjv5+OOPOfbYYwunIRp7KOpShoRdI2JRndcVwDnAxRExB3gB2PSkz+b9FuieUroqpfRKYxcsSeXkUNGVN1R0sXV36tSJZs2acc8997B+/XoADjroIObPn8/q1atZvnw5jz/++Cbbrlixgqeeeoo333yzMBz1LbfcwoQJEzZ7zFdffZVevXrxgx/8gCOPPLIQEhp7KOqShYSUUrOUUuc6rxtTSq+nlAallPqklHqklH6SX/eCunczNPR8hZTSQymlddtQS5ctPiNBksrAoaL/VyUOFV2Mb3zjG4wfP54+ffqwYMGCQrsdcMABfOlLX6Jnz5586Utfom/fvptsO3nyZE488cR6PS2nnXYaDz/8MKtXr95k/VpjxoyhZ8+e9O7dmxYtWvDFL34RyPUwDR48uOjat8QBnupo2alb6nT+mHKXoR1EzfWN9z+iysMBnornUNE7hn/5l3/hwQcfzLxLxqGiJUkl4VDRle/dd9/liiuu2OrbaDfHnoQ67EnQ1rAnYcdnT4J2Jg4VLUmSGo0hQZIkZTIkSJKkTIYESZKUyZAgSZIyGRIkKa/X+F6N+ipG8+bNqaqqok+fPvVGEFy8eDFnnXUWsOlogrWmTJlC37596dOnDz169OD222/nZz/7WeHhS7X7rn0Q08iRI4mIeqMYjhkzhohocPyGDz74gPPOO49DDz2Url27cs455/D+++8DMHv2bAYMGMARRxxB79696z1xce3atVx11VV069aN6upqBgwYwB//+MdN9j9t2jTatWtXqPPzn/88AE8++STV1dXssssu9UamhNxgURu3x7e//W3233//eo9B3lrDhg3jlVd8mG9dPiehjl77t2OGt7VJ2o7qDrj06KOPcvXVVzN9+nT222+/TX4c61q7di2XXXYZzz33HJ07d2b16tXU1NTQvXt3fvjDHwLUG2ERck807NWrFxMnTiyMFDhp0iSOOOKIBo9z8cUX07NnT+6++24ArrvuOi644AIefPBBdt11V+6++266devG4sWL6devH1/4whfYY489uPbaa3n77beZN28eLVu2ZMmSJUyfPj3zGAMHDmTKlCn15h144IGMGzeO0aNHb7L+jTfeyKWXXlqY3rBhA5MnT+aAAw5g+vTphQGottbXv/51brjhBu64445t2r4psidBkirEihUrCg/Cqamp2ewz+D/88EPWrVtXGOehZcuWdO/efYvHOP3003nwwQeB3GOf27VrV+8RyHUtXLiQmTNncu211xbm/ehHP2LOnDm89NJLHHbYYXTr1g2A/fbbj44dO/Luu+/y0Ucfcccdd/DLX/6y8LjhffbZhy996UtFtEJOly5d6N27N82abfozdd999zFo0KDC9LRp0zjiiCP4+te/Xm/Mg5EjR3LRRRdx/PHHc8ghhxQea/3Pf/6TwYMH06dPH3r27FnoARk4cCCPPfZYYRAlGRIkqaxqx244/PDDueSSS+r9IG/OnnvuyZAhQzjooIMYPnw49957b1Fd7bvvvjsHHHAA8+bNY+LEiXz5y19ucN358+cXTlvUat68OX379uXFF1+st+5zzz3HmjVr6Nq1KwsXLuTAAw9k9913L+qzPPXUU4XTDT/72c82u+7rr79O+/bt6411MGHCBIYPH87QoUP5/e9/XxiYCnKDZj366KM899xz/PjHP2bt2rU88sgj7LfffsyZM4d58+YVAkezZs049NBDmTNnTlF17wwMCZJURrWnGxYsWMAjjzzCeeed1+BQyhu78847efzxxznqqKMYPXo0F110UVHbDRs2jIkTJ/LAAw8wdOjQT1I+kLtG4Ctf+Qr/8R//kfmX/5YMHDiwMHJj7amSzR2rQ4cOhek1a9bwhz/8gdNPP53dd9+do48+mkcffbSwfPDgwbRs2ZK9996bjh07smTJEnr16sXUqVP5wQ9+wFNPPVVvUKqOHTuyePHirf4MTZUhQZIqxIABA1i6dCnvvvtu0dv06tWL73znO0ydOpX77ruvqG1OPfVU7rnnnk3+2p88eXLhL/oZM2bQo0cPZs+eXa+HYsOGDcyZM4fq6mogd4pk8ODB/OxnP+Mzn/kMAIceeihvvvlmYVTFujY+xtZq3bp1vWGcH330UZYvX06vXr3o0qULTz/9dL1TDnV7HJo3b866des47LDDmDVrFr169eKaa67hJz/5SWGdVatW0bp1662uq6kyJEhShViwYAHr168vXGewOStXrmTatGmF6dmzZ3PQQQcVdZxdd92VX/ziF5v81T506NDCX/T9+/fn0EMPpW/fvowaNaqwzqhRo/jc5z7HgQceyJo1axg6dCjnnXde4U6M2v1ffPHFfOtb32LNmjVAbvChSZMmbXKMrXXYYYdRU1NTmJ4wYQJ33nknNTU11NTU8PrrrzN16lQ++uijBvexePFidt11V84991yuvPJKZs2aVVj28ssvb/ZakJ2NdzdIUt7c8+du92PWXpMAkFJi/PjxmSMPPv7443Tu3LkwPWHCBG644Qa++tWv0rp1a9q0acO4ceOKPu6wYcOKWu+uu+5ixIgRdO3alRUrVnDkkUfy8MMPA/Db3/6WJ598kmXLlhWOPW7cOKqqqhg1ahTXXHMNPXr0oFWrVrRp06beX+xb8re//Y2hQ4fy/vvv8/DDD3Pdddfxwgsv0KZNm8J1D/vttx+PPPIIt912W2G7Nm3acNxxxxVqzDJ37lyuvPJKmjVrRosWLfjVr34FwJIlS2jdunVhhEs5CmQ9/fv3T9vS/SVpx+QokFvnpZdeYvDgwdx8882ccsopZatj8uTJzJw5s14PR2O46aab2H333bn44osbdb+VYltGgbQnQZJUlO7du9d7EFO5DB06lGXLljX6fvfYYw++8pWvNPp+d2SGBEnSDueSSy5p9H1eeOGFjb7PHZ0XLkraqXnKVTuDbf3v3JAgaafVqlUrli1bZlBQk5ZSYtmyZbRq1Wqrt/V0g6SdVufOnVm0aNFWPZdA2hG1atWq3t0xxTIkSNpptWjRgoMPPrjcZUgVy9MNkiQpkyFBkiRlMiRIkqRMhgRJkpTJkCBJkjIZEiRJUiZDgiRJymRIkCRJmQwJkiQpkyFBkiRlMiRIkqRMhgRJkpTJkCBJkjIZEiRJUiZDgiRJymRIkCRJmQwJkiQpkyFBkiRlMiRIkqRMhgRJkpTJkCBJkjIZEiRJUqZdyl1ARVn8PIxst/2PO/KD7X9MSZK2oGJ6EiJiZYn22zwino+IKaXYvyRJTVXFhIQS+hbwYrmLkCRpR1PRISEiukbEIxExMyKeiojD8/PHRcTNEfHniHgtIs5qYPvOwGDgzu1ZtyRJTUFFhwRgLDAipdQP+B5wa51lnYDjgFOB6xvYfgzwfWBDKYuUJKkpqtgLFyOiLXAMMCkiame3rLPKAymlDcD8iNgnY/tTgXdSSjMj4vjNHOcy4DKAA9tFQ6tJkrTTqdiQQK6XY3lKqaqB5avrvM/6dT8WGBIRpwCtgN0j4j9TSufWXSmlNJZcjwX992uePnnZkiQ1DRV7uiGltAJ4PSLOBoicPlux/dUppc4ppS7AMOBPGwcESZLUsEoKCbtGxKI6ryuAc4CLI2IO8AJwWnlLlCRp5xEp2cNeq2WnbqnT+WPKXcYOo+b6weUuQZL0CUTEzJRS/4aWV1JPgiRJqiCGBEmSlMmQIEmSMhkSJElSJkOCJEnKZEiQJEmZDAmSJCmTIUGSJGWq5LEbtrte+7djhg8IkiQJsCdBkiQ1wJAgSZIyGRIkSVImQ4IkScpkSJAkSZmKurshIpoD+9RdP6X0ZqmKkiRJ5bfFkBARI4DrgCXAhvzsBPQuYV2SJKnMiulJ+BbQPaW0rNTFSJKkylHMNQl/Bz4odSGSJKmyNNiTEBFX5N++BkyLiN8Dq2uXp5RuLHFtkiSpjDZ3umG3/L9v5l+fyr8gd02CJElqwhoMCSmlHwNExNkppUl1l0XE2aUuTJIklVcx1yRcXeQ8SZLUhGzumoQvAqcA+0fEzXUW7Q6sK3VhkiSpvDZ3TcJiYAYwBJhZZ/6HwHdKWZQkSSq/zV2TMAeYExH/lVJaux1rkiRJFaCYhynNioiN72b4gFwvwygfsiRJUtNUTEj4I7Ae+K/89DBgV+AfwDjgX0tSmSRJKqtiQsLnU0rVdabnRsSslFJ1RJxbqsIkSVJ5FXMLZPOIOKp2IiKOBJrnJ73LQZKkJqqYnoRLgLsioi0QwArgkohoA/y8lMVJkqTy2WJISCn9DegVEe3y03UHe/ptqQqTJEnltcWQEBEtgTOBLsAuEQFASuknJa1MkiSVVTGnGx4kd8vjTOqMAilJkpq2YkJC55TSoJJXIkmSKkoxdzf8OSJ6lbwSSZJUUYrpSTgOuCAiXid3uiGAlFLqXdLKJElSWRUTEr5Y8iokSVLF2eLphpTSG8ABwIn59x8Vs50kSdqxbfHHPiKuA34AXJ2f1QL4z1IWJUmSyq+YHoGhwBDgnwAppcXAbqUsSpIklV8xIWFNSikBCSD/OGZJktTEFRMSfhsRtwN7RMSlwGPAHaUtS5IklVsxYzeMjoiTyA3s1B34UUppaskrkyRJZVXMLZDkQ4HBQJKknUiDISEiPiR/HcLGi8g9TGn3klVVLoufh5Htyl1FeYz8YMvrSJJ2Kg2GhJTSdr2DISJWppTaNuL+WgFPAi3Jfc7fpZSua6z9S5LU1BV1umEHtZrcA6BWRkQL4OmI+GNK6S/lLkySpB1BRT85MSK6RsQjETEzIp6KiMPz88dFxM0R8eeIeC0iztp425SzMj/ZIv/KOn0iSZIyVHRIAMYCI1JK/YDvAbfWWdaJ3OBTpwLXZ20cEc0jYjbwDjA1pfTXEtcrSVKTsdnTDRHRHHgspXTCdqqn7rHbAscAkyKidnbLOqs8kFLaAMyPiH2y9pFSWg9URcQewOSI6JlSmrfRcS4DLgM4sF1k7EWSpJ3TZkNCSml9RGyIiHYppe19+XszYHlKqaqB5avrvN/sr3tKaXlEPAEMAuZttGwsuR4L+u/X3NMRkiTlFXPh4kpgbkRMJT9+A0BK6Zslqyq3/xUR8XpEnJ1SmhS57oTeKaU5xWwfER2AtfmA0Bo4CfhFKWuWJKkpKSYk3J9/ldquEbGozvSNwDnAryLiGnIXHk4EigoJ5K5ZGJ8/ZdIM+G1KaUpjFixJUlMWubGbtrBS7i/xA1NKL5W+pPJp2alb6nT+mHKXIW2zmusHl7sESTuQiJiZUurf0PIt3t0QEf8KzAYeyU9XRcRDjVeiJEmqRMXcAjkSOApYDpBSmg0cUsKaJElSBSgmJKzNuLNhQymKkSRJlaOYCxdfiIj/AzSPiG7AN4E/l7YsSZJUbsX0JIwAjiD3XIIJwAfAt0tZlCRJKr9iehI6pZR+CPyw1MVIkqTKUUxIuCsiOgN/A54CnkwpzS1tWZIkqdy2GBJSSp+NiE8BRwLHA7+PiLYppT1LXZwkSSqfLYaEiDgOGJh/7QFMIdej0OT02r8dM3wYjSRJQHGnG6YBM4GfA39IKa0paUWSJKkiFBMS9gaOBf4F+GZEbACeTSldW9LKJElSWRVzTcLyiHgNOADoDBxDbrAlSZLUhBVzTcJrwAJy1yH8CrjQUw6SJDV9xZxuODSl5GOYJUnayRTzxMXrI2L3iGgREY9HxLsRcW7JK5MkSWVVTEg4OaW0AjgVqAEOBa4sZVGSJKn8igkJtRcpDgYmZYwIKUmSmqBirkl4OCIWAB8DX4+IDsCq0pYlSZLKbYs9CSmlq8jd9tg/pbQW+CdwWqkLkyRJ5VVMTwLA4UCXiKi7/t0lqEeSJFWIYp6TcA/QFZgNrM/PThgSJElq0orpSegP9EgppVIXI0mSKkcxdzfMA/YtdSGSJKmyFDvA0/yIeA5YXTszpTSkZFVJkqSyKyYkjCx1EZIkqfIUMwrk9LrTEXEcMByYnr2FJElqCoq6BTIi+gL/BzgbeB24r5RFSZKk8mswJETEYeR6DIYDS4HfAJFSOmE71SZJkspocz0JC4CngFNTSgsBIuI726UqSZJUdpu7BfIM4G3giYi4IyI+B8T2KUuSJJVbgyEhpfRASmkYuUcyPwF8G+gYEb+KiJO3V4GSJKk8ihng6Z8ppf9KKf0r0Bl4HvhBySuTJEllVcwTFwtSSu+nlMamlD5XqoIkSVJl2KqQIEmSdh6GBEmSlMmQIEmSMhkSJElSJkOCJEnKZEiQJEmZDAmSJCmTIUGSJGUyJEiSpEyGBEmSlMmQIEmSMhkSJElSpl3KXQBARKxMKbVtxP0dANwN7AMkYGxK6f9tccPFz8PIdo1VhhrTyA/KXYEk7XQqIiSUwDrguymlWRGxGzAzIqamlOaXuzBJknYUFXu6ISK6RsQjETEzIp6KiMPz88dFxM0R8eeIeC0iztp425TS2ymlWfn3HwIvAvtv308gSdKOrZJ7EsYCX0spvRIRRwO3Aifml3UCjgMOBx4CftfQTiKiC9AX+Gspi5UkqampyJAQEW2BYxlXvo8AAAiHSURBVIBJEVE7u2WdVR5IKW0A5kfEPlvYz33At1NKKxpY5zLgMoAD20XWKpIk7ZQqMiSQOw2yPKVU1cDy1XXeZ/6yR0QLcgHh3pTS/Q0dKKU0llyvBf33a562rVxJkpqeirwmIf9X/+sRcTZA5PQpdvvIdT/8GngxpXRjicqUJKlJq5SQsGtELKrzugI4B7g4IuYALwCnbcX+jgW+ApwYEbPzr1NKULckSU1WRZxuSCk1FFYGZax7wUbTmzxfIaX0NA2chpAkScWJlDwNX6tlp26p0/ljyl2GJH0iNdcPLncJ2kFExMyUUv+GllfK6QZJklRhDAmSJCmTIUGSJGUyJEiSpEyGBEmSlMmQIEmSMhkSJElSJkOCJEnKVBFPXKwUvfZvxwwfQiJJEmBPgiRJaoAhQZIkZTIkSJKkTIYESZKUyZAgSZIyGRIkSVImQ4IkScpkSJAkSZkMCZIkKZMhQZIkZTIkSJKkTIYESZKUyZAgSZIyGRIkSVImQ4IkScpkSJAkSZkMCZIkKZMhQZIkZTIkSJKkTIYESZKUyZAgSZIyGRIkSVImQ4IkScpkSJAkSZkMCZIkKZMhQZIkZdql3AVUkheWvUCv8b3KXYYkbZO5588tdwlqYuxJkCRJmQwJkiQpkyFBkiRlMiRIkqRMhgRJkpTJkCBJkjIZEiRJUiZDgiRJyuTDlOo4YvUaZrz+ZrnLUFM28oNyVyBJRauInoSIWFmCfd4VEe9ExLzG3rckSTuDiggJJTIOGFTuIiRJ2lFVbEiIiK4R8UhEzIyIpyLi8Pz8cRFxc0T8OSJei4izsrZPKT0JvLddi5YkqQmp5GsSxgJfSym9EhFHA7cCJ+aXdQKOAw4HHgJ+V54SJUlquioyJEREW+AYYFJE1M5uWWeVB1JKG4D5EbHPJzzWZcBlAAe2iy2sLUnSzqMiQwK50yDLU0pVDSxfXef9J/plTymNJddrQf/9mqdPsi9JkpqSirwmIaW0Ang9Is4GiJw+ZS5LkqSdSqWEhF0jYlGd1xXAOcDFETEHeAE4bWt2GBETgGeB7vl9Xtz4ZUuS1HRFSvaw12rZqVvqdP6YcpchSdImaq4f3Oj7jIiZKaX+DS2vlJ4ESZJUYQwJkiQpkyFBkiRlMiRIkqRMhgRJkpTJkCBJkjIZEiRJUiZDgiRJylSpYzeURa/92zGjBA+rkCRpR2RPgiRJymRIkCRJmQwJkiQpkyFBkiRlMiRIkqRMhgRJkpTJkCBJkjIZEiRJUiZDgiRJymRIkCRJmQwJkiQpkyFBkiRlMiRIkqRMkVIqdw0VIyI+BF4qdx1N1N7A0nIX0UTZtqVj25aObVs6W9O2B6WUOjS00KGi63sppdS/3EU0RRExw7YtDdu2dGzb0rFtS6cx29bTDZIkKZMhQZIkZTIk1De23AU0YbZt6di2pWPblo5tWzqN1rZeuChJkjLZkyBJkjIZEoCIGBQRL0XEwoi4qtz17Agi4q6IeCci5tWZt2dETI2IV/L/ts/Pj4i4Od++/xMR1XW2OT+//isRcX45PkuliYgDIuKJiJgfES9ExLfy823fTygiWkXEcxExJ9+2P87PPzgi/ppvw99ExKfy81vmpxfml3eps6+r8/NfiogvlOcTVZ6IaB4Rz0fElPy0bdsIIqImIuZGxOyImJGfV/rvhJTSTv0CmgOvAocAnwLmAD3KXVelv4B/AaqBeXXm3QBclX9/FfCL/PtTgD8CAXwG+Gt+/p7Aa/l/2+ffty/3Zyv3C+gEVOff7wa8DPSwfRulbQNom3/fAvhrvs1+CwzLz78N+Hr+/TeA2/LvhwG/yb/vkf+uaAkcnP8OaV7uz1cJL+AK4L+AKflp27Zx2rUG2HujeSX/TrAnAY4CFqaUXksprQEmAqeVuaaKl1J6Enhvo9mnAePz78cDp9eZf3fK+QuwR0R0Ar4ATE0pvZdSeh+YCgwqffWVLaX0dkppVv79h8CLwP7Yvp9Yvo1W5idb5F8JOBH4XX7+xm1b2+a/Az4XEZGfPzGltDql9DqwkNx3yU4tIjoDg4E789OBbVtKJf9OMCTkvnz/Xmd6UX6ett4+KaW38+//AeyTf99QG9v2W5Dvgu1L7i9e27cR5LvDZwPvkPuSfBVYnlJal1+lbjsV2jC//ANgL2zbhowBvg9syE/vhW3bWBLw3xExMyIuy88r+XeCT1xUSaSUUkR468wnEBFtgfuAb6eUVuT+yMqxfbddSmk9UBURewCTgcPLXFKTEBGnAu+klGZGxPHlrqcJOi6l9FZEdASmRsSCugtL9Z1gTwK8BRxQZ7pzfp623pJ8lxb5f9/Jz2+ojW37BkREC3IB4d6U0v352bZvI0opLQeeAAaQ646t/aOpbjsV2jC/vB2wDNs2y7HAkIioIXfa9kTg/2HbNoqU0lv5f98hF26PYjt8JxgS4G9At/wVuJ8idwHNQ2WuaUf1EFB7tez5wIN15p+Xv+L2M8AH+S6yR4GTI6J9/qrck/Pzdmr587K/Bl5MKd1YZ5Ht+wlFRId8DwIR0Ro4idw1H08AZ+VX27hta9v8LOBPKXcF2EPAsPwV+gcD3YDnts+nqEwppatTSp1TSl3IfY/+KaV0DrbtJxYRbSJit9r35P5fnsf2+E4o9xWblfAidyXoy+TOTf6w3PXsCC9gAvA2sJbcea2LyZ1PfBx4BXgM2DO/bgC35Nt3LtC/zn4uIndh0kLgwnJ/rkp4AceRO//4P8Ds/OsU27dR2rY38Hy+becBP8rPP4TcD9FCYBLQMj+/VX56YX75IXX29cN8m78EfLHcn62SXsDx/O/dDbbtJ2/PQ8jd8TEHeKH2d2p7fCf4xEVJkpTJ0w2SJCmTIUGSJGUyJEiSpEyGBEmSlMmQIEmSMhkSJElSJkOCJEnKZEiQJEmZ/j9tqzJTGbYkpwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbehpUGXtzM-",
        "colab_type": "text"
      },
      "source": [
        "## Bar plot for model perf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPYhq9jGoNpa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "ceeae258-9784-4cc2-b15c-399ade944ae0"
      },
      "source": [
        "results = pd.read_csv(model_path + 'final-model_eval.csv')\n",
        "results.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "results.set_index('Model Name',inplace=True)\n",
        "results"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1(Ans)</th>\n",
              "      <th>EM(Ans)</th>\n",
              "      <th>F1(Plau Ans)</th>\n",
              "      <th>EM(Plau Ans)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model Name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LSTM Baseline</th>\n",
              "      <td>29.001121</td>\n",
              "      <td>28.225002</td>\n",
              "      <td>0.214623</td>\n",
              "      <td>0.053718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Deep LSTM + GloVe</th>\n",
              "      <td>26.666439</td>\n",
              "      <td>26.030236</td>\n",
              "      <td>0.276301</td>\n",
              "      <td>0.069066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bi-LSTM + GloVe</th>\n",
              "      <td>28.021961</td>\n",
              "      <td>27.526667</td>\n",
              "      <td>0.281106</td>\n",
              "      <td>0.126621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bi-LSTM + GloVe + Q2C Attention</th>\n",
              "      <td>33.095119</td>\n",
              "      <td>33.094160</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bi-LSTM + GloVe + Q2C-C2Q Attention</th>\n",
              "      <td>29.622157</td>\n",
              "      <td>29.130535</td>\n",
              "      <td>0.200039</td>\n",
              "      <td>0.069066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTM Baseline + Universal Sentence Encode</th>\n",
              "      <td>24.545255</td>\n",
              "      <td>22.952958</td>\n",
              "      <td>0.618575</td>\n",
              "      <td>0.099762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bi-LSTM + Universal Sentence Encode</th>\n",
              "      <td>32.025226</td>\n",
              "      <td>31.544010</td>\n",
              "      <td>0.068411</td>\n",
              "      <td>0.023022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bi-LSTM + Q2C Attention + Universal Sentence Encode</th>\n",
              "      <td>30.695975</td>\n",
              "      <td>30.120482</td>\n",
              "      <td>0.146946</td>\n",
              "      <td>0.042207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BERT + Cased_L-12_H-768_A-12 + DeepPavlov</th>\n",
              "      <td>59.096928</td>\n",
              "      <td>51.362136</td>\n",
              "      <td>22.539289</td>\n",
              "      <td>18.179725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BERT + Uncased_L-24_H-1024_A-24 + Huggingface</th>\n",
              "      <td>57.513153</td>\n",
              "      <td>49.769780</td>\n",
              "      <td>22.158168</td>\n",
              "      <td>17.753818</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      F1(Ans)  ...  EM(Plau Ans)\n",
              "Model Name                                                     ...              \n",
              "LSTM Baseline                                       29.001121  ...      0.053718\n",
              "Deep LSTM + GloVe                                   26.666439  ...      0.069066\n",
              "Bi-LSTM + GloVe                                     28.021961  ...      0.126621\n",
              "Bi-LSTM + GloVe + Q2C Attention                     33.095119  ...      0.000000\n",
              "Bi-LSTM + GloVe + Q2C-C2Q Attention                 29.622157  ...      0.069066\n",
              "LSTM Baseline + Universal Sentence Encode           24.545255  ...      0.099762\n",
              "Bi-LSTM + Universal Sentence Encode                 32.025226  ...      0.023022\n",
              "Bi-LSTM + Q2C Attention + Universal Sentence En...  30.695975  ...      0.042207\n",
              "BERT + Cased_L-12_H-768_A-12 + DeepPavlov           59.096928  ...     18.179725\n",
              "BERT + Uncased_L-24_H-1024_A-24 + Huggingface       57.513153  ...     17.753818\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71Mqeqf3m3uf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "1d42f84e-d728-4b08-b207-6fe36fc10d50"
      },
      "source": [
        "results.plot(kind='barh',figsize=(10,10))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f442f9af470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHv8BXzlnJfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUSShzdet2sN",
        "colab_type": "text"
      },
      "source": [
        "## bAbI data evals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO4wkVFs5kwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we will test babi for 2 models, BERT-huggingface and bilstm-glove-q2c\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm0MJ2N7G_FE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load\n",
        "loc = [m for m in list_of_models if m['id']=='bilstm-glove-q2c-attention'][0]['loc']\n",
        "loc\n",
        "bilstm_glove_q2c_attention = load_mrc_model(loc)\n",
        "params = loadparams(name='params_withoutstopwords.json')\n",
        "tokenizer = load_tokenizer(name='glove')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U99_IE30NXwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(bilstm_glove_q2c_attention)\n",
        "print(berthugmodel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGGe7pykt5lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "listofiles = glob.glob(model_path + \"bAbI-evals/*.*\")\n",
        "\n",
        "def loadBabi(f):\n",
        "  babi_1 = pd.read_csv(f,sep='\\t',names=['a','b','c','d'])\n",
        "  # print(babi_1)  \n",
        "  df = pd.DataFrame(columns=['context','question','answer','plausible_answer','prediction'])\n",
        "  c = []\n",
        "  for i in range(len(babi_1)):\n",
        "    a = babi_1['a'].iloc[i]\n",
        "    li = a.split(' ')[0]    \n",
        "    # is NaN check\n",
        "    if(babi_1['b'].iloc[i] != babi_1['b'].iloc[i]):\n",
        "      c.append(a.replace(li,'').strip())    \n",
        "\n",
        "    if(babi_1['b'].iloc[i] == babi_1['b'].iloc[i]):\n",
        "      # this is answer row\n",
        "      c_ = \"\".join(c)\n",
        "      q = babi_1['a'].iloc[i].replace(li,'').strip()\n",
        "      ans = babi_1['b'].iloc[i]\n",
        "      values = [\"\".join(c),\n",
        "                babi_1['a'].iloc[i].replace(li,'').strip(),\n",
        "                babi_1['b'].iloc[i],'']\n",
        "      zipped = zip(df.columns, values)\n",
        "      a_dictionary = dict(zipped)\n",
        "      df = df.append(a_dictionary,ignore_index=True) \n",
        "            \n",
        "    if(li == '15'):\n",
        "      c = []\n",
        "  return df "
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmXCGXBWAy5a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4bd2a641-5fad-4daa-fec9-cc8e656bbc7b"
      },
      "source": [
        "len(listofiles)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5lnmKlDuOlx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "4ce4ce4b-0903-485d-bda1-3f81f1f290d8"
      },
      "source": [
        "dfs = {}\n",
        "for file in listofiles:\n",
        "  bt = file.replace(model_path + \"bAbI-evals/\",\"\")\n",
        "  print(bt)\n",
        "  dfs[bt] = loadBabi(file)  "
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "qa3_three-supporting-facts_test.txt\n",
            "qa2_two-supporting-facts_test.txt\n",
            "qa1_single-supporting-fact_test.txt\n",
            "qa19_path-finding_test.txt\n",
            "qa20_agents-motivations_test.txt\n",
            "qa18_size-reasoning_test.txt\n",
            "qa17_positional-reasoning_test.txt\n",
            "qa16_basic-induction_test.txt\n",
            "qa15_basic-deduction_test.txt\n",
            "qa13_compound-coreference_test.txt\n",
            "qa6_yes-no-questions_test.txt\n",
            "qa14_time-reasoning_test.txt\n",
            "qa12_conjunction_test.txt\n",
            "qa10_indefinite-knowledge_test.txt\n",
            "qa8_lists-sets_test.txt\n",
            "qa11_basic-coreference_test.txt\n",
            "qa9_simple-negation_test.txt\n",
            "qa7_counting_test.txt\n",
            "qa5_three-arg-relations_test.txt\n",
            "qa4_two-arg-relations_test.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_zvySCBUo73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa4a11ed-79bb-4f85-c487-2a55fc918db6"
      },
      "source": [
        "len(dfs)"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44_evqnYOMMF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "3f1a7b8e-a833-4dd8-da56-5d04846ae2eb"
      },
      "source": [
        "babi_model_results_bilstm = pd.DataFrame(columns=['bAbI task','F1(Ans)','EM(Ans)','F1(Plau Ans)','EM(Plau Ans)'])\n",
        "babi_model_results_bert = pd.DataFrame(columns=['bAbI task','F1(Ans)','EM(Ans)','F1(Plau Ans)','EM(Plau Ans)'])\n",
        "\n",
        "for bt in dfs:\n",
        "  test = dfs[bt]\n",
        "  # topkenizer and params is already loaded above \n",
        "  print('bAbI Evaluation for ', bt.replace('_test.txt',\"\"))\n",
        "  test_context_sequence, test_question_sequence = generate_question_context_sequence(context=test[\"context\"].values,\n",
        "                                question=test[\"question\"].values,\n",
        "                                question_max_length=params['question_max_length'],\n",
        "                                padding=params['question_pad_seq'],\n",
        "                                context_max_length=params['context_max_length']\n",
        "                                )  \n",
        "  y_prediction = bilstm_glove_q2c_attention.predict([test_question_sequence,test_context_sequence])\n",
        "  y_prediction_new,start_pred,end_pred = combine_y(y_prediction,test.shape[0])\n",
        "  # acc_score,macro_f1_score,micro_f1_score = accuracy_metrics(y_test_new,y_prediction_new)\n",
        "  y_pred_text = generate_y_preds_text(test,start_pred,end_pred)\n",
        "  exact_raw, f1_raw, exact_scores_pa,f1_scores_pa = get_raw_scores(test, y_pred_text)\n",
        "  exact, f1,exact_pa, f1_pa, total = make_eval_dict(exact_raw,f1_raw, exact_scores_pa,f1_scores_pa)\n",
        "  values = [bt.replace('_test.txt',\"\"),              \n",
        "            f1,\n",
        "            exact,\n",
        "            f1_pa,\n",
        "            exact_pa]\n",
        "  zipped = zip(babi_model_results_bilstm.columns, values)\n",
        "  a_dictionary = dict(zipped)\n",
        "  babi_model_results_bilstm = babi_model_results_bilstm.append(a_dictionary,ignore_index=True) \n",
        "  "
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa3_three-supporting-facts\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:01<00:00, 956.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa2_two-supporting-facts\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:00<00:00, 2395.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa1_single-supporting-fact\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:00<00:00, 3259.55it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa19_path-finding\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [01:04<00:00, 15.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa20_agents-motivations\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:00<00:00, 3929.58it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa18_size-reasoning\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:00<00:00, 1254.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa17_positional-reasoning\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:04<00:00, 230.26it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa16_basic-induction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:55<00:00, 18.11it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa15_basic-deduction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:16<00:00, 61.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa13_compound-coreference\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:00<00:00, 2942.16it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa6_yes-no-questions\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:00<00:00, 3446.47it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa14_time-reasoning\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:00<00:00, 2746.33it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa12_conjunction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:00<00:00, 2796.36it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa10_indefinite-knowledge\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:00<00:00, 3206.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa8_lists-sets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:00<00:00, 2908.72it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa11_basic-coreference\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:00<00:00, 3158.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa9_simple-negation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:00<00:00, 3527.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa7_counting\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:00<00:00, 3062.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa5_three-arg-relations\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:00<00:00, 2081.31it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bAbI Evaluation for  qa4_two-arg-relations\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:24<00:00, 40.01it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBNXvif8VlPC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "503bae3c-8d87-478d-fd62-405ed65daa04"
      },
      "source": [
        "babi_model_results_bilstm"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bAbI task</th>\n",
              "      <th>F1(Ans)</th>\n",
              "      <th>EM(Ans)</th>\n",
              "      <th>F1(Plau Ans)</th>\n",
              "      <th>EM(Plau Ans)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>qa3_three-supporting-facts</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>qa2_two-supporting-facts</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>qa1_single-supporting-fact</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>qa19_path-finding</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>qa20_agents-motivations</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>qa18_size-reasoning</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>qa17_positional-reasoning</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>qa16_basic-induction</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>qa15_basic-deduction</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>qa13_compound-coreference</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>qa6_yes-no-questions</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>qa14_time-reasoning</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>qa12_conjunction</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>qa10_indefinite-knowledge</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>qa8_lists-sets</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>qa11_basic-coreference</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>qa9_simple-negation</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>qa7_counting</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>qa5_three-arg-relations</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>qa4_two-arg-relations</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     bAbI task  F1(Ans)  EM(Ans)  F1(Plau Ans)  EM(Plau Ans)\n",
              "0   qa3_three-supporting-facts      0.0      0.0           0.0           0.0\n",
              "1     qa2_two-supporting-facts      0.0      0.0           0.0           0.0\n",
              "2   qa1_single-supporting-fact      0.0      0.0           0.0           0.0\n",
              "3            qa19_path-finding      0.0      0.0           0.0           0.0\n",
              "4      qa20_agents-motivations      0.0      0.0           0.0           0.0\n",
              "5          qa18_size-reasoning      0.0      0.0           0.0           0.0\n",
              "6    qa17_positional-reasoning      0.0      0.0           0.0           0.0\n",
              "7         qa16_basic-induction      0.0      0.0           0.0           0.0\n",
              "8         qa15_basic-deduction      0.0      0.0           0.0           0.0\n",
              "9    qa13_compound-coreference      0.0      0.0           0.0           0.0\n",
              "10        qa6_yes-no-questions      0.0      0.0           0.0           0.0\n",
              "11         qa14_time-reasoning      0.0      0.0           0.0           0.0\n",
              "12            qa12_conjunction      0.0      0.0           0.0           0.0\n",
              "13   qa10_indefinite-knowledge      0.0      0.0           0.0           0.0\n",
              "14              qa8_lists-sets      0.0      0.0           0.0           0.0\n",
              "15      qa11_basic-coreference      0.0      0.0           0.0           0.0\n",
              "16         qa9_simple-negation      0.0      0.0           0.0           0.0\n",
              "17                qa7_counting      0.0      0.0           0.0           0.0\n",
              "18     qa5_three-arg-relations      0.0      0.0           0.0           0.0\n",
              "19       qa4_two-arg-relations      0.0      0.0           0.0           0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7jaCYRMZDzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "babi_model_results_bert = pd.DataFrame(columns=['bAbI task','F1(Ans)','EM(Ans)','F1(Plau Ans)','EM(Plau Ans)'])\n",
        "\n",
        "for bt in dfs:\n",
        "  test = dfs[bt]\n",
        "  # topkenizer and params is already loaded above \n",
        "  print('bAbI Evaluation for ', bt.replace('_test.txt',\"\"))\n",
        "  preds = []\n",
        "  for i in tqdm(range(test.shape[0])):\n",
        "    try:\n",
        "      p = ''\n",
        "      p = predBERTHuggingface(test['question'].iloc[i],test['context'].iloc[i])\n",
        "    except:\n",
        "      print('error in prediction')\n",
        "    preds = preds + [p]\n",
        "  test['prediction'] = preds\n",
        "  exact_raw, f1_raw, exact_scores_pa,f1_scores_pa = get_raw_scores(test, test['prediction'].values.tolist())\n",
        "  exact, f1,exact_pa, f1_pa, total = make_eval_dict(exact_raw,f1_raw, exact_scores_pa,f1_scores_pa)      \n",
        "  values = [bt.replace('_test.txt',\"\"),              \n",
        "            f1,\n",
        "            exact,\n",
        "            f1_pa,\n",
        "            exact_pa]\n",
        "  zipped = zip(babi_model_results_bert.columns, values)\n",
        "  a_dictionary = dict(zipped)\n",
        "  babi_model_results_bert = babi_model_results_bert.append(a_dictionary,ignore_index=True) \n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBjmDKb9bQVG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "82f10089-261f-431b-8398-68d498076208"
      },
      "source": [
        "test"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>plausible_answer</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Daniel left the football there.Daniel took the...</td>\n",
              "      <td>Where was the apple before the bathroom?</td>\n",
              "      <td>office</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Daniel left the football there.Daniel took the...</td>\n",
              "      <td>Where was the apple before the hallway?</td>\n",
              "      <td>office</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Daniel left the football there.Daniel took the...</td>\n",
              "      <td>Where was the apple before the hallway?</td>\n",
              "      <td>office</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Daniel left the football there.Daniel took the...</td>\n",
              "      <td>Where was the football before the garden?</td>\n",
              "      <td>bathroom</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Daniel left the football there.Daniel took the...</td>\n",
              "      <td>Where was the football before the garden?</td>\n",
              "      <td>bathroom</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Daniel went to the bedroom.John grabbed the mi...</td>\n",
              "      <td>Where was the apple before the office?</td>\n",
              "      <td>hallway</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Daniel went to the bedroom.John grabbed the mi...</td>\n",
              "      <td>Where was the apple before the office?</td>\n",
              "      <td>hallway</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Daniel went to the bedroom.John grabbed the mi...</td>\n",
              "      <td>Where was the milk before the kitchen?</td>\n",
              "      <td>bedroom</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>Daniel went to the bedroom.John grabbed the mi...</td>\n",
              "      <td>Where was the football before the garden?</td>\n",
              "      <td>bathroom</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Daniel went to the bedroom.John grabbed the mi...</td>\n",
              "      <td>Where was the football before the garden?</td>\n",
              "      <td>bathroom</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows  5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               context  ... prediction\n",
              "0    Daniel left the football there.Daniel took the...  ...           \n",
              "1    Daniel left the football there.Daniel took the...  ...           \n",
              "2    Daniel left the football there.Daniel took the...  ...           \n",
              "3    Daniel left the football there.Daniel took the...  ...           \n",
              "4    Daniel left the football there.Daniel took the...  ...           \n",
              "..                                                 ...  ...        ...\n",
              "995  Daniel went to the bedroom.John grabbed the mi...  ...           \n",
              "996  Daniel went to the bedroom.John grabbed the mi...  ...           \n",
              "997  Daniel went to the bedroom.John grabbed the mi...  ...           \n",
              "998  Daniel went to the bedroom.John grabbed the mi...  ...           \n",
              "999  Daniel went to the bedroom.John grabbed the mi...  ...           \n",
              "\n",
              "[1000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iU1dtOQbhQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}