{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mrc-LSTM-baseline0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandipanbasu/aiml-capstone/blob/master/mrc_LSTM_baseline0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA8sHlEbfYnn",
        "colab_type": "code",
        "outputId": "9aab83fb-8f6a-4289-bd65-aac717ceda3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGZp4iLEHE8n",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries and Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_u1n8G3fge_",
        "colab_type": "code",
        "outputId": "1aed8d2d-5bdd-48a8-a190-dc3c0125112d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "project_path = \"/content/drive/My Drive/AIML-MRC-Capstone/datasets/Squad2.0/TrainingDataset/\"\n",
        "\n",
        "squad_df = pd.read_csv(project_path+'squad_data_final.csv')\n",
        "squad_df.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "squad_df.tail(5)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>id</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer</th>\n",
              "      <th>plausible_answer_start</th>\n",
              "      <th>plausible_answer</th>\n",
              "      <th>is_impossible</th>\n",
              "      <th>clean_context</th>\n",
              "      <th>clean_question</th>\n",
              "      <th>clean_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>130301</th>\n",
              "      <td>Matter</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>Physics has broadly agreed on the definition o...</td>\n",
              "      <td>5a7e070b70df9f001a875439</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>485.0</td>\n",
              "      <td>matter</td>\n",
              "      <td>True</td>\n",
              "      <td>term matter used throughout physics bewilderin...</td>\n",
              "      <td>physics has broadly agreed on the definition o...</td>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130302</th>\n",
              "      <td>Matter</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>Who coined the term partonic matter?</td>\n",
              "      <td>5a7e070b70df9f001a87543a</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>327.0</td>\n",
              "      <td>Alfvén</td>\n",
              "      <td>True</td>\n",
              "      <td>term matter used throughout physics bewilderin...</td>\n",
              "      <td>who coined the term partonic matter</td>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130303</th>\n",
              "      <td>Matter</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>What is another name for anti-matter?</td>\n",
              "      <td>5a7e070b70df9f001a87543b</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Gk. common matter</td>\n",
              "      <td>True</td>\n",
              "      <td>term matter used throughout physics bewilderin...</td>\n",
              "      <td>what is another name for antimatter</td>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130304</th>\n",
              "      <td>Matter</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>Matter usually does not need to be used in con...</td>\n",
              "      <td>5a7e070b70df9f001a87543c</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>529.0</td>\n",
              "      <td>a specifying modifier</td>\n",
              "      <td>True</td>\n",
              "      <td>term matter used throughout physics bewilderin...</td>\n",
              "      <td>matter usually does not need to be used in con...</td>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130305</th>\n",
              "      <td>Matter</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>What field of study has a variety of unusual c...</td>\n",
              "      <td>5a7e070b70df9f001a87543d</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37.0</td>\n",
              "      <td>physics</td>\n",
              "      <td>True</td>\n",
              "      <td>term matter used throughout physics bewilderin...</td>\n",
              "      <td>what field of study has a variety of unusual c...</td>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         title  ... clean_answer\n",
              "130301  Matter  ...   IMPOSSIBLE\n",
              "130302  Matter  ...   IMPOSSIBLE\n",
              "130303  Matter  ...   IMPOSSIBLE\n",
              "130304  Matter  ...   IMPOSSIBLE\n",
              "130305  Matter  ...   IMPOSSIBLE\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK5ZkxKeHbu5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "855WpIGFHfMr",
        "colab_type": "text"
      },
      "source": [
        "# Lets use 2 LSTM network for context and question and use a concat layer to merge. y is the answer "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6dcPCGiJrz1",
        "colab_type": "text"
      },
      "source": [
        "# Step 1 Tokenize and Vectorize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcNCdQgK_sE9",
        "colab_type": "text"
      },
      "source": [
        "### Tokenizing context and question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cCWphXNKoHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context_tokenize = preprocessing.text.Tokenizer()\n",
        "context_tokenize.fit_on_texts(squad_df['clean_context']) #Fit it on clean_context\n",
        "\n",
        "questions_tokenize= preprocessing.text.Tokenizer()\n",
        "questions_tokenize.fit_on_texts(squad_df['clean_question'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2iQ-9ZZNWhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert the context text to indexes\n",
        "context_sequence= context_tokenize.texts_to_sequences(squad_df['clean_context'])\n",
        "# convert the questions to indexes\n",
        "questions_sequence= questions_tokenize.texts_to_sequences(squad_df['clean_question'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn5paTsLONKE",
        "colab_type": "code",
        "outputId": "8a703b77-8d83-42fd-a0a5-b252980ee9eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print(squad_df['clean_context'][2000])\n",
        "print(context_sequence[3000])\n",
        "print(squad_df['clean_question'][2000])\n",
        "print(questions_sequence[2000])"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "october 21 2008 apple reported 14 21 total revenue fiscal quarter 4 year 2008 came ipods september 9 2009 keynote presentation apple event phil schiller announced total cumulative sales ipods exceeded 220 million continual decline ipod sales since 2009 surprising trend apple corporation apple cfo peter oppenheimer explained june 2009 expect traditional mp3 players decline time cannibalize ipod touch iphone since 2009 companys ipod sales continually decreased every financial quarter 2013 new model introduced onto market\n",
            "[360, 464, 56909, 483, 454, 21, 7582, 7198, 1401, 2632, 2957, 4, 14, 1401, 5514, 56910, 1051, 2806, 4752, 249, 1260, 9282, 2806, 5514, 7725, 2752, 1600, 3891, 692, 1892, 5514, 204, 2129, 4752, 26680, 78, 578, 5194, 118, 1401, 618, 5590, 118, 5514, 2, 56911, 1482, 11598, 4122, 16977, 229, 56912, 962, 3628, 4968, 23304, 1030, 2632, 2957, 207, 1339, 92, 6491, 162, 1512, 337, 4752, 26680, 578, 8296, 29, 3198, 10, 397, 2728, 525, 170, 578, 65, 8, 10870, 51, 3279, 584]\n",
            "who was chief financial officer of apple in july of 2009\n",
            "[10, 6, 886, 620, 2250, 3, 762, 4, 1224, 3, 320]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTFqLp3iAqjq",
        "colab_type": "text"
      },
      "source": [
        "### Find Max Sequence Length for both the Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di181GmIOSq3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "53f5ab29-241f-4ee1-ed79-80dd51c7ac12"
      },
      "source": [
        "# max length of context\n",
        "max_context_seq_length= max(len(txt) for txt in context_sequence)\n",
        "print('max_context_seq_length=',max_context_seq_length)\n",
        "\n",
        "# vocab size of context\n",
        "context_vocab_size=len(context_tokenize.word_index)\n",
        "print('context_vocab_size=',context_vocab_size)\n",
        "\n",
        "max_question_seq_length=max(len(txt) for txt in questions_sequence)\n",
        "print('max_question_seq_length=',max_question_seq_length)\n",
        "\n",
        "# vocab size of questions\n",
        "questions_vocab_size=len(questions_tokenize.word_index)\n",
        "print('questions_vocab_size=',questions_vocab_size)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_context_seq_length= 426\n",
            "context_vocab_size= 93529\n",
            "max_question_seq_length= 40\n",
            "questions_vocab_size= 47289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHh0g7SDLOjL",
        "colab_type": "text"
      },
      "source": [
        "### Padding the sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVRGBRsXLU2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# padding context\n",
        "context_input_data= tf.keras.preprocessing.sequence.pad_sequences(context_sequence, maxlen=max_context_seq_length, padding='pre')\n",
        "# padding question\n",
        "question_input_data=tf.keras.preprocessing.sequence.pad_sequences(questions_sequence, maxlen=max_question_seq_length,padding='pre')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6FSl5UDL_qD",
        "colab_type": "text"
      },
      "source": [
        "# Build the LSTM Model for both Sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-glhG509P5Yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_size = 50\n",
        "rnn_units=256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOYjXu-vCZyB",
        "colab_type": "text"
      },
      "source": [
        "### LSTM for Context and Question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_LGPo_6QKtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CONTEXT LSTM\n",
        "# input layer\n",
        "context_input=layers.Input(shape=(max_context_seq_length,),name=\"CONTEXT_INPUT\")\n",
        "# Build Embedding layer and Get Embedding Layer output\n",
        "context_embedding_output=layers.Embedding(context_vocab_size+1, embedding_size, name=\"CONTEXT_EMBEDDING\")(context_input)\n",
        "#LSTM layer and its output\n",
        "# CONTEXT_LSTM= layers.LSTM(rnn_units,name='CONTEXT_LSTM')(context_embedding_output)\n",
        "\n",
        "c_output,c_h, c_s = layers.LSTM(rnn_units,name='CONTEXT_LSTM', return_state=True)(context_embedding_output)\n",
        "\n",
        "#build a list to feed for concatenation\n",
        "context_states= [c_h, c_s]\n",
        "\n",
        "# QUESTION LSTM\n",
        "#input layer\n",
        "question_input=layers.Input(shape=(max_question_seq_length,),name=\"QUESTION_INPUT\")\n",
        "#Embedding layer and #Embedding layer output\n",
        "question_embedding_output=layers.Embedding(input_dim=questions_vocab_size+1, output_dim=embedding_size, name=\"QUESTION_EMBEDDING\")(question_input)\n",
        "#LSTM2 layer \n",
        "# QUESTION_LSTM= tf.keras.layers.LSTM(rnn_units,name='QUESTION_LSTM')(question_embedding_output)\n",
        "q_output,q_h, q_s= tf.keras.layers.LSTM(rnn_units,name='QUESTION_LSTM',return_state=True)(question_embedding_output)\n",
        "questions_states = [q_h, q_s]\n",
        "\n",
        "\n",
        "# print(CONTEXT_LSTM)\n",
        "# print(QUESTION_LSTM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wE36OJYsgHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c786164e-b4d2-4864-876c-28fe97550069"
      },
      "source": [
        "context_states,questions_states"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<tf.Tensor 'CONTEXT_LSTM_10/Identity_1:0' shape=(None, 256) dtype=float32>,\n",
              "  <tf.Tensor 'CONTEXT_LSTM_10/Identity_2:0' shape=(None, 256) dtype=float32>],\n",
              " [<tf.Tensor 'QUESTION_LSTM_10/Identity_1:0' shape=(None, 256) dtype=float32>,\n",
              "  <tf.Tensor 'QUESTION_LSTM_10/Identity_2:0' shape=(None, 256) dtype=float32>])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRcPtZqFXabR",
        "colab_type": "text"
      },
      "source": [
        "# Concat the two LSTM layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbyWtSg8XeZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MERGED_cell_state =layers.concatenate([context_states[0],questions_states[0]],name=\"CONCAT_CELL_STATE\")\n",
        "MERGED_hidden_state =layers.concatenate([context_states[1],questions_states[1]],name=\"HIDDEN_CELL_STATE\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGqKHNq3rEPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8d90adfe-dd6e-4efd-eef6-bd151cb17b1f"
      },
      "source": [
        "decoder_initial_state = [MERGED_cell_state,MERGED_hidden_state]\n",
        "decoder_initial_state"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'CONCAT_CELL_STATE_5/Identity:0' shape=(None, 512) dtype=float32>,\n",
              " <tf.Tensor 'HIDDEN_CELL_STATE_5/Identity:0' shape=(None, 512) dtype=float32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkqzHf00dSfI",
        "colab_type": "text"
      },
      "source": [
        "# Create Decoder for Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVjDhKLUd9jM",
        "colab_type": "text"
      },
      "source": [
        "# Add  Start and  End tokens to Answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEf_85IGsYIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "squad_df['answer_start_end']= '<start>' + squad_df['clean_answer'] + '<end>'\n",
        "squad_df['answer_start_end']=squad_df['answer_start_end'].astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S25hREZeNIW",
        "colab_type": "text"
      },
      "source": [
        "#Tokenize the Answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-5MBMrOyTsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answers_tokenize=tf.keras.preprocessing.text.Tokenizer()\n",
        "answers_tokenize.fit_on_texts(squad_df['answer_start_end'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1by-Iw8yteW",
        "colab_type": "code",
        "outputId": "f5e10d35-4974-4c94-beda-5cd478a87603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Vocab\n",
        "print(len(answers_tokenize.word_index))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sbN9pYI_GqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert sentences to numbers \n",
        "answers_seq = answers_tokenize.texts_to_sequences(squad_df['answer_start_end']) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEmnUNaw_jyH",
        "colab_type": "code",
        "outputId": "4f8d6522-1a1f-4fcc-cf73-392d740800c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(squad_df['answer_start_end'][2000])\n",
        "print(answers_seq[2000])"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start>peter oppenheimer<end>\n",
            "[2, 924, 7781, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24mDpru-e624",
        "colab_type": "text"
      },
      "source": [
        "# Get maximum length and pad the sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL5y5fqqzPav",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6b7b1c97-eb1e-4f79-b4b1-4a51bc3d7edb"
      },
      "source": [
        "squad_df[squad_df['clean_answer'].str.len() > 200]['answer_start_end']"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3201    <start>that the sudden shift of a huge quantit...\n",
            "Name: answer_start_end, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4R8QCYI_ywa",
        "colab_type": "code",
        "outputId": "51e9ea9f-9d04-4de8-bc27-a285d543f47e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "max_answers_seq_length=max(len(txt) for txt in squad_df['answer_start_end'])\n",
        "print('max_answers_seq_length=',max_answers_seq_length)\n",
        "\n",
        "answers_vocab_size=len(answers_tokenize.word_index)\n",
        "print('answers_vocab_size=',answers_vocab_size)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_answers_seq_length= 248\n",
            "answers_vocab_size= 41475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqJpe8rTAUHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pad pre\n",
        "answers_input_data= tf.keras.preprocessing.sequence.pad_sequences(answers_seq,maxlen=max_answers_seq_length,padding='pre')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC5nH0YKizaj",
        "colab_type": "text"
      },
      "source": [
        "# Building Decoder Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byD2aHWjBfng",
        "colab_type": "code",
        "outputId": "bf8e4190-54f2-4018-86f4-74351154ab11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "answers_input_data.shape"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(130306, 248)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRMx8dPPB-jB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize array\n",
        "answers_target_data = np.zeros((answers_input_data.shape[0], #number of sentences 130306\n",
        "                                answers_input_data.shape[1])) #number of words in each sentence 248\n",
        "\n",
        "#Shift Target output by one word\n",
        "for i in range(answers_input_data.shape[0]):\n",
        "    for j in range(1,answers_input_data.shape[1]):\n",
        "        answers_target_data[i][j-1] = answers_input_data[i][j]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbFQKKXkDGaP",
        "colab_type": "code",
        "outputId": "e3bf0e45-788a-4c60-da32-cde6894124ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "print(squad_df['answer_start_end'][2000])\n",
        "print(answers_input_data[2000])"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start>peter oppenheimer<end>\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    2  924 7781    1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtEzDD_Ai2Rx",
        "colab_type": "text"
      },
      "source": [
        "# Convert Answers to one-hot vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN4VGg0ECo3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Crashing !!\n",
        "answers_target_data_one_hot= np.zeros((answers_input_data.shape[0], #number of sentences\n",
        "                                       answers_input_data.shape[1], #Number of words in each sentence\n",
        "                                       len(answers_tokenize.word_index)+1)) #Vocab size + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkuJpMPXpwS2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7c2aa6bf-e256-413f-f5f4-b2a2942391be"
      },
      "source": [
        "print(answers_input_data.shape)\n",
        "print(len(answers_tokenize.word_index)+1)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(130306, 248)\n",
            "41476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhCFV20ZLOmD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answers_embedding_size = 50\n",
        "decoder_rnn_units = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xfx0f0mii58",
        "colab_type": "text"
      },
      "source": [
        "# Build Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k38FCLDrJTlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#input layer\n",
        "answers_inputs=tf.keras.layers.Input(shape=(max_answers_seq_length,),name=\"ANSWER_INPUT\")\n",
        "\n",
        "#Embedding\n",
        "answers_embedding_output=tf.keras.layers.Embedding(answers_vocab_size+1, answers_embedding_size, name=\"ANSWER_EMBEDDING\")(answers_inputs)\n",
        "\n",
        "#lstm layer\n",
        "answers_lstm= tf.keras.layers.LSTM(decoder_rnn_units,return_sequences=True,name=\"ANSWER_LSTM\", return_state=True)\n",
        "\n",
        "#LSTM Output, State initialization from Encoder states(concat of question and answer)\n",
        "#Output will be all hidden sequences, last 'h' state and last 'c' state\n",
        "\n",
        "output,_,_=answers_lstm(answers_embedding_output,initial_state=decoder_initial_state)\n",
        "\n",
        "#dense layer\n",
        "lstm3_dense= tf.keras.layers.Dense(answers_vocab_size+1,activation='softmax',name=\"FINAL_OUTPUT\")\n",
        "\n",
        "#answer output\n",
        "answer_outputs=lstm3_dense(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14J7GXH2jBcO",
        "colab_type": "text"
      },
      "source": [
        "# Build Model using Encoder ( output of concat) and Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFhlppB6qsgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Model([context_input,question_input, answers_inputs],answer_outputs) #Output of the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCTlgD7tu2yn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "70a1e985-a8b0-471e-cf5f-c460b433433d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "CONTEXT_INPUT (InputLayer)      [(None, 426)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "QUESTION_INPUT (InputLayer)     [(None, 40)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "CONTEXT_EMBEDDING (Embedding)   (None, 426, 50)      4676500     CONTEXT_INPUT[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "QUESTION_EMBEDDING (Embedding)  (None, 40, 50)       2364500     QUESTION_INPUT[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "ANSWER_INPUT (InputLayer)       [(None, 248)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "CONTEXT_LSTM (LSTM)             [(None, 256), (None, 314368      CONTEXT_EMBEDDING[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "QUESTION_LSTM (LSTM)            [(None, 256), (None, 314368      QUESTION_EMBEDDING[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "ANSWER_EMBEDDING (Embedding)    (None, 248, 50)      2073800     ANSWER_INPUT[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "CONCAT_CELL_STATE (Concatenate) (None, 512)          0           CONTEXT_LSTM[0][1]               \n",
            "                                                                 QUESTION_LSTM[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "HIDDEN_CELL_STATE (Concatenate) (None, 512)          0           CONTEXT_LSTM[0][2]               \n",
            "                                                                 QUESTION_LSTM[0][2]              \n",
            "__________________________________________________________________________________________________\n",
            "ANSWER_LSTM (LSTM)              [(None, 248, 512), ( 1153024     ANSWER_EMBEDDING[0][0]           \n",
            "                                                                 CONCAT_CELL_STATE[0][0]          \n",
            "                                                                 HIDDEN_CELL_STATE[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "FINAL_OUTPUT (Dense)            (None, 248, 41476)   21277188    ANSWER_LSTM[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 32,173,748\n",
            "Trainable params: 32,173,748\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFboskisjumN",
        "colab_type": "text"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDB4_KhCiqDp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xw8T5_pdOIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcF8YXJ4ZocR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}